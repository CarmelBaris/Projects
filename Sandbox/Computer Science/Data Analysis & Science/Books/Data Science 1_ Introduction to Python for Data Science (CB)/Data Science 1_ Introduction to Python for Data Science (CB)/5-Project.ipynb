{
  "cells": [
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "markdown",
      "source": "# Project\n\n> **Learning goal:** By the end of this Capstone, you should be familiar with some of the ways to visually explore the data stored in __`DataFrame`__s.\n\nOften when probing a new data set, it is invaluable to get high-level information about what the dataset holds. Earlier in this section we discussed using methods such as __`DataFrame.info()`__, __`DataFrame.head()`__, and __`DataFrame.tail()`__ to examine some aspects of a __`DataFrame`__. While these methods are critical, they are on their own often insufficient to get enough information to know how to approach a new dataset. This is where exploratory statistics and visualizations for datasets come in.\n\nTo see what we mean in terms of gaining exploratory insight (both visually and numerically), let's dig into one of the the datasets that come with the __`scikit-learn`__ library, the Boston Housing Dataset (though you will load it from a CSV file):"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\n\ndf = pd.read_csv('Data/housing_dataset.csv')\ndf.head()\n\n# used to have Race as data, was removed\n# has measurments of housing\n# zillow - how mich is your house worth\n\n# for each house in this dataset, we've captured information\n# ZN - that's pretty huge, so it's like mansions\n# INDUS - industry, factories\n# in machine learning, a dummy variable is a way to convert a categorical value (usually string) into a number (like 'Male'/'Female' could be 1/0)\n# Charles River - if it's next to the river or not\n# NOX - pollution\n# RM how big is the house\n# AGE - the bigger, the older it is\n# PTE - the smaller, the better\n# LSTAT - economic status\n# MEDV - the actual value of the home in millions of dollars\n\n\n# so we have a lot of housing data and a lot of features",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>LSTAT</th>\n      <th>MEDV</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00632</td>\n      <td>18.0</td>\n      <td>2.31</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>6.575</td>\n      <td>65.2</td>\n      <td>4.0900</td>\n      <td>1.0</td>\n      <td>296.0</td>\n      <td>15.3</td>\n      <td>4.98</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.02731</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0.0</td>\n      <td>0.469</td>\n      <td>6.421</td>\n      <td>78.9</td>\n      <td>4.9671</td>\n      <td>2.0</td>\n      <td>242.0</td>\n      <td>17.8</td>\n      <td>9.14</td>\n      <td>21.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.02729</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0.0</td>\n      <td>0.469</td>\n      <td>7.185</td>\n      <td>61.1</td>\n      <td>4.9671</td>\n      <td>2.0</td>\n      <td>242.0</td>\n      <td>17.8</td>\n      <td>4.03</td>\n      <td>34.7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.03237</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0.0</td>\n      <td>0.458</td>\n      <td>6.998</td>\n      <td>45.8</td>\n      <td>6.0622</td>\n      <td>3.0</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>2.94</td>\n      <td>33.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.06905</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0.0</td>\n      <td>0.458</td>\n      <td>7.147</td>\n      <td>54.2</td>\n      <td>6.0622</td>\n      <td>3.0</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>5.33</td>\n      <td>36.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n\n   PTRATIO  LSTAT  MEDV  \n0     15.3   4.98  24.0  \n1     17.8   9.14  21.6  \n2     17.8   4.03  34.7  \n3     18.7   2.94  33.4  \n4     18.7   5.33  36.2  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This dataset contains information collected from the U.S Census Bureau concerning housing in the area of Boston, Massachusetts and was first published in 1978. The dataset has 14 columns:\n - **CRIM**:     Per-capita crime rate by town\n - **ZN**:       Proportion of residential land zoned for lots over 25,000 square feet\n - **INDUS**:    Proportion of non-retail business acres per town\n - **CHAS**:     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n - **NOX**:      Nitric oxides concentration (parts per 10 million)\n - **RM**:       Average number of rooms per dwelling\n - **AGE**:      Proportion of owner-occupied units built prior to 1940\n - **DIS**:      Weighted distances to five Boston employment centres\n - **RAD**:      Index of accessibility to radial highways\n - **TAX**:      Full-value property-tax rate per \\$10,000\n - **PTRATIO**:  Pupil-teacher ratio by town\n - **LSTAT**:    Percent of lower-status portion of the population\n - **MEDV**:     Median value of owner-occupied homes in \\$1,000s\n \n One of the first methods we can use to better understand this dataset is `DataFrame.shape`:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.shape # let's look at the shape of the data frame",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "(506, 13)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The dataset has 506 rows and 13 columns.\n\nTo get a better idea of the contents of each column we can use `DataFrame.describe`, which returns the maximum value, minimums value, mean, and standard deviation of numeric values in each columns, in addition to the quartiles for each column:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.describe() # descriptive statistics of data, to get a goog picture of the data",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>LSTAT</th>\n      <th>MEDV</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.593761</td>\n      <td>11.363636</td>\n      <td>11.136779</td>\n      <td>0.069170</td>\n      <td>0.554695</td>\n      <td>6.284634</td>\n      <td>68.574901</td>\n      <td>3.795043</td>\n      <td>9.549407</td>\n      <td>408.237154</td>\n      <td>18.455534</td>\n      <td>12.653063</td>\n      <td>22.532806</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8.596783</td>\n      <td>23.322453</td>\n      <td>6.860353</td>\n      <td>0.253994</td>\n      <td>0.115878</td>\n      <td>0.702617</td>\n      <td>28.148861</td>\n      <td>2.105710</td>\n      <td>8.707259</td>\n      <td>168.537116</td>\n      <td>2.164946</td>\n      <td>7.141062</td>\n      <td>9.197104</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.006320</td>\n      <td>0.000000</td>\n      <td>0.460000</td>\n      <td>0.000000</td>\n      <td>0.385000</td>\n      <td>3.561000</td>\n      <td>2.900000</td>\n      <td>1.129600</td>\n      <td>1.000000</td>\n      <td>187.000000</td>\n      <td>12.600000</td>\n      <td>1.730000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.082045</td>\n      <td>0.000000</td>\n      <td>5.190000</td>\n      <td>0.000000</td>\n      <td>0.449000</td>\n      <td>5.885500</td>\n      <td>45.025000</td>\n      <td>2.100175</td>\n      <td>4.000000</td>\n      <td>279.000000</td>\n      <td>17.400000</td>\n      <td>6.950000</td>\n      <td>17.025000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.256510</td>\n      <td>0.000000</td>\n      <td>9.690000</td>\n      <td>0.000000</td>\n      <td>0.538000</td>\n      <td>6.208500</td>\n      <td>77.500000</td>\n      <td>3.207450</td>\n      <td>5.000000</td>\n      <td>330.000000</td>\n      <td>19.050000</td>\n      <td>11.360000</td>\n      <td>21.200000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.647423</td>\n      <td>12.500000</td>\n      <td>18.100000</td>\n      <td>0.000000</td>\n      <td>0.624000</td>\n      <td>6.623500</td>\n      <td>94.075000</td>\n      <td>5.188425</td>\n      <td>24.000000</td>\n      <td>666.000000</td>\n      <td>20.200000</td>\n      <td>16.955000</td>\n      <td>25.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>88.976200</td>\n      <td>100.000000</td>\n      <td>27.740000</td>\n      <td>1.000000</td>\n      <td>0.871000</td>\n      <td>8.780000</td>\n      <td>100.000000</td>\n      <td>12.126500</td>\n      <td>24.000000</td>\n      <td>711.000000</td>\n      <td>22.000000</td>\n      <td>37.970000</td>\n      <td>50.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\ncount  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \nmean     3.593761   11.363636   11.136779    0.069170    0.554695    6.284634   \nstd      8.596783   23.322453    6.860353    0.253994    0.115878    0.702617   \nmin      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n75%      3.647423   12.500000   18.100000    0.000000    0.624000    6.623500   \nmax     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n\n              AGE         DIS         RAD         TAX     PTRATIO       LSTAT  \\\ncount  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \nmean    68.574901    3.795043    9.549407  408.237154   18.455534   12.653063   \nstd     28.148861    2.105710    8.707259  168.537116    2.164946    7.141062   \nmin      2.900000    1.129600    1.000000  187.000000   12.600000    1.730000   \n25%     45.025000    2.100175    4.000000  279.000000   17.400000    6.950000   \n50%     77.500000    3.207450    5.000000  330.000000   19.050000   11.360000   \n75%     94.075000    5.188425   24.000000  666.000000   20.200000   16.955000   \nmax    100.000000   12.126500   24.000000  711.000000   22.000000   37.970000   \n\n             MEDV  \ncount  506.000000  \nmean    22.532806  \nstd      9.197104  \nmin      5.000000  \n25%     17.025000  \n50%     21.200000  \n75%     25.000000  \nmax     50.000000  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Because dataset can have so many columns in them, it can often be useful to transpose the results of `DataFrame.describe` to better use them.\nNote that you can also examine specific descriptive statistics for columns without having to invoke `DataFrame.describe`:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df['MEDV'].mean()",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "22.532806324110698"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df['MEDV'].max()",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "50.0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df['AGE'].median()",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "77.5"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Now find the maximum value in df['AGE'].\n",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Other information that you will often want to see is the relationship between different columns. You do this with the `DataFrame.groupby` method. For example, you could examine the average MEDV (median value of owner-occupied homes) for each value of AGE (proportion of owner-occupied units built prior to 1940):"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.groupby(['AGE'])['MEDV'].mean() # Panda lets us group the data by a specific criteria\n# the MEDV value of the home, grouped by age\n# we see that when it's an older home, it's cheaper. but in the middle we also see fluctuations, so we can't draw explicit conclusions.\n# we can try to make an assumption and confirm/disconfirm it",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "AGE\n2.9      26.600000\n6.0      24.100000\n6.2      23.400000\n6.5      24.700000\n6.6      24.750000\n6.8      29.600000\n7.8      23.250000\n8.4      42.800000\n8.9      24.800000\n9.8      23.700000\n9.9      31.100000\n10.0     29.000000\n13.0     24.400000\n13.9     32.900000\n14.7     24.600000\n15.3     34.900000\n15.7     42.300000\n15.8     34.900000\n16.3     25.200000\n17.0     46.700000\n17.2     22.600000\n17.5     23.950000\n17.7     33.100000\n17.8     23.500000\n18.4     25.150000\n18.5     21.150000\n18.8     29.100000\n19.1     20.900000\n19.5     20.600000\n20.1     22.500000\n           ...    \n95.8     18.800000\n96.0     13.500000\n96.1     25.450000\n96.2     27.966667\n96.4     14.900000\n96.6     11.700000\n96.7     17.050000\n96.8     50.000000\n96.9     13.500000\n97.0     14.033333\n97.1     19.800000\n97.2     17.100000\n97.3     17.533333\n97.4     24.133333\n97.5     50.000000\n97.7     19.600000\n97.8     11.800000\n97.9     18.250000\n98.0      8.100000\n98.1     10.400000\n98.2     24.150000\n98.3     10.000000\n98.4     16.350000\n98.5     19.400000\n98.7     14.100000\n98.8     14.500000\n98.9     13.066667\n99.1     10.900000\n99.3     17.800000\n100.0    16.920930\nName: MEDV, Length: 356, dtype: float64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Now try to find the median value for AGE for each value of MEDV.\ndf.groupby(['AGE'])['MEDV'].median()",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "AGE\n2.9      26.60\n6.0      24.10\n6.2      23.40\n6.5      24.70\n6.6      24.75\n6.8      29.60\n7.8      23.25\n8.4      42.80\n8.9      24.80\n9.8      23.70\n9.9      31.10\n10.0     29.00\n13.0     24.40\n13.9     32.90\n14.7     24.60\n15.3     34.90\n15.7     42.30\n15.8     34.90\n16.3     25.20\n17.0     46.70\n17.2     22.60\n17.5     23.95\n17.7     33.10\n17.8     23.50\n18.4     25.15\n18.5     21.15\n18.8     29.10\n19.1     20.90\n19.5     20.60\n20.1     22.50\n         ...  \n95.8     18.80\n96.0     14.35\n96.1     25.45\n96.2     20.80\n96.4     14.90\n96.6     11.70\n96.7     17.05\n96.8     50.00\n96.9     13.50\n97.0     15.10\n97.1     19.80\n97.2     17.10\n97.3     19.10\n97.4     17.80\n97.5     50.00\n97.7     19.60\n97.8     11.80\n97.9     17.50\n98.0      8.10\n98.1     10.40\n98.2     16.65\n98.3     10.00\n98.4     16.35\n98.5     19.40\n98.7     14.10\n98.8     13.45\n98.9     11.50\n99.1     10.90\n99.3     17.80\n100.0    14.50\nName: MEDV, Length: 356, dtype: float64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can also apply a lambda function to each element of a `DataFrame` column by using the `apply` method. For example, say you wanted to create a new column that flagged a row if more than 50 percent of owner-occupied homes were build before 1940:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df['AGE_50'] = df['AGE'].apply(lambda x: x > 50)",
      "execution_count": 37,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Once applied, you also see how many values returned true and how many false by using the `value_counts` method:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df['AGE_50'].value_counts()",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 38,
          "data": {
            "text/plain": "True     359\nFalse    147\nName: AGE_50, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can also examine figures from the groupby statement you created earlier:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.groupby(['AGE_50'])['MEDV'].mean()",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 39,
          "data": {
            "text/plain": "AGE_50\nFalse    26.693197\nTrue     20.829248\nName: MEDV, dtype: float64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can also group by more than one variable, such AGE_50 (the one you just created), CHAS (whether a town is on the Charles River), and RAD (an index measuring access to the Boston-area radial highways), and then evaluate each group for the average median home price in that group:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "groupby_twovar = df.groupby(['AGE_50','RAD','CHAS'])['MEDV'].mean()",
      "execution_count": 40,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can then see what values are in this stacked group of variables:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "groupby_twovar",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 41,
          "data": {
            "text/plain": "AGE_50  RAD   CHAS\nFalse   1.0   0.0     24.666667\n              1.0     50.000000\n        2.0   0.0     33.300000\n        3.0   0.0     26.505556\n        4.0   0.0     25.376744\n              1.0     32.900000\n        5.0   0.0     26.302857\n              1.0     46.000000\n        6.0   0.0     23.575000\n        7.0   0.0     28.563636\n        8.0   0.0     29.220000\n        24.0  0.0     20.766667\nTrue    1.0   0.0     20.185714\n        2.0   0.0     24.170588\n        3.0   0.0     29.350000\n              1.0     27.950000\n        4.0   0.0     17.879661\n              1.0     21.560000\n        5.0   0.0     25.124638\n              1.0     25.610000\n        6.0   0.0     19.822222\n        7.0   0.0     24.433333\n        8.0   0.0     32.321429\n              1.0     26.000000\n        24.0  0.0     15.306612\n              1.0     31.362500\nName: MEDV, dtype: float64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's take a moment to analyze these results in a little depth. The first row reports that communities with less than half of houses built before 1940, with a highway-access index of 1, and that are not situated on the Charles River have a mean house price of \\$24,667 (1970s dollars); the next row shows that for communities similar to the first row except for being located on the Charles River have a mean house price of \\$50,000.\n\nOne insight that pops out from continuing down this is that, all else being equal, being located next to the Charles River can significantly increase the value of newer housing stock. The story is more ambiguous for communities dominated by older houses: proximity to the Charles significantly increases home prices in one community (and that one presumably farther away from the city); for all others, being situated on the river either provided a modest increase in value or actually decreased mean home prices.\n\nWhile groupings like this can be a great way to begin to interrogate your data, you might not care for the 'tall' format it comes in. In that case, you can unstack the data into a \"wide\" format:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "groupby_twovar.unstack()",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 42,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CHAS</th>\n      <th>0.0</th>\n      <th>1.0</th>\n    </tr>\n    <tr>\n      <th>AGE_50</th>\n      <th>RAD</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"9\" valign=\"top\">False</th>\n      <th>1.0</th>\n      <td>24.666667</td>\n      <td>50.0000</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>33.300000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>26.505556</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4.0</th>\n      <td>25.376744</td>\n      <td>32.9000</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>26.302857</td>\n      <td>46.0000</td>\n    </tr>\n    <tr>\n      <th>6.0</th>\n      <td>23.575000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7.0</th>\n      <td>28.563636</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8.0</th>\n      <td>29.220000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>24.0</th>\n      <td>20.766667</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th rowspan=\"9\" valign=\"top\">True</th>\n      <th>1.0</th>\n      <td>20.185714</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>24.170588</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>29.350000</td>\n      <td>27.9500</td>\n    </tr>\n    <tr>\n      <th>4.0</th>\n      <td>17.879661</td>\n      <td>21.5600</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>25.124638</td>\n      <td>25.6100</td>\n    </tr>\n    <tr>\n      <th>6.0</th>\n      <td>19.822222</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7.0</th>\n      <td>24.433333</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8.0</th>\n      <td>32.321429</td>\n      <td>26.0000</td>\n    </tr>\n    <tr>\n      <th>24.0</th>\n      <td>15.306612</td>\n      <td>31.3625</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "CHAS               0.0      1.0\nAGE_50 RAD                     \nFalse  1.0   24.666667  50.0000\n       2.0   33.300000      NaN\n       3.0   26.505556      NaN\n       4.0   25.376744  32.9000\n       5.0   26.302857  46.0000\n       6.0   23.575000      NaN\n       7.0   28.563636      NaN\n       8.0   29.220000      NaN\n       24.0  20.766667      NaN\nTrue   1.0   20.185714      NaN\n       2.0   24.170588      NaN\n       3.0   29.350000  27.9500\n       4.0   17.879661  21.5600\n       5.0   25.124638  25.6100\n       6.0   19.822222      NaN\n       7.0   24.433333      NaN\n       8.0   32.321429  26.0000\n       24.0  15.306612  31.3625"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# How could you use groupby to get a sense of the proportion \n# of residential land zoned for lots over 25,000 sq.ft., \n# the proportion of non-retail business acres per town, \n# and the distance of towns from employment centers in Boston?\n",
      "execution_count": 43,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "It is also often valuable to know how many unique values a column has in it with the `nunique` method:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df['CHAS'].nunique()",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 44,
          "data": {
            "text/plain": "2"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Complementary to that, you will also likely want to know what those unique values are, which is where the `unique` method helps:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df['CHAS'].unique()",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 45,
          "data": {
            "text/plain": "array([0., 1.])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can use the `value_counts` method to see how many of each unique value there are in a column:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df['CHAS'].value_counts()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Or you can easily plot a bar graph to visually see the breakdown:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline\ndf['CHAS'].value_counts().plot(kind='bar')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Note that the Jupyter magic command `%matplotlib inline` enables you to view the chart inline.\n\nLet's pull back to the dataset as a whole for a moment. Two major things that you will look for in almost any dataset are trends and relationships. A typical relationship between variables to explore is the Pearson correlation, or the extent to which two variables are linearly related. The `corr` method will show this in table format for all of the columns in a `DataFrame`:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.corr(method='pearson')\n# is there anything in my dataset that is highly correlated with something else in my dataset?\n# corr method\n# example - how does pollution correlate with the value of the home - it's all negative\n# so when the pollution goes up, the price goes down\n# same with crime - more crime rate, cheaper homes\n\n# we might want to look at correlations btw attributes, like pollution and factories\n# multi colliniarity - when we find that variables are highly correlated\n\n\n# so we want to look at our data before we even start doing things with it",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>LSTAT</th>\n      <th>MEDV</th>\n      <th>AGE_50</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>CRIM</th>\n      <td>1.000000</td>\n      <td>-0.199458</td>\n      <td>0.404471</td>\n      <td>-0.055295</td>\n      <td>0.417521</td>\n      <td>-0.219940</td>\n      <td>0.350784</td>\n      <td>-0.377904</td>\n      <td>0.622029</td>\n      <td>0.579564</td>\n      <td>0.288250</td>\n      <td>0.452220</td>\n      <td>-0.385832</td>\n      <td>0.254574</td>\n    </tr>\n    <tr>\n      <th>ZN</th>\n      <td>-0.199458</td>\n      <td>1.000000</td>\n      <td>-0.533828</td>\n      <td>-0.042697</td>\n      <td>-0.516604</td>\n      <td>0.311991</td>\n      <td>-0.569537</td>\n      <td>0.664408</td>\n      <td>-0.311948</td>\n      <td>-0.314563</td>\n      <td>-0.391679</td>\n      <td>-0.412995</td>\n      <td>0.360445</td>\n      <td>-0.590769</td>\n    </tr>\n    <tr>\n      <th>INDUS</th>\n      <td>0.404471</td>\n      <td>-0.533828</td>\n      <td>1.000000</td>\n      <td>0.062938</td>\n      <td>0.763651</td>\n      <td>-0.391676</td>\n      <td>0.644779</td>\n      <td>-0.708027</td>\n      <td>0.595129</td>\n      <td>0.720760</td>\n      <td>0.383248</td>\n      <td>0.603800</td>\n      <td>-0.483725</td>\n      <td>0.516001</td>\n    </tr>\n    <tr>\n      <th>CHAS</th>\n      <td>-0.055295</td>\n      <td>-0.042697</td>\n      <td>0.062938</td>\n      <td>1.000000</td>\n      <td>0.091203</td>\n      <td>0.091251</td>\n      <td>0.086518</td>\n      <td>-0.099176</td>\n      <td>-0.007368</td>\n      <td>-0.035587</td>\n      <td>-0.121515</td>\n      <td>-0.053929</td>\n      <td>0.175260</td>\n      <td>0.088659</td>\n    </tr>\n    <tr>\n      <th>NOX</th>\n      <td>0.417521</td>\n      <td>-0.516604</td>\n      <td>0.763651</td>\n      <td>0.091203</td>\n      <td>1.000000</td>\n      <td>-0.302188</td>\n      <td>0.731470</td>\n      <td>-0.769230</td>\n      <td>0.611441</td>\n      <td>0.668023</td>\n      <td>0.188933</td>\n      <td>0.590879</td>\n      <td>-0.427321</td>\n      <td>0.597644</td>\n    </tr>\n    <tr>\n      <th>RM</th>\n      <td>-0.219940</td>\n      <td>0.311991</td>\n      <td>-0.391676</td>\n      <td>0.091251</td>\n      <td>-0.302188</td>\n      <td>1.000000</td>\n      <td>-0.240265</td>\n      <td>0.205246</td>\n      <td>-0.209847</td>\n      <td>-0.292048</td>\n      <td>-0.355501</td>\n      <td>-0.613808</td>\n      <td>0.695360</td>\n      <td>-0.164465</td>\n    </tr>\n    <tr>\n      <th>AGE</th>\n      <td>0.350784</td>\n      <td>-0.569537</td>\n      <td>0.644779</td>\n      <td>0.086518</td>\n      <td>0.731470</td>\n      <td>-0.240265</td>\n      <td>1.000000</td>\n      <td>-0.747881</td>\n      <td>0.456022</td>\n      <td>0.506456</td>\n      <td>0.261515</td>\n      <td>0.602339</td>\n      <td>-0.376955</td>\n      <td>0.870348</td>\n    </tr>\n    <tr>\n      <th>DIS</th>\n      <td>-0.377904</td>\n      <td>0.664408</td>\n      <td>-0.708027</td>\n      <td>-0.099176</td>\n      <td>-0.769230</td>\n      <td>0.205246</td>\n      <td>-0.747881</td>\n      <td>1.000000</td>\n      <td>-0.494588</td>\n      <td>-0.534432</td>\n      <td>-0.232471</td>\n      <td>-0.496996</td>\n      <td>0.249929</td>\n      <td>-0.673813</td>\n    </tr>\n    <tr>\n      <th>RAD</th>\n      <td>0.622029</td>\n      <td>-0.311948</td>\n      <td>0.595129</td>\n      <td>-0.007368</td>\n      <td>0.611441</td>\n      <td>-0.209847</td>\n      <td>0.456022</td>\n      <td>-0.494588</td>\n      <td>1.000000</td>\n      <td>0.910228</td>\n      <td>0.464741</td>\n      <td>0.488676</td>\n      <td>-0.381626</td>\n      <td>0.361191</td>\n    </tr>\n    <tr>\n      <th>TAX</th>\n      <td>0.579564</td>\n      <td>-0.314563</td>\n      <td>0.720760</td>\n      <td>-0.035587</td>\n      <td>0.668023</td>\n      <td>-0.292048</td>\n      <td>0.506456</td>\n      <td>-0.534432</td>\n      <td>0.910228</td>\n      <td>1.000000</td>\n      <td>0.460853</td>\n      <td>0.543993</td>\n      <td>-0.468536</td>\n      <td>0.381395</td>\n    </tr>\n    <tr>\n      <th>PTRATIO</th>\n      <td>0.288250</td>\n      <td>-0.391679</td>\n      <td>0.383248</td>\n      <td>-0.121515</td>\n      <td>0.188933</td>\n      <td>-0.355501</td>\n      <td>0.261515</td>\n      <td>-0.232471</td>\n      <td>0.464741</td>\n      <td>0.460853</td>\n      <td>1.000000</td>\n      <td>0.374044</td>\n      <td>-0.507787</td>\n      <td>0.236216</td>\n    </tr>\n    <tr>\n      <th>LSTAT</th>\n      <td>0.452220</td>\n      <td>-0.412995</td>\n      <td>0.603800</td>\n      <td>-0.053929</td>\n      <td>0.590879</td>\n      <td>-0.613808</td>\n      <td>0.602339</td>\n      <td>-0.496996</td>\n      <td>0.488676</td>\n      <td>0.543993</td>\n      <td>0.374044</td>\n      <td>1.000000</td>\n      <td>-0.737663</td>\n      <td>0.468146</td>\n    </tr>\n    <tr>\n      <th>MEDV</th>\n      <td>-0.385832</td>\n      <td>0.360445</td>\n      <td>-0.483725</td>\n      <td>0.175260</td>\n      <td>-0.427321</td>\n      <td>0.695360</td>\n      <td>-0.376955</td>\n      <td>0.249929</td>\n      <td>-0.381626</td>\n      <td>-0.468536</td>\n      <td>-0.507787</td>\n      <td>-0.737663</td>\n      <td>1.000000</td>\n      <td>-0.289750</td>\n    </tr>\n    <tr>\n      <th>AGE_50</th>\n      <td>0.254574</td>\n      <td>-0.590769</td>\n      <td>0.516001</td>\n      <td>0.088659</td>\n      <td>0.597644</td>\n      <td>-0.164465</td>\n      <td>0.870348</td>\n      <td>-0.673813</td>\n      <td>0.361191</td>\n      <td>0.381395</td>\n      <td>0.236216</td>\n      <td>0.468146</td>\n      <td>-0.289750</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "             CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\nCRIM     1.000000 -0.199458  0.404471 -0.055295  0.417521 -0.219940  0.350784   \nZN      -0.199458  1.000000 -0.533828 -0.042697 -0.516604  0.311991 -0.569537   \nINDUS    0.404471 -0.533828  1.000000  0.062938  0.763651 -0.391676  0.644779   \nCHAS    -0.055295 -0.042697  0.062938  1.000000  0.091203  0.091251  0.086518   \nNOX      0.417521 -0.516604  0.763651  0.091203  1.000000 -0.302188  0.731470   \nRM      -0.219940  0.311991 -0.391676  0.091251 -0.302188  1.000000 -0.240265   \nAGE      0.350784 -0.569537  0.644779  0.086518  0.731470 -0.240265  1.000000   \nDIS     -0.377904  0.664408 -0.708027 -0.099176 -0.769230  0.205246 -0.747881   \nRAD      0.622029 -0.311948  0.595129 -0.007368  0.611441 -0.209847  0.456022   \nTAX      0.579564 -0.314563  0.720760 -0.035587  0.668023 -0.292048  0.506456   \nPTRATIO  0.288250 -0.391679  0.383248 -0.121515  0.188933 -0.355501  0.261515   \nLSTAT    0.452220 -0.412995  0.603800 -0.053929  0.590879 -0.613808  0.602339   \nMEDV    -0.385832  0.360445 -0.483725  0.175260 -0.427321  0.695360 -0.376955   \nAGE_50   0.254574 -0.590769  0.516001  0.088659  0.597644 -0.164465  0.870348   \n\n              DIS       RAD       TAX   PTRATIO     LSTAT      MEDV    AGE_50  \nCRIM    -0.377904  0.622029  0.579564  0.288250  0.452220 -0.385832  0.254574  \nZN       0.664408 -0.311948 -0.314563 -0.391679 -0.412995  0.360445 -0.590769  \nINDUS   -0.708027  0.595129  0.720760  0.383248  0.603800 -0.483725  0.516001  \nCHAS    -0.099176 -0.007368 -0.035587 -0.121515 -0.053929  0.175260  0.088659  \nNOX     -0.769230  0.611441  0.668023  0.188933  0.590879 -0.427321  0.597644  \nRM       0.205246 -0.209847 -0.292048 -0.355501 -0.613808  0.695360 -0.164465  \nAGE     -0.747881  0.456022  0.506456  0.261515  0.602339 -0.376955  0.870348  \nDIS      1.000000 -0.494588 -0.534432 -0.232471 -0.496996  0.249929 -0.673813  \nRAD     -0.494588  1.000000  0.910228  0.464741  0.488676 -0.381626  0.361191  \nTAX     -0.534432  0.910228  1.000000  0.460853  0.543993 -0.468536  0.381395  \nPTRATIO -0.232471  0.464741  0.460853  1.000000  0.374044 -0.507787  0.236216  \nLSTAT   -0.496996  0.488676  0.543993  0.374044  1.000000 -0.737663  0.468146  \nMEDV     0.249929 -0.381626 -0.468536 -0.507787 -0.737663  1.000000 -0.289750  \nAGE_50  -0.673813  0.361191  0.381395  0.236216  0.468146 -0.289750  1.000000  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Suppose you just wanted to look at the correlations between all of the columns and just one variable? Let's examine just the correlation between all other variables and the median value of the homes (MEDV). We will do this by accessing the column by index number:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "corr = df.corr(method='pearson') # compute the corelation of every other variable\ncorr_with_homevalue = corr.iloc[-2]\ncorr_with_homevalue[corr_with_homevalue.argsort()[::-1]]\n# we'll sort them from highest to lowest, which of my attributes are corelated/contribute the most to the price of the home?\n# size of the house - it will be pricier, no matter in which neighborhood",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 32,
          "data": {
            "text/plain": "MEDV       1.000000\nRM         0.695360\nZN         0.360445\nDIS        0.249929\nCHAS       0.175260\nAGE_50    -0.289750\nAGE       -0.376955\nRAD       -0.381626\nCRIM      -0.385832\nNOX       -0.427321\nTAX       -0.468536\nINDUS     -0.483725\nPTRATIO   -0.507787\nLSTAT     -0.737663\nName: MEDV, dtype: float64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "corr = df.corr(method='pearson')\ncorr_with_homevalue = corr.iloc[-1]\ncorr_with_homevalue[corr_with_homevalue.argsort()[::-1]]\n\n# let's look at the big negative correlations\n# in areas where the socio-economic income is low, the price goes down\n# on the other hand, living next to the river doesn't matter much",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "AGE_50     1.000000\nAGE        0.870348\nNOX        0.597644\nINDUS      0.516001\nLSTAT      0.468146\nTAX        0.381395\nRAD        0.361191\nCRIM       0.254574\nPTRATIO    0.236216\nCHAS       0.088659\nRM        -0.164465\nMEDV      -0.289750\nZN        -0.590769\nDIS       -0.673813\nName: AGE_50, dtype: float64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "With the correlations arranged in descending order, it's easy to start to see some patterns. Correlating AGE with a variable we created from AGE is a trivial correlation. However, it is interesting to note that the percentage of older housing stock in communities strongly correlates with air pollution (NOX) and the proportion of non-retail business acres per town (INDUS); at least in 1978 metro Boston, older towns are more industrial.\n\nGraphically, we can see the correlations using a heatmap from the Seaborn library:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline\nimport seaborn as sns\nimport numpy as np\nsns.set(rc={'figure.figsize':(11, 8)})\n# Generate a mask for the upper triangle / values above the identity diagonal\n# Remove use of the mask below to see the \"whole\" heatmap\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(corr, cmap='coolwarm', annot=True, mask=mask);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Histograms are another valuable tool for investigating your data. For example, what is the overall distribution of prices of owner-occupied houses in the Boston area?"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nplt.hist(df['MEDV'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The default bin size for the matplotlib histogram (essentially big of buckets of percentages that you include in each histogram bar in this case) is pretty large and might mask smaller details. To get a finer-grained view of the AGE column, you can manually increase the number of bins in the histogram:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "plt.hist(df['MEDV'], bins=50);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Seaborn has a somewhat more attractive version of the standard matplotlib histogram: the distribution plot. This is a combination histogram and kernel density estimate (KDE) plot (essentially a smoothed histogram):"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sns.distplot(df['MEDV'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Another commonly used plot is the Seaborn jointplot, which combines histograms for two columns along with a scatterplot:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sns.jointplot(df['RM'], df['MEDV'], kind='scatter') # we see that most homes have 6 rooms and are worth 20k",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Unfortunately, many of the dots print over each other. You can help address this by adding some alpha blending, a figure that sets the transparency for the dots so that concentrations of them drawing over one another will be apparent:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sns.jointplot(df['RM'], df['MEDV'], kind='scatter', alpha=0.3) ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Another way to see patterns in your data is with a two-dimensional KDE plot. Darker colors here represent a higher concentration of data points:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sns.kdeplot(df['RM'], df['MEDV'], shade=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Note that while the KDE plot is very good at showing concentrations of data points, finer structures like linear relationships (such as the clear relationship between the number of rooms in homes and the house price) are lost in the KDE plot.\n\nFinally, the pairplot in Seaborn allows you to see scatterplots and histograms for several columns in one table. Here we have played with some of the keywords to produce a more sophisticated and easier to read pairplot that incorporates both alpha blending and linear regression lines for the scatterplots."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sns.pairplot(df[['RM', 'AGE', 'LSTAT', 'DIS', 'MEDV']], kind=\"reg\", plot_kws={'line_kws':{'color':'red'}, 'scatter_kws': {'alpha': 0.1}})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Visualization is the start of the really cool, fun part of data science. So play around with these visualization tools and see what you can learn from the data!\n\n> **Takeaway:** An old joke: “What does a data scientist seen when they look at a dataset? A bunch of numbers.” There is more than a little truth in that joke. Visualization is often the key to finding patterns and correlations in your data. While visualization cannot often deliver precise results, it can point you in the right direction to ask better questions and efficiently find value in the data."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# you can't understand your data just by looking at numbers\n# you should use plots to visualise your data",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}