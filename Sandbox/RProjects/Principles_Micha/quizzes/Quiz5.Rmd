---
title: "Quiz5"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE, warning=FALSE}

#When launching R, run this line to load the tinytex package
library(tinytex)

#Run to generate document including embedded R code and its outputs:
knitr::opts_chunk$set(echo = TRUE)
```

# Question 1:

The Ministry of Finance decided that the salary (in shekels) in the public service in 2020 will behave according to the $X \sim LogNormal(8,1^2)$ distribution. According to this model, what is the probability that a person will earn less than 10,000 NIS? Answer to the nearest 2 decimal places.

$$
  X \sim LogNormal(8,1^2) \Leftrightarrow log(X) \sim Normal(8,1^2) \\
  \text {We want to find } P[X \le 10,000]
$$

$$
\begin{align*}
  & = P \Bigr[ log(X) \le log(10,000)\Bigr] 
    = P \Bigr[Y\le log(10,000)\Bigr] \\
  & = P\biggr[\frac{log(X)-\mu}{\sigma} \le 
            \frac{log(10,000)-8}{\sqrt[]{1^2}}\biggr]
    = P \Bigr[ Z \le log(10,000)-8 \Bigr] \\
  & = \phi \Bigr[ log(10,000)-8 \Bigr] 
  = pnorm \Bigr[ log(10,000)-8 \Bigr]
\end{align*}
$$

```{r q1, echo=FALSE}
pnorm(log(10000)-8) #P[X≤x]
```

# Question 2:

Suppose I sampled one observation from the distribution $U(0,\theta)$. The observation value is estimated to $\theta$. Calculate what is the average squared error (MSE) of this estimator if we were told that $\theta=6$? Answer with one decimal place.

# Question 3:

Let $X$ be a random variable with mean $\mu$ and variance $\sigma^2$.

For a random sample of size $n=4$, the following estimator for $\mu$ was proposed: $T=\frac{1}{n+1}\displaystyle\sum_{i=1}^{n} X_i$.

Let: $\tilde{T} = a \cdot {T}$

Find $a$ for which $\tilde{T}$ is an unbiased estimator.

Answer to the nearest 2 decimal places.

## Solution

Note: see question 3b in solved exercises for week 5.

Let $X_1,X_2,\dots, X_n \sim F_{_{T}} \\ \overline{X}=\mu \\ var(X) = {\sigma}^2$ .

$$
  \hat T= \frac{1}{n+1} \displaystyle\sum_{i=1}^{n} X_i
  = \frac{1}{n+1}X_1 + \frac{1}{n+1}X_2 + \dots + \frac{1}{n+1}X_n
$$

The bias of estimator $\hat T$ is defined as the distance of the estimator's expectancy $E(\hat T)$ from the real parameter $T$:

$$
\begin{align*}
  & \tilde T = f(\hat T) = \hat T \cdot a\\ \Rightarrow
  &bias(\tilde T)\\
  &= \tilde T - \overline X\\
  &= \hat T \cdot a - \mu\\
  &= \frac{1}{n+1} \displaystyle\sum_{i=1}^{n} X_i 
      \cdot a - \mu \\
  &= \displaystyle\sum_{i=1}^{n} X_i 
      \cdot \frac{1}{n} - \mu \\
  &= \overline{X} - \mu \\
  &= \mu - \mu 
\end{align*}
$$


```{r q3, echo=FALSE}
pnorm(log(10000)-8) #P[X≤x]
```

# Question 4:

There will be $X_1,X_2,...,X_n\sim N(\mu,\sigma^2)$ independent random variables. Calculate the mean square error of maximum visibility estimator for $\mu$ if you know that $\mu=10,\sigma^2=5^2,n=56$. Answer to the nearest two digits after the period.

Based on the notes from Tirgul 4, we know that for Normal distribution: 
$$
\begin{align*}

&\text{To calculate the Mean Squared Error we will use the formula:} \\
&MSE(\hat \mu)
  = Var(\hat \mu) + b^2(\hat \mu)
  = E^2[\hat \mu - E(\mu)] + {[E(\hat \mu) - \mu]}^2 \\
  
&\\ &\text{Using the Maximum Likelihood method for a Normal distr. gives:} \\

&\hat \mu = \overline {X}_n \\
&\hat {\sigma}^2 = \frac{1}{n} \cdot 
  \sum_{i=1}^{n} {(x_{i} - \overline {x}_n)}^2 \\

&\\ &\text{And specifically it is given that:} \ \mu = 10 \\

&\Rightarrow
  E^2[\overline {X}_n - E(10)] + {[E(\overline {X}_n) - 10]}^2 \\
&\overset{*}{=} E^2[\overline {X}_n - 10] + {[10 - 10]}^2 \\

&\rule{10cm}{0.4pt}

&\\ 
&\\ &\overset{*}{}
  \text{ Detailed explanation for } E[\overline {X}_n]=10.\\

&\quad \text{Step A: expectancy is linear.} \\
&\qquad E[\overline {X}_n]
= E\Bigr[ \frac{1}{n} \cdot \sum_{i=1}^{n} {(x_{i})} \Bigr] 
= \frac{1}{n} \cdot E\Bigr[\sum_{i=1}^{n} {(x_{i})} \Bigr]\\

&\quad \text{Step B: expectancy of a sum is the sum of expectancies.} \\
&\qquad \qquad \quad 
= \frac{1}{n} \cdot \Bigr[\sum_{i=1}^{n} {E(x_{i})} \Bigr]
= \frac{1}{n} \cdot n \cdot \mu = \mu = 10

\end{align*}

$$

# Question 5:

Let $X_1,X_2,...,X_n$ be a random sample of size $n=82$ from the distribution $U(\theta,19)$. Find the variance of the Moments Method estimator for $\theta$ assuming that $\theta=5$. Answer to two decimal places.

$$
\begin{align*}

&\text{Using the method of Moments for a cont. Uniform distr. gives: }
  \ \hat{\theta} = 2 \overline {x}_n.

&\\ &\\ &Variance(\hat{\theta})
  = Var(2\overline {x}_n)
  = 4 \cdot Var(\overline {x}_n) \\
&= 4 \cdot Var\Bigr[\frac{1}{n} \sum_{i=1}^{n} {x_{i}} \Bigr]
  = \frac{4}{n^2} \cdot Var \Bigr[ \sum_{i=1}^{n} {x_{i}} \Bigr]


&\\ &\\ &\textrm{var}(\widehat{\theta})
  = E\left[\Bigr(\widehat{\theta} 
    - E(\widehat{\theta}) \Bigr) ^2\right] \\
  &= E\left[\Bigr(2 \overline {x}_n
    - E(2 \overline {x}_n) \Bigr) ^2\right] \\
  &= E\left[\Bigr(2 \frac{1}{n} \sum_{i=1}^{n} {x_{i}}
    - E(2 \frac{1}{n} \sum_{i=1}^{n} {x_{i}}) \Bigr) ^2\right] \\
  &= E\left[\Bigr(2 \frac{1}{n} \sum_{i=1}^{n} {x_{i}}
    - \frac{2^2}{n^2} \cdot  \Bigr( \sum_{i=1}^{n} {E(x_{i})} \Bigr) ^2\right]

\end{align*}

$$


# Question 6:

$X$ is a random variable with span $\mu$ and variance $1$. Based on a random sample of size 4: $X_1, X_2, X_3, X_4$ ($X_i$ are independent and have the same distribution as $X$) Three estimators for $\mu$ have been proposed: $\hat{\mu_1}=0.4X_1+0.4X_2+0.4X_3+0.4X_4$ $\hat{\mu_2}=1/4X_1+1/4X_2+1/4X_3+1/4X_4+0.3$ $\hat{\mu_3}=1/3X_1+1/3X_2+1/3X_3$

# Question 7:

Let X be a random variable that takes values on the entire line according to the following density: 
$$ 
f(x) = \begin{cases}
       {1- \theta + \frac{\theta}{\sqrt{2\Pi}}e^{-0.5x^2},} &\quad{0 \leq x \leq 1 }\\
       {\frac{\theta}{\sqrt{2\Pi}}e^{-0.5x^2},} &\quad
       {O.W} \\
          \end{cases}
$$
Let T be the estimator of the moments for \theta. What is the bias of the estimator T equal if it is known that \theta=0.8

# Question 8:

Let $X_1,X_2,...X_{50}$ be a sample from the binomial distribution $B(k,p)$, assume that $k$ is constant and $p$ is an unknown parameter. What is the variance of the maximum likelihood estimator for $p$? Choose one answer: $$
A. \ \ \frac{1}{k^2}p(1-p); \ \
B. \frac{50}{k^2}p(1-p); \ \
C. \frac{(1-p)}{50p^2}; \ \
D. \frac{p(1-p)}{50k}
$$

# Question 9:

Let $X_1,X_2,...,X_n$ be a random sample of size $n$ from the distribution $U(\theta,19)$. Find the variance of the torque estimator for $\theta$.

# Question 10:

We have a random sample of size 19 from a normal distribution $N(\mu,\mu^2)$ (the expectation is equal to the standard deviation). We are interested in an estimator for the unknown parameter $\mu$ of the form $\hat{\mu}=a\bar{X}$. What is a for which the estimator has minimum mean square deviation? Answer with two digits after the decimal point.

$$X_{1}, X_{2}, X_{3}, ...., X_{n}\sim {\ Exp(\lambda)}
\\ L(\lambda) = \prod_{i = 1}^{n} f_\lambda(X_i)=
\lambda^n \ e^{-\lambda \ \sum_{i=1}^{n} (X_{i})}
\\\hat{\lambda} = \displaystyle \frac{1}{\overline{X}}=\displaystyle \frac{n}{\sum_{i=1}^{n} (X_{i})}
$$

According to the given data: $$
X_{1}, X_{2}, X_{3}\sim {\ Exp(\lambda)}\\
\hat\lambda = 
\displaystyle \frac{1}{\overline{X}}=
\displaystyle \frac{1}{\frac{1}{n} \sum_{i=1}^{n} (X_{i})}=
\displaystyle \frac{n}{\sum_{i=1}^{n} (X_{i})}
\\ \Rightarrow
\frac{1}{\frac{1}{3} \sum_{i=1}^{3} (X_{i})}=
\displaystyle \frac{3}{\sum_{i=1}^{3} (X_{i})}=
\displaystyle \frac{3}{X_{1}+ X_{2}+ X_{3}}=
\frac{3}{6.4+6+1.4}=13.8
$$ \newpage

# Question 2: extracting continuous U() parameter using Method of Moments

$$Y_{cont.} \sim U(0, \theta)$$

# Question 3: extracting continuous U() parameter using Max Likelihood

    \documentclass[12pt]{amsmath}
    \usepackage{amsmath}
    \begin{document}
    \begin{gather*}
    c \colon \{1, \dots, n\} \rightarrow \ {1, \dots, n\} \text{such that}\\
    \begin{cases}
    \end{cases}
    \end{gather*}
    \end{document}

$$Y_{cont.} \sim U(0, \theta)
\begin{equation*}
\\I_{(0, \theta)}(X_i)= \left\{
\begin{array}{rl}
1 & \text{if } x < 0,\\
0 & \text{if } x > 0.
\end{array} \right.
\end{equation*}
$$

Function of maximum likelihood for cont. uniform distr. $$
\\L(\theta)=\prod_{i = 1}^{n} f_\theta(X_i) \ I_{(0, \theta)}(X_i)=
\prod_{i = 1}^{n}\displaystyle \frac{1}{\theta - 0}I_{(0, \theta)}(X_i)
= \displaystyle \frac{1}{\theta^n} \prod_{i = 1}^{n} I_{(0, \theta)}(X_i) 
$$ $$
f_\theta(X_i) = e^{-(X-\theta)}\dot \ I_{x \geq \theta}(X_i), \ \ \theta>0$$ Because $L(\theta)$ is a fraction, when the estimator $\hat\theta$ is at its lowest value, we get that $L(\theta)$ is at its maximal value. Therefore, we'll select the minimal bound for $\theta$, which in continuous uniform distribution we know it equals to $max[X_i] = 8.2$.

According to the given data & using the Max Likelihood for a continuous Uniform distribution: $$X_{1}, X_{2}, X_{3}\sim {\ U(0, \theta)}\\
\\ \Rightarrow \hat\theta = max_{x_i}=8.2
$$

# Question 4: extracting cont. Normal distr. param using Max Likelihood

According to the given data & using the Max Likelihood for a continuous Uniform distribution: $$X_{1}, X_{2}, X_{3}\sim {\ Norm(\mu , \sigma^2)}\\
\\ \Rightarrow \overline{X} = \frac{1}{X_{1}+ X_{2}+ X_{3}} = = 
\frac{1}{2+3+6} = \frac{1}{11}
\\ \Rightarrow \hat{\sigma^2} = 
\frac{1}{n} \sum_{i=1}^{n} (X_{i}-\overline{X})^2 =
\frac{1}{3}[(2-\frac{1}{11})^2 + (3-\frac{1}{11})^2 + (6-\frac{1}{11})^2]=
\frac{5690}{363} \approx 15.67
$$

# Quesion 5

$$ f(x;\theta)={e^{-(x-\theta)}}\dot \ I_{x \geq 0}$$ Seeing as we are given that $\theta>0$, and according to the condition of the indicator $x\geq\theta$ we understand that the above function will produce a result only if $x\geq\theta>0$. In other words, $X_i$ is the upper-bound of $\theta$. Looking at our given density function, we realize that it is a **negative** exponential, which grows as $(x-\theta)$ decreases. The smaller the value of x, the bigger the function's value will be. Therefore

# Question 6

$$
f(x;\theta >0)=\frac {3x^2}{2\theta ^3}\cdot I_{\{-\theta \leq x\leq \theta \}}
\\L(\theta)= \prod_{i = 1}^{n}\frac {3x^2}{2\theta ^3}\cdot I \ ,\ where \ I_{\{-\theta \leq x\leq \theta \}}
\\l_e(\theta)=
log[{\prod_{i = 1}^{n}\frac {3x_{i}^2}{2\theta ^3}\cdot I}]=
\sum_{i=1}^{n} ({log{\frac {3x_{i}^2}{2\theta ^3}\cdot  I}})=
\\\text{if }  \ \hat\theta=max(X_i) 
\\\text{if }  \ \hat\theta=min(X_i) 
\\\text{if }  \ \hat\theta=max(|X_i|) 
\\\text{if }  \ \hat\theta=|max(X_i) |
$$ #Question 7 $$f(x;\theta)=\frac {3}{4\theta ^3}(\theta +x)(\theta -x)\cdot I_{\{-\theta \leq x\leq \theta \} }
\\I_x=1, \ -\theta \leq x\leq \theta \Leftrightarrow x\leq |\theta|
\\f(x)=\frac {3}{4\theta ^3}(\theta^2 -x^2)\cdot I
=(\frac {3}{4\theta}-\frac {3x^2}{4\theta^3})\cdot I
$$

We'll calculate the first moment $E(X)$ for the given range of $x$: $$
\\I_x=1, \ -\theta \leq x\leq \theta
\\ \Rightarrow E(X)= \int_{x} x \cdot f(x)= 
\int_{{-\theta}}^{\theta} [(\frac {3}{4\theta}-\frac{3x^2}{4\theta^3}) \cdot I] \,dx=
\int_{{-\theta}}^{\theta} [(\frac {3}{4\theta}-\frac{3x^2}{4\theta^3}) \cdot 1] \,dx
\\ = \frac {3}{4\theta}\biggl[x\biggr]_{-\theta}^{\theta} -
\frac{3}{8\theta}\biggl[x^3\biggr]_{-\theta}^{\theta}
\ = \frac {3}{4\theta}\biggl[2\theta\biggr] -
\frac{3}{8\theta}\biggl[2\theta^3\biggr]
\ = 1.5 - 0.75\theta^2
$$

#Question 8

```{r}
 x <- c(1.18,1.29,0.49,0.19,1.57,3.13,1.61,0.92,0.42,4.48,0.91,0.05,0.11, 0.68,0.76,1.89,3.09,4.83,1.53,1.94,1.32,0.08,1.29,0.06,0.63,0.25, 1.93,1.01,0.01,0.78)
```

$$
X_{1}, X_{2}, \dots, X_{30}\sim {\ Exp(\lambda)}\\
F_x(X)= 1-e^{-\lambda x}\\
\hat\lambda = 
\displaystyle \frac{1}{\overline{X}}
$$ Let's calculate using R:

```{r, echo=FALSE}
lambda <- 1/mean(x)
```

$$F_x(X)= 1-e^{-0.78 x}
\\ \Rightarrow P(X \geq 2)=1-F_x(2)=1-e^{-0.78 \cdot2}
$$ We'll calculate using R:

```{r, echo=FALSE}
pexp(q=2, rate=lambda, lower.tail = FALSE)
```

#Question 9

```{r}
y <- c(1,1,4,3,2,3,0,4,6,7)
```

$$
X_{1}, X_{2}, \dots, X_{30}\sim {\ Pois(\alpha)}\\
\hat\alpha = {\overline{X}}=\sum_{i=1}^{10}X_i
$$ Let's calculate using R:

```{r}
lambda <- 1/mean(y)
```

$$F_x(X)= 1-e^{-0.78 x}
\\ \Rightarrow P(X \geq 2)=1-F_x(2)=1-e^{-0.78 \cdot2}
$$ We'll calculate using R:

```{r}
ppois(q=2, lambda=lambda, lower.tail = FALSE)
```

# Question 10

$$ f(x;\theta)={\theta^4 x^3 e^{-\theta x}}\dot \ I_{x>0}\dot \ C$$
