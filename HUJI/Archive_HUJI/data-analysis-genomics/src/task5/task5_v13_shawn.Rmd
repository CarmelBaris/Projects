---
title: "Lab Task 4: Approx. Regression w/ Piecewise Polynomial Model"
author: "Group 6"
date: Sys.Date()
output:
  html_document:
    code_folding: show
editor_options: 
  markdown: 
    wrap: sentence
---

Group members:

- Shawn Yakir , 315714980, shawnyakir@gmail.com
- Sarah Levitz, 324673623, sarah.levitz@mail.huji.ac.il
- Carmel Baris, 318455276, carmel.baris@mail.huji.ac.il 


## Libraries

```{r library, message=FALSE, warning=FALSE}
library(segmented)
library(data.table)
library(splines)
```

## Setting up environment & paths
```{r setup}
## ------------------------------------------------
## ---- DEPENDENCIES AKA FILES REQUIRED
## Make sure that all files are in the current working directory:
## 1. chr1_bases.rda
## 2. TCGA-13-0723-01A_lib2_all_chr1.forward
## 3. helpers_file
## 
## Note that in this lecture we'll create and save a new file:
## 4. reads_gc_20K.rda


## ------------------------------------------------
## ---- CLEAN ENVIRONMENT
rm(list = ls())


## ---- SET WORKING DIRECTORY
# dir_name = "\\Users\\shawn\\Desktop\\"
dir_name = "~/Carmel/RProjects/Lab_Benjamini/data/"

chr1_reads=file.path(dir_name, "TCGA-13-0723-01A_lib2_all_chr1.forward")


# dir_name = "/Users/alevi/Downloads/"
# setwd(dir_name)
# getwd() # validate


## ------------------------------------------------
## ---- LOAD HELPER FUNCTIONS
helpers_file = file.path(dir_name, "help_funcs.R")
source(helpers_file)
helpers <- list(
    loadRData = loadRData,
    fitMet = fitMetrics,
    binBases = binBases)

```

## Loading data files 

```{r warning=FALSE}

## ------------------------------------------------
## ---- LOAD FILE OF NUCLEO_BASES (A,T,C,G)
bases_file = file.path(dir_name, "chr1_line.rda")
chr1_bases = helpers$loadRData(bases_file) # like Lecture1


## ------------------------------------------------
## ---- LOAD FILE OF READS LOCATIONS (THAT START A FRAGMENT)
  
reads_file_all = file.path(dir_name,"TCGA-13-0723-01A_lib2_all_chr1.forward")
chr1_reads = data.table::fread(reads_file_all) #like Lecture2
colnames(chr1_reads) = c("Chrom","Loc","FragLen")   


```


## Preprocessing data 

```{r message=FALSE, warning=FALSE}

## chunk should not have eval = FALSE!!
## o/w it messes up GC_20K

nreads = nrow(chr1_reads)
myLocations = as.numeric(chr1_reads$Loc)
last_read = myLocations[nreads]

binsize = 20000

## ------------------------------------------------
## ---- BINNING NUCLEO_BASES DATA
##
# per bin, count occurrences of each letter
bases_20K = binBases(chr1_bases, last_read, binsize) 

# per bin, sum occurrence counts of C & G only (GC content)
GC_20K <<- bases_20K[, 3] + bases_20K[, 4] #store as global variable

# convert GC_20K into percentages
if(any(GC_20K>1)){ # This makes sure I don't repeat the command
  GC_20K = GC_20K / binsize
}

## ------------------------------------------------
## ---- BINNING READS COVERAGE DATA

# per bin, calculate reads coverage 
reads_20K = binReads(myLocations,binsize,last_read)
save(reads_20K, GC_20K,file = file.path(dir_path=dir_name,"reads_gc_20K.rda"))


## ------------------------------------------------
## ---- CLEARING UP ENV
rm("chr1_bases","chr1_reads") # remove from memory

# load data
reads_file_20K = file.path(dir_name, "reads_gc_20K.rda")
reads_gc_20K = helpers$loadRData(reads_file_20K)
# access using `$`:
#   GC_20K = reads_gc_20K$GC_20K
#   reads_20K = reads_gc_20K$reads_20K


```







```{r fit}
GC_20K_clean <- GC_20K[GC_20K != 0]
zero_GC_indices <- which(GC_20K == 0)
reads_20K_clean <- reads_20K[-zero_GC_indices]

z_scores <- abs(scale(GC_20K_clean))

# Identify outliers based on z-score threshold of 2
outliers <- which(z_scores > 2)

# Extract outliers
GC_outliers <- GC_20K[outliers]
reads_outliers <- reads_20K[outliers]

# Create boxplot and store the stats
bp <- boxplot(reads_20K_clean, main = "Boxplot of Reads Count",
              ylab = "Reads Count", col = "lightblue", border = "blue",
              ylim = c(0, 3000))

# Extract stats from boxplot
stats <- boxplot.stats(reads_20K_clean)$out

# Label outliers on the boxplot
points(rep(1, length(stats)), stats, col = "red", pch = 19)


# Add red points for outliers on the boxplot
points(outliers, reads_outliers, col = "red", pch = 19, )


outliers <- bp$out

# Plot GC_20K_clean against reads_20K
plot(GC_20K_clean, reads_20K_clean, ylim = c(0, 3000), cex = 0.5,
     xlab = "GC Content", ylab = "Reads Count", main = "GC Content vs. Reads Count")

# Mark outliers with red color
points(GC_20K_clean[which(reads_20K_clean %in% outliers)], reads_20K_clean[which(reads_20K_clean %in% outliers)], col = "red", pch = 19)

# Add legend
legend("topright", legend = "Outliers", col = "red", pch = 19)


```




```{r outliers}

# Defining logical vectors for filtering out bins (observations)

# outliers of gc percent per bin
zeros_GC = GC_20K == 0 #bins w/o GC content
small_GC = GC_20K <= 0.3 & GC_20K > 0 #low-GC content bins (<30%)
valid_GC = GC_20K  > 0.3 #bins w/ at least 30% GC content

# outliers of reads count per bin
mean_reads = mean(reads_20K)
sd_reads = sd(reads_20K)
lwr = mean_reads - 2 * sd_reads
upr = mean_reads + 2 * sd_reads
normal_reads = (lwr <= reads_20K & reads_20K <= upr)
xtreme_reads = !normal_reads

# create new variables without outliers
outliers = (zeros_GC | small_GC | xtreme_reads)
reads_20K_clean = reads_20K[!outliers]
GC_20K_clean = GC_20K[!outliers]


```













## Q1: 

```{r fit}
set.seed(100)

# Division 1: Data into 20 parts and randomly assigning 14 parts to train
n_bins <- length(reads_20K)
bins_per_group <- n_bins %/% 20  # Integer division to get bins per group
extra_bins <- n_bins %% 20       # Remainder to ensure equal-sized groups

# Distribute extra bins (if any) across the groups
group_sizes <- rep(bins_per_group, 20)
if (extra_bins > 0) {
  group_sizes[1:extra_bins] <- group_sizes[1:extra_bins] + 1
}

# Create the 20 groups
groups <- split(1:n_bins, rep(1:20, group_sizes))

# Randomly select 14 groups for training and 6 for testing
train_indices_div1 <- sample(1:20, 14)
test_indices_div1 <- setdiff(1:20, train_indices_div1)

# Create logical vectors for Division 1
train_logical_div1 <- rep(FALSE, n_bins)
test_logical_div1 <- rep(FALSE, n_bins)

train_logical_div1[unlist(groups[train_indices_div1])] <- TRUE
test_logical_div1[unlist(groups[test_indices_div1])] <- TRUE

# Division 2: Completely random division (70% train, 30% test)
n_samples <- length(reads_20K)
train_indices_div2 <- sample(1:n_samples, 0.7 * n_samples)
test_indices_div2 <- setdiff(1:n_samples, train_indices_div2)

# Create logical vectors for Division 2
train_logical_div2 <- rep(FALSE, n_samples)
test_logical_div2 <- rep(FALSE, n_samples)

train_logical_div2[train_indices_div2] <- TRUE
test_logical_div2[test_indices_div2] <- TRUE

# Division 3: Regular division (first 70% train, last 30% test)
train_indices_div3 <- 1:floor(0.7 * n_samples)
test_indices_div3 <- (floor(0.7 * n_samples) + 1):n_samples

# Create logical vectors for Division 3
train_logical_div3 <- rep(FALSE, n_samples)
test_logical_div3 <- rep(FALSE, n_samples)

train_logical_div3[train_indices_div3] <- TRUE
test_logical_div3[test_indices_div3] <- TRUE

```



```{r}
# Subset data for each division
train_data_div1 <- data.frame(GC_20K = GC_20K_clean[train_logical_div1], reads_20K = reads_20K_clean[train_logical_div1])
train_data_div2 <- data.frame(GC_20K = GC_20K_clean[train_logical_div2], reads_20K = reads_20K_clean[train_logical_div2])
train_data_div3 <- data.frame(GC_20K = GC_20K_clean[train_logical_div3], reads_20K = reads_20K_clean[train_logical_div3])

# Define knots for the B-spline
knots_bs <- c(0.37, 0.415, 0.45, 0.54)

# Fit the B-spline model using the train data for each division
reg_bs_train_div1 <- lm(reads_20K ~ bs(GC_20K, knots = knots_bs, degree = 3, Boundary.knots = c(min(GC_20K_clean), max(GC_20K_clean))), data = train_data_div1)
reg_bs_train_div2 <- lm(reads_20K ~ bs(GC_20K, knots = knots_bs, degree = 3, Boundary.knots = c(min(GC_20K_clean), max(GC_20K_clean))), data = train_data_div2)
reg_bs_train_div3 <- lm(reads_20K ~ bs(GC_20K, knots = knots_bs, degree = 3, Boundary.knots = c(min(GC_20K_clean), max(GC_20K_clean))), data = train_data_div3)

# Create new data for prediction
new_data <- data.frame(GC_20K = seq(min(GC_20K_clean), max(GC_20K_clean), length.out = 1000))

# Predict for each division
predicted_div1 <- predict(reg_bs_train_div1, newdata = new_data)
predicted_div2 <- predict(reg_bs_train_div2, newdata = new_data)
predicted_div3 <- predict(reg_bs_train_div3, newdata = new_data)

# Plot the data and the B-spline regression lines for each division
plot(GC_20K_clean, reads_20K_clean, pch = 16, cex = 0.5, col = rgb(0, 0, 0, 0.7),
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     xlim = c(min(GC_20K_clean), max(GC_20K_clean)),
     ylim = c(0, max(reads_20K_clean)),
     main = "Piecewise Polynomial Regression")

# Plot the B-spline regression lines for each division
lines(new_data$GC_20K, predicted_div1, col = "blue", lwd = 2)
lines(new_data$GC_20K, predicted_div2, col = "red", lwd = 2)
lines(new_data$GC_20K, predicted_div3, col = "green", lwd = 2)

# Add vertical lines to indicate breakpoints
abline(v = knots_bs, lty = 2, col = "darkgray", lwd = 1.5)

# Add legend
legend("topleft", legend = c("B-spline Div 1", "B-spline Div 2", "B-spline Div 3"), col = c("blue", "red", "green"), lwd = 2, cex = 0.7)


```
     


```{r}
# Subset test data for each division
test_data_div1 <- data.frame(GC_20K = GC_20K_clean[test_logical_div1], reads_20K = reads_20K_clean[test_logical_div1])
test_data_div2 <- data.frame(GC_20K = GC_20K_clean[test_logical_div2], reads_20K = reads_20K_clean[test_logical_div2])
test_data_div3 <- data.frame(GC_20K = GC_20K_clean[test_logical_div3], reads_20K = reads_20K_clean[test_logical_div3])

# Predict for test data in each division
test_data_div1$predicted <- predict(reg_bs_train_div1, newdata = test_data_div1)
test_data_div2$predicted <- predict(reg_bs_train_div2, newdata = test_data_div2)
test_data_div3$predicted <- predict(reg_bs_train_div3, newdata = test_data_div3)

# Define a function to calculate R-squared, MAE, and MSE
calculate_metrics <- function(actual, predicted) {
  r_squared <- 1 - sum((actual - predicted)^2) / sum((actual - mean(actual))^2)
  mae <- mean(abs(actual - predicted))
  mse <- mean((actual - predicted)^2)
  return(list(R_squared = r_squared, MAE = mae, MSE = mse))
}

# Calculate metrics for train and test data in each division
metrics_train_div1 <- calculate_metrics(train_data_div1$reads_20K, predict(reg_bs_train_div1, newdata = train_data_div1))
metrics_test_div1 <- calculate_metrics(test_data_div1$reads_20K, test_data_div1$predicted)
metrics_train_div2 <- calculate_metrics(train_data_div2$reads_20K, predict(reg_bs_train_div2, newdata = train_data_div2))
metrics_test_div2 <- calculate_metrics(test_data_div2$reads_20K, test_data_div2$predicted)
metrics_train_div3 <- calculate_metrics(train_data_div3$reads_20K, predict(reg_bs_train_div3, newdata = train_data_div3))
metrics_test_div3 <- calculate_metrics(test_data_div3$reads_20K, test_data_div3$predicted)

# Print metrics
print(metrics_train_div1)
print(metrics_test_div1)
print(metrics_train_div2)
print(metrics_test_div2)
print(metrics_train_div3)
print(metrics_test_div3)



# Division 1
par(mfrow = c(1, 1))  # Reset to single plot
plot(train_data_div1$reads_20K,train_data_div1$GC_20K, pch = 16, cex = 0.5, col = rgb(0, 0, 1, 0.5),
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     xlim = c(min(GC_20K_clean), max(GC_20K_clean)),
     ylim = c(0, max(reads_20K_clean)),
     main = "Division 1: Piecewise Polynomial Regression")

lines(new_data$GC_20K, predicted_div1, col = "blue", lwd = 2)
points(test_data_div1$GC_20K, test_data_div1$reads_20K, pch = 16, cex = 0.5, col = rgb(1, 0, 0, 0.5))
points(test_data_div1$GC_20K, test_data_div1$predicted, pch = 16, cex = 0.5, col = rgb(0, 1, 0, 0.5))

legend("topleft", legend = c("Train Data", "Test Data Actual", "Test Data Predicted", "B-spline Fit"),
       col = c(rgb(0, 0, 1, 0.5), rgb(1, 0, 0, 0.5), rgb(0, 1, 0, 0.5), "blue"), lwd = 2, pch = 16, cex = 0.7)

# Division 2
plot(train_data_div2$GC_20K, train_data_div2$reads_20K, pch = 16, cex = 0.5, col = rgb(0, 0, 1, 0.5),
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     xlim = c(min(GC_20K_clean), max(GC_20K_clean)),
     ylim = c(0, max(reads_20K_clean)),
     main = "Division 2: Piecewise Polynomial Regression")

lines(new_data$GC_20K, predicted_div2, col = "red", lwd = 2)
points(test_data_div2$GC_20K, test_data_div2$reads_20K, pch = 16, cex = 0.5, col = rgb(1, 0, 0, 0.5))
points(test_data_div2$GC_20K, test_data_div2$predicted, pch = 16, cex = 0.5, col = rgb(0, 1, 0, 0.5))

legend("topleft", legend = c("Train Data", "Test Data Actual", "Test Data Predicted", "B-spline Fit"),
       col = c(rgb(0, 0, 1, 0.5), rgb(1, 0, 0, 0.5), rgb(0, 1, 0, 0.5), "red"), lwd = 2, pch = 16, cex = 0.7)

# Division 3
plot(train_data_div3$GC_20K, train_data_div3$reads_20K, pch = 16, cex = 0.5, col = rgb(0, 0, 1, 0.5),
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     xlim = c(min(GC_20K_clean), max(GC_20K_clean)),
     ylim = c(0, max(reads_20K_clean)),
     main = "Division 3: Piecewise Polynomial Regression")

lines(new_data$GC_20K, predicted_div3, col = "green", lwd = 2)
points(test_data_div3$GC_20K, test_data_div3$reads_20K, pch = 16, cex = 0.5, col = rgb(1, 0, 0, 0.5))
points(test_data_div3$GC_20K, test_data_div3$predicted, pch = 16, cex = 0.5, col = rgb(0, 1, 0, 0.5))

legend("topleft", legend = c("Train Data", "Test Data Actual", "Test Data Predicted", "B-spline Fit"),
       col = c(rgb(0, 0, 1, 0.5), rgb(1, 0, 0, 0.5), rgb(0, 1, 0, 0.5), "green"), lwd = 2, pch = 16, cex = 0.7)

```

## Till Here

```{r}



calculate_metrics <- function(actual, predicted) {
  # Remove NA values from actual and predicted
  actual <- actual[!is.na(actual)]
  predicted <- predicted[!is.na(predicted)]
  
  if (length(actual) != length(predicted)) {
    stop("Length of 'actual' and 'predicted' must be the same.")
  }
  
  n <- length(actual)
  
  if (n == 0) {
    stop("No valid data points to calculate metrics.")
  }
  
  # Calculate R-squared
  mean_actual <- mean(actual)
  ss_total <- sum((actual - mean_actual)^2)
  ss_residual <- sum((actual - predicted)^2)
  r_squared <- 1 - ss_residual / ss_total
  
  # Calculate MAE and MSE
  mae <- mean(abs(actual - predicted))
  mse <- mean((actual - predicted)^2)
  
  return(list(R_squared = r_squared, MAE = mae, MSE = mse))
}
# Calculate metrics for train and test data in each division
metrics_train_div1 <- calculate_metrics(train_data_div1$reads_20K, predict(reg_bs_train_div1, newdata = train_data_div1))
metrics_test_div1 <- calculate_metrics(test_data_div1$reads_20K, test_data_div1$predicted)
metrics_train_div2 <- calculate_metrics(train_data_div2$reads_20K, predict(reg_bs_train_div2, newdata = train_data_div2))
metrics_test_div2 <- calculate_metrics(test_data_div2$reads_20K, test_data_div2$predicted)
metrics_train_div3 <- calculate_metrics(train_data_div3$reads_20K, predict(reg_bs_train_div3, newdata = train_data_div3))
metrics_test_div3 <- calculate_metrics(test_data_div3$reads_20K, test_data_div3$predicted)

# Print metrics
print("Division 1 Train Metrics:")
print(metrics_train_div1)
print("Division 1 Test Metrics:")
print(metrics_test_div1)

print("Division 2 Train Metrics:")
print(metrics_train_div2)
print("Division 2 Test Metrics:")
print(metrics_test_div2)

print("Division 3 Train Metrics:")
print(metrics_train_div3)
print("Division 3 Test Metrics:")
print(metrics_test_div3)
```



```{r}
# Verify the dimensions of train_data_div3
print(dim(train_data_div3))

# Ensure there are no NA or infinite values in the relevant columns
train_data_div3 <- train_data_div3[complete.cases(train_data_div3$GC_20K, train_data_div3$reads_20K), ]
train_data_div3 <- train_data_div3[is.finite(train_data_div3$GC_20K) & is.finite(train_data_div3$reads_20K), ]

# Fit the B-spline model again with the cleaned train data
reg_bs_train_div3 <- lm(reads_20K ~ bs(GC_20K, knots = knots_bs, degree = 3, Boundary.knots = c(min(GC_20K_clean), max(GC_20K_clean))), data = train_data_div3)

# Predict for the cleaned train data
train_data_div3$predicted <- predict(reg_bs_train_div3, newdata = train_data_div3)

# Calculate residuals for the train data
train_data_div3$residuals <- train_data_div3$reads_20K - train_data_div3$predicted

# Calculate metrics for train data
metrics_train_div3 <- calculate_metrics(train_data_div3$reads_20K, train_data_div3$predicted)

# Print the metrics for train data
print(metrics_train_div3)

# Plot the residuals against GC content for the train data
plot(train_data_div3$GC_20K, train_data_div3$residuals, 
     pch = 16, cex = 0.5, col = rgb(1, 0, 0, 0.5),
     xlab = "GC Content (cleaned)", ylab = "Residuals",
     main = "Residuals vs GC Content (Train Data)")

# Plot the residuals against the predicted coverage for the train data
plot(train_data_div3$predicted, train_data_div3$residuals, 
     pch = 16, cex = 0.5, col = rgb(0, 0, 1, 0.5),
     xlab = "Predicted Coverage", ylab = "Residuals",
     main = "Residuals vs Predicted Coverage (Train Data)")


```


```{r}
# Ensure test_data_div3 has predicted values
test_data_div3$predicted <- predict(reg_bs_train_div3, newdata = test_data_div3)

# Calculate residuals for test data
test_data_div3$residuals <- test_data_div3$reads_20K - test_data_div3$predicted

# Plot residuals against GC content for test data
plot(test_data_div3$GC_20K, test_data_div3$residuals, 
     pch = 16, cex = 0.5, col = rgb(1, 0, 0, 0.5),
     xlab = "GC Content (cleaned)", ylab = "Residuals",
     main = "Residuals vs GC Content (Test Data)")

# Plot residuals against predicted coverage for test data
plot(test_data_div3$predicted, test_data_div3$residuals, 
     pch = 16, cex = 0.5, col = rgb(0, 0, 1, 0.5),
     xlab = "Predicted Coverage", ylab = "Residuals",
     main = "Residuals vs Predicted Coverage (Test Data)")
```

