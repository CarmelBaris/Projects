---
title: "Lab Task 4: Approx. Regression w/ Piecewise Polynomial Model"
author: "Group 6"
date: Sys.Date()
output:
  html_document:
    code_folding: show
editor_options: 
  markdown: 
    wrap: sentence
---

Group members:

- Shawn Yakir , 315714980, shawnyakir@gmail.com
- Sarah Levitz, 324673623, sarah.levitz@mail.huji.ac.il
- Carmel Baris, 318455276, carmel.baris@mail.huji.ac.il 


## Setup

```{r setup}

# Clean the environment
rm(list = ls())

# Load required packages
library('data.table')
library('splines')
library('ggplot2')

# Set working directory
# dir_name = "/Users/alevi/Downloads/"
dir_name = "~/Carmel/RProjects/Lab_Benjamini/data/"
# dir_name = "\\Users\\shawn\\Desktop\\"

# Load helper functions
helpers_file = file.path(dir_name, "help_funcs_v5.R")
source(helpers_file)
helpers = list(
    loadRData = loadRData,
    fitMet = fitMetrics,
    binBases = binBases,
    binReads = binReads,
    fit_bspline = fit_bspline
    )
# Load data
bases_file = file.path(dir_name, "chr1_line.rda")
chr1_bases = loadRData(bases_file)
reads_file_all = file.path(dir_name, "TCGA-13-0723-01A_lib2_all_chr1.forward")
chr1_reads = data.table::fread(reads_file_all)
colnames(chr1_reads) = c("Chrom", "Loc", "FragLen")

# Preprocess data
nreads = nrow(chr1_reads)
myLocations = as.numeric(chr1_reads$Loc)
last_read = myLocations[nreads]
binsize = 20000
bases_20K = binBases(chr1_bases, last_read, binsize)
GC_20K = bases_20K[, 3] + bases_20K[, 4]
GC_20K = GC_20K / binsize
reads_20K = binReads(myLocations, binsize, last_read)
save(reads_20K, GC_20K, file = file.path(dir_name, "reads_gc_20K.rda"))
```

```{r outliers}
# Defining logical vectors for filtering out bins (observations)

# outliers of gc percent per bin
zeros_GC = GC_20K == 0 #bins w/o GC content
small_GC = GC_20K <= 0.3 & GC_20K > 0 #low-GC content bins (<30%)
valid_GC = !(zeros_GC | small_GC) #bins w/ at least 30% GC content

# identify outliers of reads count per bin
z_scores = (reads_20K - mean(reads_20K)) / sd(reads_20K)
xtreme_reads = abs(z_scores) > 2

# create new variables without outliers
outliers = (zeros_GC | small_GC | xtreme_reads)
reads_20K_clean = reads_20K[!outliers]
GC_20K_clean = GC_20K[!outliers]
```

## QUESTION 1: 

```{r split}
# Set seed for reproducibility
set.seed(100)

# Division 1: Data into 20 parts and randomly assigning 14 parts to train
n_bins <- length(reads_20K_clean)  # Use the cleaned data
bins_per_group <- n_bins %/% 20  # Integer division to get bins per group
extra_bins <- n_bins %% 20       # Remainder to ensure equal-sized groups

# Distribute extra bins (if any) across the groups
group_sizes <- rep(bins_per_group, 20)
if (extra_bins > 0) {
  group_sizes[1:extra_bins] <- group_sizes[1:extra_bins] + 1
}

# Create the 20 groups
groups <- split(1:n_bins, rep(1:20, group_sizes))

# Randomly select 14 groups for training and 6 for testing
train_indices_div1 <- sample(1:20, 14)
test_indices_div1 <- setdiff(1:20, train_indices_div1)

# Create logical vectors for Division 1
train_logical_div1 <- rep(FALSE, n_bins)
test_logical_div1 <- rep(FALSE, n_bins)

train_logical_div1[unlist(groups[train_indices_div1])] <- TRUE
test_logical_div1[unlist(groups[test_indices_div1])] <- TRUE

# Division 2: Completely random division (70% train, 30% test)
n_samples <- length(reads_20K_clean)
train_indices_div2 <- sample(1:n_samples, 0.7 * n_samples)
test_indices_div2 <- setdiff(1:n_samples, train_indices_div2)

# Create logical vectors for Division 2
train_logical_div2 <- rep(FALSE, n_samples)
test_logical_div2 <- rep(FALSE, n_samples)

train_logical_div2[train_indices_div2] <- TRUE
test_logical_div2[test_indices_div2] <- TRUE

# Division 3
n_samples <- length(reads_20K_clean)
train_indices_div3 <- 1:floor(0.7 * n_samples)
test_indices_div3 <- (floor(0.7 * n_samples) + 1):n_samples

# Create logical vectors for Division 3
train_logical_div3 <- rep(FALSE, n_samples)
test_logical_div3 <- rep(FALSE, n_samples)

train_logical_div3[train_indices_div3] <- TRUE
test_logical_div3[test_indices_div3] <- TRUE

```


## Q1.b

```{r plot}
# Subset data for each division
train_data_div1 <- data.frame(GC_20K = GC_20K_clean[train_logical_div1], reads_20K = reads_20K_clean[train_logical_div1])

train_data_div2 <- data.frame(GC_20K = GC_20K_clean[train_logical_div2], reads_20K = reads_20K_clean[train_logical_div2])

train_data_div3 <- data.frame(GC_20K = GC_20K_clean[train_logical_div3], reads_20K = reads_20K_clean[train_logical_div3])

# Define knots for the B-spline
knots_bs = c(0.415, 0.45, 0.54)

# Fit the B-spline model using the train data from Group 1 (sub-grouped by location then randomly assigned)
reg_bs_train_div1 <- lm(reads_20K ~ bs(GC_20K, knots = knots_bs, degree = 3, Boundary.knots = c(min(GC_20K_clean), max(GC_20K_clean))), data = train_data_div1)

# Fit the B-spline model using the train data from Group 2 (Location-dependent)
reg_bs_train_div2 <- lm(reads_20K ~ bs(GC_20K, knots = knots_bs, degree = 3, Boundary.knots = c(min(GC_20K_clean), max(GC_20K_clean))), data = train_data_div2)

# Fit the B-spline model using the train data from Group 2 (randomly assigned)
reg_bs_train_div3 <- lm(reads_20K ~ bs(GC_20K, knots = knots_bs, degree = 3, Boundary.knots = c(min(GC_20K_clean), max(GC_20K_clean))), data = train_data_div3)

# Create new data for prediction
new_data <- data.frame(GC_20K = seq(min(GC_20K_clean), max(GC_20K_clean), length.out = 1000))

# Predict for each division
predicted_div1 <- predict(reg_bs_train_div1, newdata = new_data)
predicted_div2 <- predict(reg_bs_train_div2, newdata = new_data)
predicted_div3 <- predict(reg_bs_train_div3, newdata = new_data)
```


# Plot the data and the B-spline regression lines for each division

```{r train_viz}
# Plot the data and the B-spline regression lines for each division
plot(GC_20K_clean, reads_20K_clean, pch = 16, cex = 0.5, col = rgb(0, 0, 0, 0.7),
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     xlim = c(min(GC_20K_clean), max(GC_20K_clean)),
     ylim = c(0, max(reads_20K_clean)),
     main = "B-Spline Regression on Train Data")

# Plot the B-spline regression lines for each division
lines(new_data$GC_20K, predicted_div1, col = "blue", lwd = 2)
lines(new_data$GC_20K, predicted_div2, col = "red", lwd = 2)
lines(new_data$GC_20K, predicted_div3, col = "green", lwd = 2)

# Add vertical lines to indicate breakpoints
abline(v = knots_bs, lty = 2, col = "darkgray", lwd = 1.5)

# Add legend
legend("topleft", legend = c("Grouped Locally, Assigned Randomly (Div 1)", "By Location (Div 2)", "Totally Random (Div 3)"), col = c("blue", "red", "green"), lwd = 2, cex = 0.75, bty = "n")

```


```{r}
# Subset test data for each division
test_data_div1 <- data.frame(GC_20K = GC_20K_clean[test_logical_div1], reads_20K = reads_20K_clean[test_logical_div1])

test_data_div2 <- data.frame(GC_20K = GC_20K_clean[test_logical_div2], reads_20K = reads_20K_clean[test_logical_div2])

test_data_div3 <- data.frame(GC_20K = GC_20K_clean[test_logical_div3], reads_20K = reads_20K_clean[test_logical_div3])

# Predict for test data in each division
test_data_div1$predicted <- predict(reg_bs_train_div1, newdata = test_data_div1)

test_data_div2$predicted <- predict(reg_bs_train_div2, newdata = test_data_div2)

test_data_div3$predicted <- predict(reg_bs_train_div3, newdata = test_data_div3)

# Define a function to calculate R-squared, MAE, and MSE
calculate_metrics <- function(actual, predicted) {
  r_squared <- 1 - sum((actual - predicted)^2) / sum((actual - mean(actual))^2)
  mae <- mean(abs(actual - predicted))
  mse <- mean((actual - predicted)^2)
  return(list(R_squared = r_squared, MAE = mae, MSE = mse))
}

# Calculate metrics for train and test data in each division
metrics_train_div1 <- calculate_metrics(train_data_div1$reads_20K, predict(reg_bs_train_div1, newdata = train_data_div1))

metrics_test_div1 <- calculate_metrics(test_data_div1$reads_20K, test_data_div1$predicted)

metrics_train_div2 <- calculate_metrics(train_data_div2$reads_20K, predict(reg_bs_train_div2, newdata = train_data_div2))

metrics_test_div2 <- calculate_metrics(test_data_div2$reads_20K, test_data_div2$predicted)

metrics_train_div3 <- calculate_metrics(train_data_div3$reads_20K, predict(reg_bs_train_div3, newdata = train_data_div3))

metrics_test_div3 <- calculate_metrics(test_data_div3$reads_20K, test_data_div3$predicted)

# Print metrics
print(metrics_train_div1)
print(metrics_test_div1)
print(metrics_train_div2)
print(metrics_test_div2)
print(metrics_train_div3)
print(metrics_test_div3)
```

```{r}
# Create plots for each division separately

# Division 1
par(mfrow = c(1, 1))  # Reset to single plot
plot(train_data_div1$GC_20K, train_data_div1$reads_20K, pch = 16, cex = 0.5, col = rgb(0, 0.5, 1, 0.5),
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     xlim = c(min(GC_20K_clean), max(GC_20K_clean)),
     ylim = c(0, max(reads_20K_clean)),
     main = "Division 1: Piecewise Polynomial Regression")

lines(new_data$GC_20K, predicted_div1, col = "blue", lwd = 2)
points(test_data_div1$GC_20K, test_data_div1$reads_20K, pch = 16, cex = 0.5, col = rgb(1, 0.2, 0.2, 0.5))
points(test_data_div1$GC_20K, test_data_div1$predicted, pch = 16, cex = 0.5, col = rgb(0.2, 1, 0.2, 0.5))

legend("topleft", legend = c("Train Data", "Test Data Actual", "Test Data Predicted", "B-spline Fit"),
       col = c(rgb(0, 0.5, 1, 0.5), rgb(1, 0.2, 0.2, 0.5), rgb(0.2, 1, 0.2, 0.5), "blue"), lwd = 2, pch = 16, cex = 0.7)

##########################################3
# Division 2
plot(train_data_div2$GC_20K, train_data_div2$reads_20K, pch = 16, cex = 0.5, col = rgb(0, 0.5, 1, 0.5),
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     xlim = c(min(GC_20K_clean), max(GC_20K_clean)),
     ylim = c(0, max(reads_20K_clean)),
     main = "Division 2: Piecewise Polynomial Regression")

lines(new_data$GC_20K, predicted_div2, col = "blue", lwd = 2)
points(test_data_div2$GC_20K, test_data_div2$reads_20K, pch = 16, cex = 0.5, col = rgb(1, 0.2, 0.2, 0.5))
points(test_data_div2$GC_20K, test_data_div2$predicted, pch = 16, cex = 0.5, col = rgb(0.2, 1, 0.2, 0.5))

# legend("topleft", legend = c("Train Data", "Test Data Actual", "Test Data Predicted", "B-spline Fit"),
       # col = c(rgb(0, 0.5, 1, 0.5), rgb(1, 0.2, 0.2, 0.5), rgb(0.2, 1, 0.2, 0.5), "blue"), lwd = 2, pch = 16, cex = 0.7)
legend("topleft", legend = c("Train Data", "Test Data Actual", "Test Data Predicted", "B-spline Fit"),
       col = c("darkgoldenrod2", "wheat4", "blue", "springgreen1"), lwd = 2, pch = 16, cex = 0.7)


##########################################
############DARK MODE
##########################################

ggplot() +
  geom_point(data = train_data_div3, aes(x = GC_20K, y = reads_20K, color = "Train Data"), size = 1.5, alpha = 0.5) +
  geom_point(data = test_data_div3, aes(x = GC_20K, y = reads_20K, color = "Test Data Actual"), size = 1.5, alpha = 0.5) +
  geom_point(data = test_data_div3, aes(x = GC_20K, y = predicted, color = "Test Data Predicted"), size = 1.5, alpha = 0.5) +
  geom_line(data = data.frame(GC_20K = new_data$GC_20K, predicted_div3), aes(x = GC_20K, y = predicted_div3, color = "B-spline Fit"), size = 1) +
  labs(title = "Div3: Completely Random Partitioning", x = "GC Content (cleaned)", y = "Read Counts (cleaned)") +
  theme_minimal() +
  scale_x_continuous(labels = percent_format(accuracy = 1)) +
  scale_y_continuous(limits = c(0, max(reads_20K_clean))) +
  scale_color_manual(name = "", values = c("Train Data" = "darkgoldenrod2", "Test Data Actual" = "darkseagreen3", "Test Data Predicted" = "red", "B-spline Fit" = "blue")) +
  theme(
    legend.position = "top",
    legend.text = element_text(size = 12),
    legend.background = element_rect(fill = "azure2", color = NA),
    axis.text.y.left = element_blank(),
    axis.text.x = element_text(size = 12, color = "grey95"),
    axis.text.y.right = element_text(size = 12, color = "grey95"),
    axis.title.y.left = element_text(size = 14, color = "grey95", angle = 90, vjust = 0.5),
    axis.title.y.right = element_blank(),
    axis.title.x = element_text(size = 14, color = "grey95"),
    plot.background = element_rect(fill = "#3D3F49", color = NA),
    panel.background = element_rect(fill = "#3D3F49", color = NA),
    panel.grid.major = element_line(color = "grey95"),
    panel.grid.minor = element_line(color = "grey95"),
    plot.title = element_text(size = 16, color = "grey95"),
    axis.ticks = element_line(color = "lightgray")
  ) +
  scale_y_continuous(sec.axis = dup_axis())

##########################################
########LIGHT MODE
##########################################
library(ggplot2)
library(scales)  # For percentage formatting

ggplot() +
    # Train data points
    geom_point(data = train_data_div1, aes(x = GC_20K, y = reads_20K, color = "Train Data"), 
               size = 1.5, alpha = 0.5) +
    # Test data actual points
    geom_point(data = test_data_div1, aes(x = GC_20K, y = reads_20K, color = "Test Data Actual"), 
               size = 1.5, alpha = 0.5) +
    # Test data predicted points
    geom_point(data = test_data_div1, aes(x = GC_20K, y = predicted, color = "Test Data Predicted"), 
               size = 1.5, alpha = 0.5) +
    # B-spline fit line
    geom_line(data = data.frame(GC_20K = new_data$GC_20K, predicted_div1), 
              aes(x = GC_20K, y = predicted_div1, color = "B-spline Fit"), 
              size = 1) +
    # Labels and theme
    labs(title = "Mixed: Grouped by Location, Assigned Randomly (Div 1)", 
         x = "GC Content (cleaned)", 
         y = "Read Counts (cleaned)") +
    theme_minimal() +
    # X axis as percentage
    scale_x_continuous(labels = percent_format(accuracy = 1)) +
    # Y axis limits and secondary axis
    scale_y_continuous(
        limits = c(0, max(reads_20K_clean)),
        sec.axis = sec_axis(~ ., name = "")
    ) +
    # Legend
    scale_color_manual(name = "", 
                       values = c("Train Data" = "darkgoldenrod2", 
                                  "Test Data Actual" = "wheat4", 
                                  "Test Data Predicted" = "blue", 
                                  "B-spline Fit" = "red")) +
    theme(
        legend.position = "top",
        axis.title.y.left = element_text(margin = margin(r = 10)),
        axis.title.y.right = element_blank(),
        axis.text.y.right = element_text(color = "black")
    )


##########################################
ggplot() +
    geom_point(data = train_data_div2, aes(x = GC_20K, y = reads_20K, color = "Train Data"), size = 1.5, alpha = 0.5) +
    geom_point(data = test_data_div2, aes(x = GC_20K, y = reads_20K, color = "Test Data Actual"), size = 1.5, alpha = 0.5) +
    geom_point(data = test_data_div2, aes(x = GC_20K, y = predicted, color = "Test Data Predicted"), size = 1.5, alpha = 0.5) +
    geom_line(data = data.frame(GC_20K = new_data$GC_20K, predicted_div2), aes(x = GC_20K, y = predicted_div3, color = "B-spline Fit"), size = 1) +
    labs(title = "Div2: Partitioned by Location", x = "GC Content (cleaned)", y = "Read Counts (cleaned)") +
    theme_minimal() +
    scale_x_continuous(labels = percent_format(accuracy = 1)) +
    scale_y_continuous(limits = c(0, max(reads_20K_clean))) +
    scale_color_manual(name = "", values = c("Train Data" = "darkgoldenrod2", "Test Data Actual" = "darkseagreen3", "B-spline Fit" = "red", "Test Data Predicted" = "blue")) +
    theme(
        legend.position = "top",
        legend.text = element_text(size = 12),
        legend.background = element_rect(fill = rgb(1,1,1,0.8),color=NA),
        axis.text.y.left = element_blank(),
        axis.text.x = element_text(size = 12, color = "grey95"),
        axis.text.y.right = element_text(size = 12, color = "grey95"),
        axis.title.y.left = element_text(size = 14, color = "grey95", angle = 90, vjust = 0.5),
        axis.title.y.right = element_blank(),
        axis.title.x = element_text(size = 14, color = "grey95"),
        plot.background = element_rect(fill = "#3D3F49", color = NA),
        panel.background = element_rect(fill = "#3D3F49", color = NA),
        panel.grid.major = element_line(color = "grey95"),
        panel.grid.minor = element_line(color = "grey95"),
        plot.title = element_text(size = 16, color = "grey95"),
        axis.ticks = element_line(color = "lightgray")
    ) +
    scale_y_continuous(sec.axis = dup_axis())
##################################################3

library(ggplot2)
library(scales)  # For percentage formatting

ggplot() +
  # Train data points
  geom_point(data = train_data_div3, aes(x = GC_20K, y = reads_20K, color = "Train Data"), 
             size = 1.5, alpha = 0.5) +
  # Test data actual points
  geom_point(data = test_data_div3, aes(x = GC_20K, y = reads_20K, color = "Test Data Actual"), 
             size = 1.5, alpha = 0.5) +
  # Test data predicted points
  geom_point(data = test_data_div3, aes(x = GC_20K, y = predicted, color = "Test Data Predicted"), 
             size = 1.5, alpha = 0.5) +
  # B-spline fit line
  geom_line(data = data.frame(GC_20K = new_data$GC_20K, predicted_div3), 
            aes(x = GC_20K, y = predicted_div3, color = "B-spline Fit"), 
            size = 1) +
  # Labels and theme
  labs(title = "Div3: Completely Random Partitioning", 
       x = "GC Content (cleaned)", 
       y = "Read Counts (cleaned)") +
  theme_minimal() +
  # X axis as percentage
  scale_x_continuous(labels = percent_format(accuracy = 1)) +
  # Y axis limits
  scale_y_continuous(limits = c(0, max(reads_20K_clean))) +
  # Legend
  scale_color_manual(name = "", 
                     values = c("Train Data" = "darkgoldenrod2", 
                                "Test Data Actual" = "wheat4", 
                                "Test Data Predicted" = "blue", 
                                "B-spline Fit" = "springgreen1"),
                     ) +
  theme(
    legend.position = "top",
    legend.text = element_text(size = 12),  # Enlarging legend text
    axis.text = element_text(size = 12, color = "grey95"),  # Enlarging and lightening tick labels
    axis.title.y.right = element_text(size = 14, color = "grey95", angle = 90, vjust = 0.5),  # Moving y-axis title to right
    axis.title.x = element_text(size = 14, color = "grey95"),
    plot.background = element_rect(fill = "#3D3F49", color = NA),  # Dark gray background
    panel.background = element_rect(fill = "#3D3F49", color = NA),  # Dark gray background
    panel.grid.major = element_line(color = "grey95"),  # Light gray gridlines
    panel.grid.minor = element_line(color = "grey95"),
    plot.title = element_text(size = 16, color = "grey95"),  # Light gray title
    axis.title.y = element_blank(),  # Removing original y-axis title
    axis.ticks = element_line(color = "lightgray")
  ) +
  scale_y_continuous(sec.axis = dup_axis(name = "Read Counts (cleaned)"))



# Create the ggplot
ggplot() +
  # Train data points
  geom_point(data = train_data_div3, aes(x = GC_20K, y = reads_20K), 
             color = "darkgoldenrod2", size = 1.5, alpha = 0.5) +
  # Test data actual points
  geom_point(data = test_data_div3, aes(x = GC_20K, y = reads_20K), 
             color = "wheat4", size = 1.5, alpha = 0.5) +
  # Test data predicted points
  geom_point(data = test_data_div3, aes(x = GC_20K, y = predicted), 
             color = "blue", size = 1.5, alpha = 0.5) +
  # B-spline fit line
  geom_line(data = data.frame(new_data$GC_20K, predicted_div3), aes(x = new_data$GC_20K, y = predicted_div3), 
            color = "springgreen1", size = 1) +
  # Labels and theme
  labs(title = "Div3: Completely Random Partitioning", 
       x = "GC Content (cleaned)", 
       y = "Read Counts (cleaned)") +
  theme_minimal() +
  # X and Y axis limits
  scale_x_continuous(limits = c(min(GC_20K_clean), max(GC_20K_clean))) +
  scale_y_continuous(limits = c(0, max(reads_20K_clean))) +
  # Legend
  scale_color_manual(name = "Legend", 
                     values = c("Train Data" =  "darkgoldenrod2", "Test Data Actual" = "wheat4", 
                                "Test Data Predicted" = "blue", "B-spline Fit" = "springgreen1")) +
  theme(legend.position = "topleft")




```
