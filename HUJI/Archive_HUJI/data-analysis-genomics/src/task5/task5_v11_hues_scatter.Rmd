---
title: "Lab Task 4: Approx. Regression w/ Piecewise Polynomial Model"
author: "Group 6"
date: Sys.Date()
output:
  html_document:
    code_folding: show
editor_options: 
  markdown: 
    wrap: sentence
---

Group members:

- Shawn Yakir , 315714980, shawnyakir@gmail.com
- Sarah Levitz, 324673623, sarah.levitz@mail.huji.ac.il
- Carmel Baris, 318455276, carmel.baris@mail.huji.ac.il 


## Setup

```{r setup}
# Clean the environment
rm(list = ls())

# Load required packages
library('data.table')
library('splines')
library('quantreg')

# Set working directory
# dir_name = "/Users/alevi/Downloads/"
dir_name = "C:/Users/user/Documents/Carmel/Projects/HUJI/Archive_HUJI/data-analysis-genomics/data/"

# Load helper functions
helpers_file = file.path(dir_name, "help_funcs_v5.R")
source(helpers_file)
helpers = list(
    loadRData = loadRData,
    fitMet = fitMetrics,
    binBases = binBases,
    binReads = binReads,
    fit_bspline = fit_bspline
    )

# Load data
bases_file = file.path(dir_name, "chr1_line.rda")
chr1_bases = helpers$loadRData(bases_file)
reads_file_all = file.path(dir_name, "TCGA-13-0723-01A_lib2_all_chr1.forward")
chr1_reads = data.table::fread(reads_file_all)
colnames(chr1_reads) = c("Chrom", "Loc", "FragLen")

# Preprocess data
nreads = nrow(chr1_reads)
myLocations = as.numeric(chr1_reads$Loc)
last_read = myLocations[nreads]
binsize = 20000
bases_20K = helpers$binBases(chr1_bases, last_read, binsize)
GC_20K = bases_20K[, 3] + bases_20K[, 4]
if(any(GC_20K>1)){GC_20K = GC_20K / binsize}
```


```{r setup2}
reads_20K = helpers$binReads(myLocations, binsize, last_read)
save(reads_20K, GC_20K, file = file.path(dir_name, "reads_gc_20K.rda"))
save(myLocations, file = file.path(dir_name, "myLocations.rda"))

```




## Removing outliers

```{r outliers}

# Defining logical vectors for filtering out bins (observations)

# Defining logical vectors for filtering out bins (observations)

# outliers of gc percent per bin
zeros_GC = GC_20K == 0 #bins w/o GC content
small_GC = GC_20K <= 0.3 & GC_20K > 0 #low-GC content bins (<30%)
valid_GC = !(zeros_GC | small_GC) #bins w/ at least 30% GC content

# identify outliers of reads count per bin
z_scores = (reads_20K - mean(reads_20K)) / sd(reads_20K)
xtreme_reads = abs(z_scores) > 2

# create new variables without outliers
outliers = (zeros_GC | small_GC | xtreme_reads)
reads_20K_clean = reads_20K[!outliers]
GC_20K_clean = GC_20K[!outliers]
```



## Benchmark: fit bspline regression (pre-split)


```{r fit}

plot(GC_20K, reads_20K, pch = 16, cex = 0.5, col = rgb(0, 0, 0, 0.7),
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     xlim = c(min(GC_20K_clean),max(GC_20K_clean)),
     ylim = c(min(reads_20K_clean),max(reads_20K_clean)),
     main = "B-spline Regression")


# Fit the regression models
knots_bs = c(0.415, 0.45, 0.54)
lknot = min(GC_20K)
rknot = max(GC_20K)
reg_bs = lm(subset = !outliers,
             formula = reads_20K ~ bs(GC_20K, degree = 3, 
                                      knots = knots_bs, 
                                      Boundary.knots = c(lknot, rknot)))

# Create new data for prediction
new_data <- data.frame(GC_20K = seq(min(GC_20K_clean), max(GC_20K_clean), length.out = 1000))
new_data$predicted <- predict(reg_bs, newdata = new_data)

# Plot the B-spline regression line
lines(new_data$GC_20K, new_data$predicted, col = "blue", lwd = 2)

# Add vertical lines to indicate breakpoints
abline(v = knots_bs, lty = 2, col = "darkgray", lwd = 1.5)
```





```{r ggplot_setup, warning=FALSE}
library(ggplot2)
library(dplyr)
library(ggrepel)

# Assuming helpers and chr1_reads, chr1_bases, etc. are already loaded into the environment
nreads = nrow(chr1_reads)
myLocations = as.numeric(chr1_reads$Loc)
last_read = myLocations[nreads]
binsize = 20000
bases_20K = helpers$binBases(chr1_bases, last_read, binsize)
GC_20K = bases_20K[, 3] + bases_20K[, 4]
if(any(GC_20K > 1)) { GC_20K = GC_20K / binsize }

reads_20K = helpers$binReads(myLocations, binsize, last_read)

# Assuming reg_bs is the regression model


# Extract train and test datasets based on the logical indices
train_data_div3 <- data.frame(GC_20K = GC_20K_clean[train_logical_div3], reads_20K = reads_20K_clean[train_logical_div3])
test_data_div3 <- data.frame(GC_20K = GC_20K_clean[test_logical_div3], reads_20K = reads_20K_clean[test_logical_div3])

# Predictions for the training data
train_pred_div3 <- predict(reg_bs_train_div3, newdata = train_data_div3)

# Calculate residuals for the training data
train_resid_div3 <- train_data_div3$reads_20K - train_pred_div3

# Predictions for the testing data
test_pred_div3 <- predict(reg_bs_train_div3, newdata = test_data_div3)

# Calculate residuals for the testing data
test_resid_div3 <- test_data_div3$reads_20K - test_pred_div3

# Add the predicted values to the test_data_div3 dataframe
test_data_div3$predicted <- test_pred_div3

```


## Scatter Plot of Residuals on GC_20K_clean:

```{r ggplot_GC}
ggplot(data.frame(GC_20K_clean, resid_bs), aes(x = GC_20K_clean, y = resid_bs)) +
  geom_point(color = rgb(0,0,0,0.5)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Residuals vs. GC Content", x = "GC Content", y = "Residuals") +
  theme_minimal()


```

## Scatter Plot of Residuals on pred_bs:

```{r ggplot_pred}
ggplot(data.frame(pred_bs, resid_bs), aes(x = pred_bs, y = resid_bs)) +
  geom_point(color = rgb(0,0,0,0.5)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Residuals vs. Predicted Values", x = "Predicted Values", y = "Residuals") +
  theme_minimal()

```

## Scatter Plot of Residuals on reads_20K_clean:

```{r ggplot_locs}

ggplot(data.frame(Location = 1:length(resid_bs), Residuals = resid_bs), aes(x = Location, y = Residuals)) +
  geom_point(color = rgb(0,0,0,0.5)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Residuals vs. Chromosomal Location", x = "Chromosomal Location", y = "Residuals") +
  theme_minimal()

```


## Residuals vs. GC Content (Grouped by Percentiles)

```{r}


# Recreate your logical vectors for Group 3
train_indices_div3 <- 1:floor(0.7 * n_samples)
test_indices_div3 <- (floor(0.7 * n_samples) + 1):n_samples

train_logical_div3 <- rep(FALSE, n_samples)
test_logical_div3 <- rep(FALSE, n_samples)

train_logical_div3[train_indices_div3] <- TRUE
test_logical_div3[test_indices_div3] <- TRUE

test_data_div3 <- data.frame(GC_20K = GC_20K_clean[test_logical_div3], reads_20K = reads_20K_clean[test_logical_div3])
test_data_div3$predicted <- predict(reg_bs_train_div3, newdata = test_data_div3)




# Calculate residuals
residuals <- test_data_div3$reads_20K - test_data_div3$predicted
```


```{r}
# Create GC groups of percentages (e.g., 2% intervals)
breaks <- seq(0.3, 0.7, by = 0.02)
GC_groups <- cut(GC_20K_clean, breaks = breaks, include.lowest = TRUE, right = FALSE)

# Count the number of data points in each group
group_counts <- table(GC_groups)

# Create a color palette of blue hues
blue_palette <- colorRampPalette(c("lightblue", "darkblue"))(length(unique(group_counts)))

# Assign colors based on counts
group_colors <- blue_palette[as.numeric(cut(group_counts, breaks = length(blue_palette)))]

# Set up the plot area
par(mar = c(5, 4, 4, 2) + 0.1)

# Create the boxplot
boxplot(residuals ~ GC_groups, 
        main = "Residuals vs. GC Groups",
        xlab = "GC Content (Cleaned)",
        ylab = "Residuals",
        outline = TRUE,
        whisklty = 1,
        staplelty = 0,
        boxwex = 0.8,
        border = "black",
        col = group_colors,
        xaxt = "n")  # Remove default x-axis

# Create simplified x-axis labels
major_breaks <- seq(30, 70, by = 5)
axis(1, at = seq(1, length(levels(GC_groups)), length.out = length(major_breaks)), 
     labels = paste0(major_breaks, "%"))

# Add minor ticks for all groups
axis(1, at = 1:length(levels(GC_groups)), labels = FALSE, tcl = -0.2)

# Add a reference line at y = 0
abline(h = 0, col = "red", lty = 2)

# Add a legend for color interpretation
legend("bottomright", legend = c("Fewer", "More"), 
       fill = c(blue_palette[1], blue_palette[length(blue_palette)]), 
       title = "Number of Observations", cex = 0.8,
       bty = "n")

```


## Residuals vs. Predicted Value

```{r res_yhat}

# Assuming you have calculated residuals and have reads_20K_clean

# Create groups for reads_20K_clean
reads_breaks <- seq(min(reads_20K_clean), max(reads_20K_clean), length.out = 21)
reads_groups <- cut(reads_20K_clean, breaks = reads_breaks, include.lowest = TRUE, right = FALSE)

# Count the number of data points in each group
group_counts <- table(reads_groups)

# Create a color palette of blue hues
blue_palette <- colorRampPalette(c("lightblue", "darkblue"))(length(unique(group_counts)))

# Assign colors based on counts
group_colors <- blue_palette[as.numeric(cut(group_counts, breaks = length(blue_palette)))]

# Set up the plot area
par(mar = c(5, 4, 4, 2) + 0.1)

# Create the boxplot
boxplot(residuals ~ reads_groups, 
        main = "Residuals vs. Predicted Reads Count Per Bin",
        xlab = "Predicted Reads Count",
        ylab = "Residuals",
        outline = TRUE,
        whisklty = 1,
        staplelty = 0,
        boxwex = 0.8,
        border = "black",
        col = group_colors,
        xaxt = "n")  # Remove default x-axis

# Create simplified x-axis labels
axis(1, at = seq(1, length(levels(reads_groups)), length.out = 5), 
     labels = round(seq(min(reads_20K_clean), max(reads_20K_clean), length.out = 5)))

# Add minor ticks for all groups
axis(1, at = 1:length(levels(reads_groups)), labels = FALSE, tcl = -0.2)

# Add a reference line at y = 0
abline(h = 0, col = "red", lty = 2)

# Add a legend for color interpretation
legend("bottomright", legend = c("Fewer", "More"), 
       fill = c(blue_palette[1], blue_palette[length(blue_palette)]), 
       title = "Number of Observations", cex = 0.8, bty = "n")
```






## Residuals vs. Bin Location

```{r res_locs}
# Create groups for bin locations
location_breaks <- seq(1, length(residuals), length.out = 21)
location_groups <- cut(1:length(residuals), breaks = location_breaks, include.lowest = TRUE, right = FALSE)

# Count the number of data points in each group
group_counts <- table(location_groups)

# Create a color palette of blue hues
blue_palette <- colorRampPalette(c("lightblue", "darkblue"))(length(unique(group_counts)))

# Assign colors based on counts
group_colors <- blue_palette[as.numeric(cut(group_counts, breaks = length(blue_palette)))]

# Set up the plot area
par(mar = c(5, 4, 4, 2) + 0.1)

# Create the boxplot
boxplot(residuals ~ location_groups, 
        main = "Residuals vs. Bin Location",
        xlab = "Bin Location",
        ylab = "Residuals",
        outline = TRUE,
        whisklty = 1,
        staplelty = 0,
        boxwex = 0.8,
        border = "black",
        col = group_colors,
        xaxt = "n")  # Remove default x-axis

# Create simplified x-axis labels
axis(1, at = seq(1, length(levels(location_groups)), length.out = 5), 
     labels = round(seq(1, length(residuals), length.out = 5)))

# Add minor ticks for all groups
axis(1, at = 1:length(levels(location_groups)), labels = FALSE, tcl = -0.2)

# Add a reference line at y = 0
abline(h = 0, col = "red", lty = 2)

# Add a legend for color interpretation
legend("topright", legend = c("Fewer", "More"), 
       fill = c(blue_palette[1], blue_palette[length(blue_palette)]), 
       title = "Number of Observations", cex = 0.8)

par(mfrow = c(1,1))

```

```{r res_scatter}
predicted_reads <- predict(reg_bs)

# 1. Residuals on GC_20K_clean
plot(GC_20K_clean, residuals, 
     main = "Residuals vs. GC Content",
     xlab = "GC Content",
     ylab = "Residuals",
     pch = 20,
     col = rgb(0,0,0,0.3))
abline(h = 0, col = "red", lty = 2)

plot(predicted_reads, residuals, 
     main = "Residuals vs. Predicted Reads",
     xlab = "Predicted Reads",
     ylab = "Residuals",
     pch = 20,
     col = rgb(0,0,0,0.3))
abline(h = 0, col = "red", lty = 2)
```

```{r}

par(mfrow = c(3,1))
# 3. Residuals on location across the chromosome
plot(1:length(residuals), residuals, 
     main = "Residuals vs. Chromosome Location",
     xlab = "Bin Location",
     ylab = "Residuals",
     pch = 20,
     col = rgb(0,0,0,0.2)
     ,ylim = c(-3000,3000)
     )
abline(h = 0, col = "red", lty = 2)


# 4. Reads Count on location across the chromosome
plot(1:length(residuals), reads_20K_clean, 
     main = "Reads Count vs. Chromosome Location",
     xlab = "Bin Location",
     ylab = "Actual",
     pch = 20,
     col = rgb(0,0,0,0.2)
     ,ylim = c(0,5000)
     )
abline(h = median(reads_20K_clean), col = "red", lty = 2)

# 5. Predicted Reads Count on location across the chromosome
plot(1:length(residuals), predicted_reads, 
     main = "Predicted Reads Count vs. Chromosome Location",
     xlab = "Bin Location",
     ylab = "Predicted",
     pch = 20,
     col = rgb(0,0,0,0.2)
     ,ylim = c(0,5000)
     )
abline(h = median(predicted_read), col = "red", lty = 2)

# par(mfrow = c(1,1))

```


```{r residuals}
pred_bs = predict(reg_bs)
res_bs = reads_20K_clean - pred_bs

plot(GC_20K_clean, res_bs, pch = 16, cex = 0.5, col = rgb(0, 0, 0, 0.5),
     xlab = "GC Content (cleaned)", ylab = "Residuals",
     main = "Residuals of BSpline Model")
abline(h = 0, col = "darkgray", lwd = 1.5)

```






## QUESTION 1: 

## Splitting to test and train (three versions)
```{r train_fit}
# Subset data for each division
# Set seed for reproducibility
set.seed(100)

# Division 1: Data into 20 parts and randomly assigning 14 parts to train
n_bins <- length(reads_20K)
bins_per_group <- n_bins %/% 20  # Integer division to get bins per group
extra_bins <- n_bins %% 20       # Remainder to ensure equal-sized groups

# Distribute extra bins (if any) across the groups
group_sizes <- rep(bins_per_group, 20)
if (extra_bins > 0) {
  group_sizes[1:extra_bins] <- group_sizes[1:extra_bins] + 1
}

# Create the 20 groups
groups <- split(1:n_bins, rep(1:20, group_sizes))

# Randomly select 14 groups for training and 6 for testing
train_indices_div1 <- sample(1:20, 14)
test_indices_div1 <- setdiff(1:20, train_indices_div1)

# Create logical vectors for Division 1
train_logical_div1 <- rep(FALSE, n_bins)
test_logical_div1 <- rep(FALSE, n_bins)

train_logical_div1[unlist(groups[train_indices_div1])] <- TRUE
test_logical_div1[unlist(groups[test_indices_div1])] <- TRUE

# Division 2: Completely random division (70% train, 30% test)
n_samples <- length(reads_20K)
train_indices_div2 <- sample(1:n_samples, 0.7 * n_samples)
test_indices_div2 <- setdiff(1:n_samples, train_indices_div2)

# Create logical vectors for Division 2
train_logical_div2 <- rep(FALSE, n_samples)
test_logical_div2 <- rep(FALSE, n_samples)

train_logical_div2[train_indices_div2] <- TRUE
test_logical_div2[test_indices_div2] <- TRUE

# Division 3: Regular division (first 70% train, last 30% test)
train_indices_div3 <- 1:floor(0.7 * n_samples)
test_indices_div3 <- (floor(0.7 * n_samples) + 1):n_samples

# Create logical vectors for Division 3
train_logical_div3 <- rep(FALSE, n_samples)
test_logical_div3 <- rep(FALSE, n_samples)

train_logical_div3[train_indices_div3] <- TRUE
test_logical_div3[test_indices_div3] <- TRUE


train_data_div1 <- data.frame(GC_20K = GC_20K_clean[train_logical_div1], reads_20K = reads_20K_clean[train_logical_div1])
train_data_div2 <- data.frame(GC_20K = GC_20K_clean[train_logical_div2], reads_20K = reads_20K_clean[train_logical_div2])
train_data_div3 <- data.frame(GC_20K = GC_20K_clean[train_logical_div3], reads_20K = reads_20K_clean[train_logical_div3])

# Define knots for the B-spline
knots_bs <- c(0.415, 0.45, 0.54)

# Fit the B-spline model using the train data for each division
reg_bs_train_div1 <- lm(reads_20K ~ bs(GC_20K, knots = knots_bs, degree = 3, Boundary.knots = c(min(GC_20K_clean), max(GC_20K_clean))), data = train_data_div1)
reg_bs_train_div2 <- lm(reads_20K ~ bs(GC_20K, knots = knots_bs, degree = 3, Boundary.knots = c(min(GC_20K_clean), max(GC_20K_clean))), data = train_data_div2)
reg_bs_train_div3 <- lm(reads_20K ~ bs(GC_20K, knots = knots_bs, degree = 3, Boundary.knots = c(min(GC_20K_clean), max(GC_20K_clean))), data = train_data_div3)

# Create new data for prediction
new_data <- data.frame(GC_20K = seq(min(GC_20K_clean), max(GC_20K_clean), length.out = 1000))

# Predict for each division
predicted_div1 <- predict(reg_bs_train_div1, newdata = new_data)
predicted_div2 <- predict(reg_bs_train_div2, newdata = new_data)
predicted_div3 <- predict(reg_bs_train_div3, newdata = new_data)
```


## Plot the data and the B-spline regression lines for each division


```{r train_viz}

# Plot the data and the B-spline regression lines for each division
plot(GC_20K_clean, reads_20K_clean, pch = 16, cex = 0.5, col = rgb(0, 0, 0, 0.7),
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     xlim = c(min(GC_20K_clean), max(GC_20K_clean)),
     ylim = c(0, 3500),
     main = "B-Spline Regression on Train Data")

# Plot the B-spline regression lines for each division
lines(new_data$GC_20K, predicted_div1, col = "blue", lwd = 2)
lines(new_data$GC_20K, predicted_div2, col = "red", lwd = 2)
lines(new_data$GC_20K, predicted_div3, col = "green", lwd = 2)

# Add vertical lines to indicate breakpoints
abline(v = knots_bs, lty = 2, col = "darkgray", lwd = 1.5)

# Add legend
legend("topleft", legend = c("70% Random Regions (Div 1)", "70% Random Bins (Div 2)", "70% First Bins on Left (Div 3)"), col = c("blue", "red", "green"), lwd = 2, cex = 0.75, bty = "n")

```

# Question1: c+d

```{r}
# Subset test data for each division
test_data_div1 <- data.frame(GC_20K = GC_20K_clean[test_logical_div1], reads_20K = reads_20K_clean[test_logical_div1])
test_data_div2 <- data.frame(GC_20K = GC_20K_clean[test_logical_div2], reads_20K = reads_20K_clean[test_logical_div2])
test_data_div3 <- data.frame(GC_20K = GC_20K_clean[test_logical_div3], reads_20K = reads_20K_clean[test_logical_div3])

# Predict for test data in each division
test_data_div1$predicted <- predict(reg_bs_train_div1, newdata = test_data_div1)
test_data_div2$predicted <- predict(reg_bs_train_div2, newdata = test_data_div2)
test_data_div3$predicted <- predict(reg_bs_train_div3, newdata = test_data_div3)

calculate_metrics <- function(actual, predicted) {
  # Remove NA values from actual and predicted
  actual <- actual[!is.na(actual)]
  predicted <- predicted[!is.na(predicted)]
  
  if (length(actual) != length(predicted)) {
    stop("Length of 'actual' and 'predicted' must be the same.")
  }
  
  n <- length(actual)
  
  if (n == 0) {
    stop("No valid data points to calculate metrics.")
  }
  
  # Calculate R-squared
  mean_actual <- mean(actual)
  ss_total <- sum((actual - mean_actual)^2)
  ss_residual <- sum((actual - predicted)^2)
  r_squared <- 1 - ss_residual / ss_total
  
  # Calculate MAE and MSE
  mae <- mean(abs(actual - predicted))
  mse <- mean((actual - predicted)^2)
  
  return(list(R_squared = r_squared, MAE = mae, MSE = mse))
}
# Calculate metrics for train and test data in each division
metrics_train_div1 <- calculate_metrics(train_data_div1$reads_20K, predict(reg_bs_train_div1, newdata = train_data_div1))
metrics_test_div1 <- calculate_metrics(test_data_div1$reads_20K, test_data_div1$predicted)
metrics_train_div2 <- calculate_metrics(train_data_div2$reads_20K, predict(reg_bs_train_div2, newdata = train_data_div2))
metrics_test_div2 <- calculate_metrics(test_data_div2$reads_20K, test_data_div2$predicted)
metrics_train_div3 <- calculate_metrics(train_data_div3$reads_20K, predict(reg_bs_train_div3, newdata = train_data_div3))
metrics_test_div3 <- calculate_metrics(test_data_div3$reads_20K, test_data_div3$predicted)

# Print metrics
print("Division 1 Train Metrics:")
print(metrics_train_div1)
print("Division 1 Test Metrics:")
print(metrics_test_div1)

print("Division 2 Train Metrics:")
print(metrics_train_div2)
print("Division 2 Test Metrics:")
print(metrics_test_div2)

print("Division 3 Train Metrics:")
print(metrics_train_div3)
print("Division 3 Test Metrics:")
print(metrics_test_div3)
```



# Plot the data and the B-spline regression lines for each division
```{r}
# Plot the data and the B-spline regression lines for each division
plot(GC_20K_clean, reads_20K_clean, pch = 16, cex = 0.5, col = rgb(0, 0, 0, 0.3),
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     xlim = c(min(GC_20K_clean), max(GC_20K_clean)),
     ylim = c(0, max(reads_20K_clean)),
     main = "Piecewise Polynomial Regression")

# Plot the B-spline regression lines for each division
lines(new_data$GC_20K, predicted_div1, col = "blue", lwd = 2)
lines(new_data$GC_20K, predicted_div2, col = "red", lwd = 2)
lines(new_data$GC_20K, predicted_div3, col = "green", lwd = 2)

# Plot the test data with predictions and add vertical lines for prediction errors
points(test_data_div1$GC_20K, test_data_div1$reads_20K, col = rgb(0, 0, 1, 0.5), pch = 1)
points(test_data_div1$GC_20K, test_data_div1$predicted, col = rgb(0, 0, 1, 0.5), pch = 16)
segments(test_data_div1$GC_20K, test_data_div1$reads_20K, test_data_div1$GC_20K, test_data_div1$predicted, col = rgb(0, 0, 1, 0.3), lty = 2)

points(test_data_div2$GC_20K, test_data_div2$reads_20K, col = rgb(1, 0, 0, 0.5), pch = 1)
points(test_data_div2$GC_20K, test_data_div2$predicted, col = rgb(1, 0, 0, 0.5), pch = 16)
segments(test_data_div2$GC_20K, test_data_div2$reads_20K, test_data_div2$GC_20K, test_data_div2$predicted, col = rgb(1, 0, 0, 0.3), lty = 2)

points(test_data_div3$GC_20K, test_data_div3$reads_20K, col = rgb(0, 1, 0, 0.5), pch = 1)
points(test_data_div3$GC_20K, test_data_div3$predicted, col = rgb(0, 1, 0, 0.5), pch = 16)
segments(test_data_div3$GC_20K, test_data_div3$reads_20K, test_data_div3$GC_20K, test_data_div3$predicted, col = rgb(0, 1, 0, 0.3), lty = 2)

# Add vertical lines to indicate breakpoints
abline(v = knots_bs, lty = 2, col = "darkgray", lwd = 1.5)

# Add legend
legend("topleft", legend = c("B-spline Div 1", "B-spline Div 2", "B-spline Div 3"), col = c("blue", "red", "green"), lwd = 2, cex = 0.7)
```



#### Sanity checks for splitting process

```{r qa_split}
#+++++++++++ Check Proportions
# Division 1
props_div1 = helpers$chk_ratio(train_div1, test_div1, 14/20)
cat("Div1 props\n", 
    "Test proportion:", props_div1$test_ratio, "\n",
    "Train proportion:", props_div1$train_ratio, "\n",
    "Expected proportion of train:", props_div1$expected_train_ratio,
     "\n\n"
    )

# Division 2
props_div2 = helpers$chk_ratio(train_div2, test_div2, 0.7)
cat("Div2 props\n", 
    "Test proportion:", props_div2$test_ratio, "\n",
    "Train proportion:", props_div2$train_ratio, "\n",
    "Expected proportion of train:", props_div2$expected_train_ratio,
     "\n\n"
    )

# Division 3
props_div3 = helpers$chk_ratio(train_div3, test_div3, 0.7)
cat("Div3 props\n", 
    "Test proportion:", props_div3$test_ratio, "\n",
    "Train proportion:", props_div3$train_ratio, "\n",
    "Expected proportion of train:", props_div3$expected_train_ratio,
     "\n\n"
    )

#+++++++++++ Check for Overlaps
cat("\n OVERLAP TEST \n\n")

# Division 1
overlaps_div1 = helpers$chk_ovrlp(train_indices_div1, test_indices_div1)
paste0("Has Div1 passed overlap test? ", overlaps_div1)

# Division 2
overlaps_div2 = helpers$chk_ovrlp(train_indices_div2, test_indices_div2)
paste0("Has Div2 passed overlap test? ", overlaps_div2)

# Division 3
overlaps_div3 = helpers$chk_ovrlp(train_indices_div3, test_indices_div3)
paste0("Has Div3 passed overlap test? ", overlaps_div3)

#+++++++++++ Check Data Integrity

cat("\n SIZE TEST\n\n")

# debugonce(helpers$chk_size) # @CB

# Division 1
size_div1 = helpers$chk_size(train_div1, test_div1, reads_20K)
paste0("Has Div1 passed size test? ", size_div1)

# Division 2
size_div2 = helpers$chk_size(train_div2, test_div2, reads_20K)
paste0("Has Div2 passed size test? ", size_div2)

# Division 3
size_div3 = helpers$chk_size(train_div3, test_div3, reads_20K)
paste0("Has Div3 passed size test? ", size_div3)

```







## Q1.b+c+d


```{r fit_compare}
# Define knots by quantiles (0.25, 0.50, 0.75 of the data range)
# knots_bs = c(-0.67, 0, 0.67)  # Standardized positions for knots

# Fit Spline Regression using BSplines
# Warning in bs(x_train_scaled, degree = 3L, knots = c(-0.67, 0, 0.67), Boundary.knots = c(-1.73175054161184,  :
#   some 'x' values beyond boundary knots may cause ill-conditioned bases
 
bspline_div1 = helpers$fit_bspline(train_div1, test_div1, knots_bs)
bspline_div2 = helpers$fit_bspline(train_div2, test_div2, knots_bs)
bspline_div3 = helpers$fit_bspline(train_div3, test_div3, knots_bs)

# Division 1
print("Division 1: Train Metrics")
print(bspline_div1$metrics_train)
print("Division 1: Test Metrics")
print(bspline_div1$metrics_test)

# Division 2
print("Division 2: Train Metrics")
print(bspline_div2$metrics_train)
print("Division 2: Test Metrics")
print(bspline_div2$metrics_test)

# Division 3
print("Division 3: Train Metrics")
print(bspline_div3$metrics_train)
print("Division 3: Test Metrics")
print(bspline_div3$metrics_test)

# Plotting the results for visual inspection
helpers$plot_bspline(train_div1, test_div1, bspline_div1$pred_train, bspline_div1$pred_test, "Division 1: BSpline Regression")

helpers$plot_bspline(train_div2, test_div2, bspline_div2$pred_train, bspline_div2$pred_test, "Division 2: BSpline Regression")

helpers$plot_bspline(train_div3, test_div3, bspline_div3$pred_train, bspline_div3$pred_test, "Division 3: BSpline Regression")


```





