---
title: "Lab Task 4: Approx. Regression w/ Piecewise Polynomial Model"
author: "Group 6"
date: Sys.Date()
output:
  html_document:
    code_folding: show
editor_options: 
  markdown: 
    wrap: sentence
---

Group members:

- Shawn Yakir , 315714980, shawnyakir@gmail.com
- Sarah Levitz, 324673623, sarah.levitz@mail.huji.ac.il
- Carmel Baris, 318455276, carmel.baris@mail.huji.ac.il 


## Setup

```{r setup}

# Clean the environment
rm(list = ls())

# Load required packages
library('data.table')
library('splines')
library('quantreg')

# Set working directory
# dir_name = "/Users/alevi/Downloads/"
dir_name = "C:/Users/user/Documents/Carmel/Projects/HUJI/Archive_HUJI/data-analysis-genomics/data/"

# Load helper functions
helpers_file = file.path(dir_name, "help_funcs.R")
source(helpers_file)
helpers = list(
    loadRData = loadRData,
    fitMet = fitMetrics,
    binBases = binBases,
    binReads = binReads,
    chk_ratio = check_proportions,
    chk_ovrlp = check_overlaps,
    chk_size = check_data_size,
    fit_bspline = fit_bspline,
    plot_bspline = plot_bspline_results
    )

# Load data
bases_file = file.path(dir_name, "chr1_line.rda")
chr1_bases = helpers$loadRData(bases_file)
reads_file_all = file.path(dir_name, "TCGA-13-0723-01A_lib2_all_chr1.forward")
chr1_reads = data.table::fread(reads_file_all)
colnames(chr1_reads) = c("Chrom", "Loc", "FragLen")

# Preprocess data
nreads = nrow(chr1_reads)
myLocations = as.numeric(chr1_reads$Loc)
last_read = myLocations[nreads]
binsize = 20000
bases_20K = helpers$binBases(chr1_bases, last_read, binsize)
GC_20K = bases_20K[, 3] + bases_20K[, 4]
if(any(GC_20K>1)){GC_20K = GC_20K / binsize}

reads_20K = helpers$binReads(myLocations, binsize, last_read)
save(reads_20K, GC_20K, file = file.path(dir_name, "reads_gc_20K.rda"))
```




## Removing outliers

```{r outliers}

# Defining logical vectors for filtering out bins (observations)

# outliers of gc percent per bin
zeros_GC = GC_20K == 0 #bins w/o GC content
small_GC = GC_20K <= 0.3 & GC_20K > 0 #low-GC content bins (<30%)
valid_GC = GC_20K  > 0.3 #bins w/ at least 30% GC content

# identify outliers of reads count per bin
zeros_reads = reads_20K == 0 #bins w/o any reads
zscore_line = scale(reads_20K)
xtreme_reads = abs(zscore_line) > 2
few_reads = 0 < reads_20K & reads_20K < 350
whiskers = boxplot.stats(reads_20K)$stats[c(1, 5)]
confounders = reads_20K < whiskers[1] | reads_20K > whiskers[2]

# create new variables without outliers
outliers = (zeros_GC | small_GC | zeros_reads | xtreme_reads | few_reads | confounders)
# outliers = (small_GC | confounders)
reads_20K_clean = reads_20K[!outliers]
GC_20K_clean = GC_20K[!outliers]

```



## Sanity checks for removing outliers process

```{r qa_outliers, message=FALSE, warning=FALSE}

cat("GC & Reads started out same length?", length(reads_20K) == length(GC_20K))
cat("\nGC_clean & Reads_clean ended up same length?", length(reads_20K_clean) == length(GC_20K_clean))
cat("\n","Total of",sum(outliers),"mutually unique outliers = ",sum(confounders),"confounders and",sum(confounders|small_GC) - sum(confounders),"GC between 0-30%.")

# Calculate sums and percentages
values <- c(sum(zeros_GC), sum(small_GC), 
            sum(zeros_reads), sum(zeros_reads & !(zeros_GC)), 
            sum(xtreme_reads),sum(few_reads), 
            sum(confounders),
            sum(outliers),length(outliers))
percentages <- (values / length(outliers)) * 100
percentages_formatted <- sprintf("%.2f%%", percentages)

# Create a data frame
table_data <- data.frame(
  Outliers_Condition = c("GC=0%", "0%<GC<30%", 
                         "0 Reads", "0 Reads (GC nonzero)", 
                         "Xtreme Reads (nonzero)", "0<Reads<200", 
                         "Confounders","Total Outliers", "Total Observations"),
  Num_Observed = values,
  Percentage = percentages_formatted <- sprintf("%.2f%%", percentages)
)

sorted_table_data <- table_data[order(table_data$Num_Observed), ]

print(sorted_table_data)

```




## Visualize outliers

```{r viz_outliers}

par(mfrow = c(1,2))

# Create the scatter plot
plot(GC_20K, reads_20K, pch = 20, cex = 0.7, col = "white",
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     # ylim = c(min(reads_20K), max(reads_20K_clean)),
     ylim = c(2000, 7000),
     main = "Majority of Outliers")

# Add mean line
abline(h = mean(reads_20K), col = "darkgray", lwd = 2)

# Add horizontal lines for quartiles and whiskers
quantiles = quantile(reads_20K, c(0.25, 0.75))
abline(h = c(quantiles, whiskers), col = "darkgray", lty = 2)


# Mark outliers
# points(GC_20K[confounders], reads_20K[confounders], col = "red", pch = 20)
# points(GC_20K[small_GC], reads_20K[small_GC], col = "orange", pch = 20)
zs_big = z_scores > 2
points(GC_20K[zs_big], reads_20K[zs_big], col = "green", pch = 20)


# Create the scatter plot
plot(GC_20K, reads_20K, pch = 20, cex = 0.7, col = "white",
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     ylim = c(7000,max(reads_20K)),
     main = "Outliers Above Upper Quantile (Zoomed In)")

# Add mean line
abline(h = mean(reads_20K), col = "darkgray", lwd = 2)

# Add horizontal lines for quartiles and whiskers
quantiles <- quantile(reads_20K, c(0.25, 0.75))
whiskers <- boxplot.stats(reads_20K)$stats[c(1, 5)]
abline(h = c(quantiles, whiskers), col = "darkgray", lty = 2)


# Mark outliers
# points(GC_20K[confounders], reads_20K[confounders], col = "red", pch = 20)
# points(GC_20K[small_GC], reads_20K[small_GC], col = "orange", pch = 20)
points(GC_20K[zs_big], reads_20K[zs_big], col = "green", pch = 20)

par(mfrow = c(1,1))

```

## Benchmark: fit bspline regression (pre-split)


```{r fit}

plot(GC_20K, reads_20K, pch = 16, cex = 0.5, col = rgb(0, 0, 0, 0.7),
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     xlim = c(min(GC_20K_clean),max(GC_20K_clean)),
     ylim = c(min(reads_20K_clean),max(reads_20K_clean)),
     main = "B-spline Regression")


# Fit the regression models
knots_bs = c(0.415, 0.45, 0.54)
lknot = min(GC_20K)
rknot = max(GC_20K)
reg_bs = lm(subset = !outliers,
             formula = reads_20K ~ bs(GC_20K, degree = 3, 
                                      knots = knots_bs, 
                                      Boundary.knots = c(lknot, rknot)))

# Create new data for prediction
new_data <- data.frame(GC_20K = seq(min(GC_20K_clean), max(GC_20K_clean), length.out = 1000))
new_data$predicted <- predict(reg_bs, newdata = new_data)

# Plot the B-spline regression line
lines(new_data$GC_20K, new_data$predicted, col = "blue", lwd = 2)

# Add vertical lines to indicate breakpoints
abline(v = knots_bs, lty = 2, col = "darkgray", lwd = 1.5)
```

```{r}

# Calculate residuals
residuals <- resid(reg_bs)

# Create GC groups of percentages (e.g., 2% intervals)
breaks <- seq(0.3, 0.7, by = 0.02)
GC_groups <- cut(GC_20K_clean, breaks = breaks, include.lowest = TRUE, right = FALSE)

# Count the number of data points in each group
group_counts <- table(GC_groups)

# Create a color palette of blue hues
blue_palette <- colorRampPalette(c("lightblue", "darkblue"))(length(unique(group_counts)))

# Assign colors based on counts
group_colors <- blue_palette[as.numeric(cut(group_counts, breaks = length(blue_palette)))]

# Set up the plot area
par(mar = c(5, 4, 4, 2) + 0.1)

# Create the boxplot
boxplot(residuals ~ GC_groups, 
        main = "Residuals vs. GC Groups",
        xlab = "GC Content (Cleaned)",
        ylab = "Residuals",
        outline = TRUE,
        whisklty = 1,
        staplelty = 0,
        boxwex = 0.8,
        border = "black",
        col = group_colors,
        xaxt = "n")  # Remove default x-axis

# Create simplified x-axis labels
major_breaks <- seq(30, 70, by = 5)
axis(1, at = seq(1, length(levels(GC_groups)), length.out = length(major_breaks)), 
     labels = paste0(major_breaks, "%"))

# Add minor ticks for all groups
axis(1, at = 1:length(levels(GC_groups)), labels = FALSE, tcl = -0.2)

# Add a reference line at y = 0
abline(h = 0, col = "red", lty = 2)

# Add a legend for color interpretation
legend("bottomright", legend = c("Fewer", "More"), 
       fill = c(blue_palette[1], blue_palette[length(blue_palette)]), 
       title = "Number of Observations", cex = 0.8,
       bty = "n")

```

```{r res_yhat}

# Assuming you have calculated residuals and have reads_20K_clean

# Create groups for reads_20K_clean
reads_breaks <- seq(min(reads_20K_clean), max(reads_20K_clean), length.out = 21)
reads_groups <- cut(reads_20K_clean, breaks = reads_breaks, include.lowest = TRUE, right = FALSE)

# Count the number of data points in each group
group_counts <- table(reads_groups)

# Create a color palette of blue hues
blue_palette <- colorRampPalette(c("lightblue", "darkblue"))(length(unique(group_counts)))

# Assign colors based on counts
group_colors <- blue_palette[as.numeric(cut(group_counts, breaks = length(blue_palette)))]

# Set up the plot area
par(mar = c(5, 4, 4, 2) + 0.1)

# Create the boxplot
boxplot(residuals ~ reads_groups, 
        main = "Residuals vs. Predicted Reads Count Per Bin",
        xlab = "Predicted Reads Count",
        ylab = "Residuals",
        outline = TRUE,
        whisklty = 1,
        staplelty = 0,
        boxwex = 0.8,
        border = "black",
        col = group_colors,
        xaxt = "n")  # Remove default x-axis

# Create simplified x-axis labels
axis(1, at = seq(1, length(levels(reads_groups)), length.out = 5), 
     labels = round(seq(min(reads_20K_clean), max(reads_20K_clean), length.out = 5)))

# Add minor ticks for all groups
axis(1, at = 1:length(levels(reads_groups)), labels = FALSE, tcl = -0.2)

# Add a reference line at y = 0
abline(h = 0, col = "red", lty = 2)

# Add a legend for color interpretation
legend("bottomright", legend = c("Fewer", "More"), 
       fill = c(blue_palette[1], blue_palette[length(blue_palette)]), 
       title = "Number of Observations", cex = 0.8, bty = "n")
```



```{r res_locs}
# Assuming you have the bin locations

# Create groups for bin locations
location_breaks <- seq(1, length(residuals), length.out = 21)
location_groups <- cut(1:length(residuals), breaks = location_breaks, include.lowest = TRUE, right = FALSE)

# Count the number of data points in each group
group_counts <- table(location_groups)

# Create a color palette of blue hues
blue_palette <- colorRampPalette(c("lightblue", "darkblue"))(length(unique(group_counts)))

# Assign colors based on counts
group_colors <- blue_palette[as.numeric(cut(group_counts, breaks = length(blue_palette)))]

# Set up the plot area
par(mar = c(5, 4, 4, 2) + 0.1)

# Create the boxplot
boxplot(residuals ~ location_groups, 
        main = "Residuals vs. Bin Location",
        xlab = "Bin Location",
        ylab = "Residuals",
        outline = TRUE,
        whisklty = 1,
        staplelty = 0,
        boxwex = 0.8,
        border = "black",
        col = group_colors,
        xaxt = "n")  # Remove default x-axis

# Create simplified x-axis labels
axis(1, at = seq(1, length(levels(location_groups)), length.out = 5), 
     labels = round(seq(1, length(residuals), length.out = 5)))

# Add minor ticks for all groups
axis(1, at = 1:length(levels(location_groups)), labels = FALSE, tcl = -0.2)

# Add a reference line at y = 0
abline(h = 0, col = "red", lty = 2)

# Add a legend for color interpretation
legend("topright", legend = c("Fewer", "More"), 
       fill = c(blue_palette[1], blue_palette[length(blue_palette)]), 
       title = "Number of Observations", cex = 0.8)

```

```{r res_scatter}

# 1. Residuals on GC_20K_clean
plot(GC_20K_clean, residuals, 
     main = "Residuals vs. GC Content",
     xlab = "GC Content",
     ylab = "Residuals",
     pch = 20,
     col = "blue")
abline(h = 0, col = "red", lty = 2)

# 2. Residuals on predicted reads_20K
predicted_reads <- predict(reg_bs)
plot(predicted_reads, residuals, 
     main = "Residuals vs. Predicted Reads",
     xlab = "Predicted Reads",
     ylab = "Residuals",
     pch = 20,
     col = "green")
abline(h = 0, col = "red", lty = 2)

# 3. Residuals on location across the chromosome
plot(1:length(residuals), residuals, 
     main = "Residuals vs. Chromosome Location",
     xlab = "Bin Location",
     ylab = "Residuals",
     pch = 20)
abline(h = 0, col = "red", lty = 2)

```


```{r residuals}
pred_bs = predict(reg_bs)
res_bs = reads_20K_clean - pred_bs

plot(GC_20K_clean, res_bs, pch = 16, cex = 0.5, col = rgb(0, 0, 0, 0.5),
     xlab = "GC Content (cleaned)", ylab = "Residuals",
     main = "Residuals of BSpline Model")
abline(h = 0, col = "darkgray", lwd = 1.5)

```






## QUESTION 1: 

## Splitting to test and train (three versions)
```{r train_fit}
# Subset data for each division
# Set seed for reproducibility
set.seed(100)

# Division 1: Data into 20 parts and randomly assigning 14 parts to train
n_bins <- length(reads_20K)
bins_per_group <- n_bins %/% 20  # Integer division to get bins per group
extra_bins <- n_bins %% 20       # Remainder to ensure equal-sized groups

# Distribute extra bins (if any) across the groups
group_sizes <- rep(bins_per_group, 20)
if (extra_bins > 0) {
  group_sizes[1:extra_bins] <- group_sizes[1:extra_bins] + 1
}

# Create the 20 groups
groups <- split(1:n_bins, rep(1:20, group_sizes))

# Randomly select 14 groups for training and 6 for testing
train_indices_div1 <- sample(1:20, 14)
test_indices_div1 <- setdiff(1:20, train_indices_div1)

# Create logical vectors for Division 1
train_logical_div1 <- rep(FALSE, n_bins)
test_logical_div1 <- rep(FALSE, n_bins)

train_logical_div1[unlist(groups[train_indices_div1])] <- TRUE
test_logical_div1[unlist(groups[test_indices_div1])] <- TRUE

# Division 2: Completely random division (70% train, 30% test)
n_samples <- length(reads_20K)
train_indices_div2 <- sample(1:n_samples, 0.7 * n_samples)
test_indices_div2 <- setdiff(1:n_samples, train_indices_div2)

# Create logical vectors for Division 2
train_logical_div2 <- rep(FALSE, n_samples)
test_logical_div2 <- rep(FALSE, n_samples)

train_logical_div2[train_indices_div2] <- TRUE
test_logical_div2[test_indices_div2] <- TRUE

# Division 3: Regular division (first 70% train, last 30% test)
train_indices_div3 <- 1:floor(0.7 * n_samples)
test_indices_div3 <- (floor(0.7 * n_samples) + 1):n_samples

# Create logical vectors for Division 3
train_logical_div3 <- rep(FALSE, n_samples)
test_logical_div3 <- rep(FALSE, n_samples)

train_logical_div3[train_indices_div3] <- TRUE
test_logical_div3[test_indices_div3] <- TRUE


train_data_div1 <- data.frame(GC_20K = GC_20K_clean[train_logical_div1], reads_20K = reads_20K_clean[train_logical_div1])
train_data_div2 <- data.frame(GC_20K = GC_20K_clean[train_logical_div2], reads_20K = reads_20K_clean[train_logical_div2])
train_data_div3 <- data.frame(GC_20K = GC_20K_clean[train_logical_div3], reads_20K = reads_20K_clean[train_logical_div3])

# Define knots for the B-spline
knots_bs <- c(0.415, 0.45, 0.54)

# Fit the B-spline model using the train data for each division
reg_bs_train_div1 <- lm(reads_20K ~ bs(GC_20K, knots = knots_bs, degree = 3, Boundary.knots = c(min(GC_20K_clean), max(GC_20K_clean))), data = train_data_div1)
reg_bs_train_div2 <- lm(reads_20K ~ bs(GC_20K, knots = knots_bs, degree = 3, Boundary.knots = c(min(GC_20K_clean), max(GC_20K_clean))), data = train_data_div2)
reg_bs_train_div3 <- lm(reads_20K ~ bs(GC_20K, knots = knots_bs, degree = 3, Boundary.knots = c(min(GC_20K_clean), max(GC_20K_clean))), data = train_data_div3)

# Create new data for prediction
new_data <- data.frame(GC_20K = seq(min(GC_20K_clean), max(GC_20K_clean), length.out = 1000))

# Predict for each division
predicted_div1 <- predict(reg_bs_train_div1, newdata = new_data)
predicted_div2 <- predict(reg_bs_train_div2, newdata = new_data)
predicted_div3 <- predict(reg_bs_train_div3, newdata = new_data)
```


```{r train_viz}

# Plot the data and the B-spline regression lines for each division
plot(GC_20K_clean, reads_20K_clean, pch = 16, cex = 0.5, col = rgb(0, 0, 0, 0.7),
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     xlim = c(min(GC_20K_clean), max(GC_20K_clean)),
     ylim = c(0, 3500),
     main = "B-Spline Regression on Train Data")

# Plot the B-spline regression lines for each division
lines(new_data$GC_20K, predicted_div1, col = "blue", lwd = 2)
lines(new_data$GC_20K, predicted_div2, col = "red", lwd = 2)
lines(new_data$GC_20K, predicted_div3, col = "green", lwd = 2)

# Add vertical lines to indicate breakpoints
abline(v = knots_bs, lty = 2, col = "darkgray", lwd = 1.5)

# Add legend
legend("topleft", legend = c("70% Random Regions (Div 1)", "70% Random Bins (Div 2)", "70% First Bins on Left (Div 3)"), col = c("blue", "red", "green"), lwd = 2, cex = 0.75, bty = "n")

```

1.c+d
```{r}
# Subset test data for each division
test_data_div1 <- data.frame(GC_20K = GC_20K_clean[test_logical_div1], reads_20K = reads_20K_clean[test_logical_div1])
test_data_div2 <- data.frame(GC_20K = GC_20K_clean[test_logical_div2], reads_20K = reads_20K_clean[test_logical_div2])
test_data_div3 <- data.frame(GC_20K = GC_20K_clean[test_logical_div3], reads_20K = reads_20K_clean[test_logical_div3])

# Predict for test data in each division
test_data_div1$predicted <- predict(reg_bs_train_div1, newdata = test_data_div1)
test_data_div2$predicted <- predict(reg_bs_train_div2, newdata = test_data_div2)
test_data_div3$predicted <- predict(reg_bs_train_div3, newdata = test_data_div3)

# Define a function to calculate R-squared, MAE, and MSE
calculate_metrics <- function(actual, predicted) {
  r_squared <- 1 - sum((actual - predicted)^2) / sum((actual - mean(actual))^2)
  mae <- mean(abs(actual - predicted))
  mse <- mean((actual - predicted)^2)
  return(list(R_squared = r_squared, MAE = mae, MSE = mse))
}

# Calculate metrics for train and test data in each division
metrics_train_div1 <- calculate_metrics(train_data_div1$reads_20K, predict(reg_bs_train_div1, newdata = train_data_div1))
metrics_test_div1 <- calculate_metrics(test_data_div1$reads_20K, test_data_div1$predicted)
metrics_train_div2 <- calculate_metrics(train_data_div2$reads_20K, predict(reg_bs_train_div2, newdata = train_data_div2))
metrics_test_div2 <- calculate_metrics(test_data_div2$reads_20K, test_data_div2$predicted)
metrics_train_div3 <- calculate_metrics(train_data_div3$reads_20K, predict(reg_bs_train_div3, newdata = train_data_div3))
metrics_test_div3 <- calculate_metrics(test_data_div3$reads_20K, test_data_div3$predicted)

# Print metrics
print(metrics_train_div1)
print(metrics_test_div1)
print(metrics_train_div2)
print(metrics_test_div2)
print(metrics_train_div3)
print(metrics_test_div3)

# Plot the data and the B-spline regression lines for each division
plot(GC_20K_clean, reads_20K_clean, pch = 16, cex = 0.5, col = rgb(0, 0, 0, 0.3),
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     xlim = c(min(GC_20K_clean), max(GC_20K_clean)),
     ylim = c(0, max(reads_20K_clean)),
     main = "Piecewise Polynomial Regression")

# Plot the B-spline regression lines for each division
lines(new_data$GC_20K, predicted_div1, col = "blue", lwd = 2)
lines(new_data$GC_20K, predicted_div2, col = "red", lwd = 2)
lines(new_data$GC_20K, predicted_div3, col = "green", lwd = 2)

# Plot the test data with predictions and add vertical lines for prediction errors
points(test_data_div1$GC_20K, test_data_div1$reads_20K, col = rgb(0, 0, 1, 0.5), pch = 1)
points(test_data_div1$GC_20K, test_data_div1$predicted, col = rgb(0, 0, 1, 0.5), pch = 16)
segments(test_data_div1$GC_20K, test_data_div1$reads_20K, test_data_div1$GC_20K, test_data_div1$predicted, col = rgb(0, 0, 1, 0.3), lty = 2)

points(test_data_div2$GC_20K, test_data_div2$reads_20K, col = rgb(1, 0, 0, 0.5), pch = 1)
points(test_data_div2$GC_20K, test_data_div2$predicted, col = rgb(1, 0, 0, 0.5), pch = 16)
segments(test_data_div2$GC_20K, test_data_div2$reads_20K, test_data_div2$GC_20K, test_data_div2$predicted, col = rgb(1, 0, 0, 0.3), lty = 2)

points(test_data_div3$GC_20K, test_data_div3$reads_20K, col = rgb(0, 1, 0, 0.5), pch = 1)
points(test_data_div3$GC_20K, test_data_div3$predicted, col = rgb(0, 1, 0, 0.5), pch = 16)
segments(test_data_div3$GC_20K, test_data_div3$reads_20K, test_data_div3$GC_20K, test_data_div3$predicted, col = rgb(0, 1, 0, 0.3), lty = 2)

# Add vertical lines to indicate breakpoints
abline(v = knots_bs, lty = 2, col = "darkgray", lwd = 1.5)

# Add legend
legend("topleft", legend = c("B-spline Div 1", "B-spline Div 2", "B-spline Div 3"), col = c("blue", "red", "green"), lwd = 2, cex = 0.7)
```



#### Sanity checks for splitting process

```{r qa_split}
#+++++++++++ Check Proportions
# Division 1
props_div1 = helpers$chk_ratio(train_div1, test_div1, 14/20)
cat("Div1 props\n", 
    "Test proportion:", props_div1$test_ratio, "\n",
    "Train proportion:", props_div1$train_ratio, "\n",
    "Expected proportion of train:", props_div1$expected_train_ratio,
     "\n\n"
    )

# Division 2
props_div2 = helpers$chk_ratio(train_div2, test_div2, 0.7)
cat("Div2 props\n", 
    "Test proportion:", props_div2$test_ratio, "\n",
    "Train proportion:", props_div2$train_ratio, "\n",
    "Expected proportion of train:", props_div2$expected_train_ratio,
     "\n\n"
    )

# Division 3
props_div3 = helpers$chk_ratio(train_div3, test_div3, 0.7)
cat("Div3 props\n", 
    "Test proportion:", props_div3$test_ratio, "\n",
    "Train proportion:", props_div3$train_ratio, "\n",
    "Expected proportion of train:", props_div3$expected_train_ratio,
     "\n\n"
    )

#+++++++++++ Check for Overlaps
cat("\n OVERLAP TEST \n\n")

# Division 1
overlaps_div1 = helpers$chk_ovrlp(train_indices_div1, test_indices_div1)
paste0("Has Div1 passed overlap test? ", overlaps_div1)

# Division 2
overlaps_div2 = helpers$chk_ovrlp(train_indices_div2, test_indices_div2)
paste0("Has Div2 passed overlap test? ", overlaps_div2)

# Division 3
overlaps_div3 = helpers$chk_ovrlp(train_indices_div3, test_indices_div3)
paste0("Has Div3 passed overlap test? ", overlaps_div3)

#+++++++++++ Check Data Integrity

cat("\n SIZE TEST\n\n")

# debugonce(helpers$chk_size) # @CB

# Division 1
size_div1 = helpers$chk_size(train_div1, test_div1, reads_20K)
paste0("Has Div1 passed size test? ", size_div1)

# Division 2
size_div2 = helpers$chk_size(train_div2, test_div2, reads_20K)
paste0("Has Div2 passed size test? ", size_div2)

# Division 3
size_div3 = helpers$chk_size(train_div3, test_div3, reads_20K)
paste0("Has Div3 passed size test? ", size_div3)

```







## Q1.b+c+d


```{r fit_compare}
# Define knots by quantiles (0.25, 0.50, 0.75 of the data range)
# knots_bs = c(-0.67, 0, 0.67)  # Standardized positions for knots

# Fit Spline Regression using BSplines
# Warning in bs(x_train_scaled, degree = 3L, knots = c(-0.67, 0, 0.67), Boundary.knots = c(-1.73175054161184,  :
#   some 'x' values beyond boundary knots may cause ill-conditioned bases
 
bspline_div1 = helpers$fit_bspline(train_div1, test_div1, knots_bs)
bspline_div2 = helpers$fit_bspline(train_div2, test_div2, knots_bs)
bspline_div3 = helpers$fit_bspline(train_div3, test_div3, knots_bs)

# Division 1
print("Division 1: Train Metrics")
print(bspline_div1$metrics_train)
print("Division 1: Test Metrics")
print(bspline_div1$metrics_test)

# Division 2
print("Division 2: Train Metrics")
print(bspline_div2$metrics_train)
print("Division 2: Test Metrics")
print(bspline_div2$metrics_test)

# Division 3
print("Division 3: Train Metrics")
print(bspline_div3$metrics_train)
print("Division 3: Test Metrics")
print(bspline_div3$metrics_test)

# Plotting the results for visual inspection
helpers$plot_bspline(train_div1, test_div1, bspline_div1$pred_train, bspline_div1$pred_test, "Division 1: BSpline Regression")

helpers$plot_bspline(train_div2, test_div2, bspline_div2$pred_train, bspline_div2$pred_test, "Division 2: BSpline Regression")

helpers$plot_bspline(train_div3, test_div3, bspline_div3$pred_train, bspline_div3$pred_test, "Division 3: BSpline Regression")


```


```{r manipulate}
pl = 2000
plot_with_abline <- function(x) {
    plot(1:length(residuals), residuals, 
         main = "Residuals vs. Chromosome Location",
         xlab = "Bin Location",
         ylab = "Residuals",
         pch = 20)
    abline(h = 0, col = "red", lty = 2)
    abline(h = 4000, col = "red", lw = 2)
}

manipulate(
    plot_with_abline(x),
    x = slider(1, length(reads_20K_clean) - pl + 1, initial = 200)
)

```


