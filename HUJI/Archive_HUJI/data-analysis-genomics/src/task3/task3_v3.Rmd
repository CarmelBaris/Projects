---
title: "Task2"
date: Sys.Date()
output:
  html_document:
    code_folding: show
  pdf_document: default
editor_options:
  markdown:
    wrap: sentence
---

Team 6:
 - Shawn Yakir , 315714980, shawnyakir@gmail.com  
 - Sarah Levitz, 324673623, sarah.levitz@mail.huji.ac.il
 - Carmel Baris, 318455276, carmel.baris@mail.huji.ac.il


### Libraries used

```{r libraries, message=FALSE, warning=FALSE, include=FALSE}
library('ggplot2')
library('data.table')
library('tidyr')
library('dplyr')
library('tictoc')
```


### Paths and Data


```{r data_A, message=FALSE, warning=FALSE, include=FALSE}

#helper functions
source("help_funcs.R")

# Load the data (Group A)
reads_file = '~/Carmel/RProjects/Lab_Benjamini/data/TCGA-13-0723-01A_lib2_all_chr1.forward'
# reads_file = "/Users/alevi/Downloads/ATCGA-13-0723-01A_lib2_all_chr1.forward/TCGA-13-0723-01A_lib2_all_chr1.forward"

chr1_reads = fread(reads_file) 
colnames(chr1_reads) = c("Chrom","Loc","FragLen")

# get read line of actual data
locations = chr1_reads$Loc
beg_region = 1
end_region = 1+2e07

read_20K = getReadLine(locations, beg_region, end_region) #20K

# logical vector s.t. TRUE if condition is met (within selected cutoff range)
no_outlier = !is.na(read_20K) & read_20K > 600 & read_20K < 2600

# exclude outliers
h_no_out = hist(read_20K[no_outlier],breaks=100, plot = FALSE)

```


## Introduction 




## Avg coverage and distance between reads
```{r}
last_read = as.numeric(chr1_reads[nrow(chr1_reads),"Loc"])

# {Average Coverage} = {Total Reads}/{Total Bases}
avg_coverage = nrow(chr1_reads)*(1 / last_read)



```

## Compare the expected distribution versus the actual distribution

```{r}
# produce many instances of uniform variables
set.seed(1)
nsamp = 100e+06
max_samp = nsamp * 10
unif_dat = runif(n = nsamp, 0,max_samp )
s_dat = sort(unif_dat)

# obtain Poisson by counting occurrences in equal-size intervals 
k = 1000
output_1K = binReads(ceiling(s_dat), k)

```

```{r}

```


### Observed distribution of the data (count)
```{r}

# Filter out values for 0-5 and aggregate 5+ as 5+
line_filtered = ifelse(read_20K > 5, 5, read_20K)

# Initialize observed counts (numeric vector) with names for 0 to 5 and "5+"
obs_cnt_singl = setNames(numeric(7), c(as.character(0:5), "5+"))

# Calculate counts for 0 to 5
tic()
obs_cnt_singl[as.character(0:5)] = table(factor(line_filtered, levels = 0:5))
toc()

# Calculate and add the "5+" count
obs_cnt_singl["5+"] = sum(read_20K > 5)

# Round the counts to 2 decimal places and display the result
obs_cnt_singl = round(obs_cnt_singl, 2)
obs_cnt_singl
# observed counts of single reads (unbinned)
# =========================================================================== #
#        0        1        2        3        4        5       5+ 
# 18279693  1610109   103067     6187      581      363      228 
# =========================================================================== #

```

### Theoretical Poission density

```{r}

# model_prob = dpois(0:39,lambda = reg_lambda)

```

```{r}

Nsingle = length(read_20K)
lambda = mean(read_20K)  # Mean of observed counts

# Calculate expected probabilites for 0-5 and aggregate the rest as 5+
obs_prob_singl = obs_cnt_singl / Nsingle
obs_prob_single = sum(read_20K) / Nsingle # in region

# Calculate the expected distribution for a uniform Poisson model
exp_pois_upto5 = dpois(0:5, lambda)

exp_pois_plus5 = sum(dpois(6:max(read_20K), lambda))

# join to merged probs object
expected_prob = c(exp_pois_upto5, exp_pois_plus5)

expected_prob = round(expected_prob, 2) 
names(expected_prob) = c(as.character(0:5), "5+") # add column names
expected_prob = round(expected_prob, 2) 
names(expected_prob) = c(as.character(0:5), "5+") # add column names

```



### Comparing the densities in a table:
```{r}


# Round the counts to 5 decimal places
obs_prob_singl_ = round(obs_prob_singl, 5)

expected_prob_ = round(expected_prob, 5)

# Create a data frame
prob_df_ = data.frame(
  pois_val_ = c("expected", "observed"),
  "0"  = c(expected_prob_[1], obs_prob_singl_[1]),
  "1"  = c(expected_prob_[2], obs_prob_singl_[2]),
  "2"  = c(expected_prob_[3], obs_prob_singl_[3]),
  "3"  = c(expected_prob_[4], obs_prob_singl_[4]),
  "4"  = c(expected_prob_[5], obs_prob_singl_[5]),
  "5"  = c(expected_prob_[6], obs_prob_singl_[6]),
  "5+" = c(expected_prob_[7], obs_prob_singl_[7])
  )

# Create a data frame rounded to 2 decimal points and display the result

obs_prob_singl = round(obs_prob_singl, 2)
expected_prob = round(expected_prob, 2)
prob_df = data.frame(
  pois_val = c("expected", "observed"),
  "0"  = c(expected_prob[1], obs_prob_singl[1]),
  "1"  = c(expected_prob[2], obs_prob_singl[2]),
  "2"  = c(expected_prob[3], obs_prob_singl[3]),
  "3"  = c(expected_prob[4], obs_prob_singl[4]),
  "4"  = c(expected_prob[5], obs_prob_singl[5]),
  "5"  = c(expected_prob[6], obs_prob_singl[6]),
  "5+" = c(expected_prob[7], obs_prob_singl[7])
  )

print(prob_df, right = TRUE)


```


Graphical comparison:
```{r}
# Create a data frame for the graphical comparison
comparison_df = data.frame(
  Count = names(obs_prob_singl),
  Observed = as.numeric(obs_prob_singl),
  Expected = as.numeric(expected_prob)
)

# Reshape data to long format using pivot_longer
comparison_df_long = comparison_df %>%
  pivot_longer(cols = c("Observed", "Expected"), names_to = "Type", values_to = "Value")

# Plot
ggplot(comparison_df_long, aes(x = Count, y = Value, fill = Type)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9)) +
  scale_fill_manual(values = c("Observed" = "darkblue", "Expected" = "lightblue")) +
  labs(title = "Observed vs Expected Poisson Distribution Probabilities",
       y = "Probabilities",
       x = "Read Counts") +
  theme_minimal()


```




```{r}
# Step 5: Numerical metric (Chi-square goodness-of-fit test)
chisq_test = chisq.test(as.numeric(obs20K_count), p = exp20K_count/sum(exp20K_count))
print(chisq_test)

```




## Short summary

Based on our analysis of the data, it seems that the reads are not distributed normally or uniformly.
