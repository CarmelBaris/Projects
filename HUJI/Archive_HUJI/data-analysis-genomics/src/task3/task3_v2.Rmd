---
title: "Task2"
date: Sys.Date()
output:
  html_document:
    code_folding: show
  pdf_document: default
editor_options:
  markdown:
    wrap: sentence
---

Team 6:
 - Shawn Yakir , 315714980, shawnyakir@gmail.com  
 - Sarah Levitz, 324673623, sarah.levitz@mail.huji.ac.il
 - Carmel Baris, 318455276, carmel.baris@mail.huji.ac.il


### Libraries used

```{r libraries, message=FALSE, warning=FALSE, include=FALSE}
library('ggplot2')
library('data.table')
library('tidyr')
library('dplyr')
library('tictoc')
source("help_funcs.R")
```


### Paths and Data


```{r data_A, message=FALSE, warning=FALSE, include=FALSE}


# Load the data (Group A)
reads_file = 'C:/Users/user/Documents/Carmel/Projects/HUJI/Archive_HUJI/data-analysis-genomics/data/TCGA-13-0723-01A_lib2_all_chr1.forward'
# reads_file = "/Users/alevi/Downloads/ATCGA-13-0723-01A_lib2_all_chr1.forward/TCGA-13-0723-01A_lib2_all_chr1.forward"

chr1_reads = fread(reads_file) 
colnames(chr1_reads) = c("Chrom","Loc","FragLen")
```


## Introduction 

<!-- This week we analyzed a text-based sequencing data file used in Paired End Sequencing. It stores short reads that were generated using Next Generation Sequencing (NGS). To clarify, in our work 'reads' refer to the first read of a DNA fragment. These fragments differ in the locaiton of their first read, and in their size. \n -->

<!-- We attempted to identify trends in the data. To be specific, our focus was on understanding the marginal and spatial distribution of reads along the chromosome being sequenced. \n -->


```{r}
# produce many instances of uniform variables
set.seed(1)
nsamp = 100e+06
max_samp = nsamp * 10
unif_dat = runif(n = nsamp, 0,max_samp )
s_dat = sort(unif_dat)

# obtain Poisson by counting occurrences in equal-size intervals 
k = 1000
output_1K = binReads(ceiling(s_dat), k)

```




## Compare the expected distribution versus the actual distribution

```{r}

# get read line of actual data
locations = chr1_reads$Loc
beg_region = 1
end_region = 2e07

read_line = getReadLine(locations, beg_region, end_region)

```


### Observed distribution of the data (count)
```{r}

# Filter out values for 0-5 and aggregate 5+ as 5+
line_filtered = ifelse(read_line > 5, 5, read_line)

# Initialize observed counts (numeric vector) with names for 0 to 5 and "5+"
obs_cnt_singl = setNames(numeric(7), c(as.character(0:5), "5+"))

# Calculate counts for 0 to 5
tic()
obs_cnt_singl[as.character(0:5)] = table(factor(line_filtered, levels = 0:5))
toc()

# Calculate and add the "5+" count
obs_cnt_singl["5+"] = sum(read_line > 5)

# Round the counts to 2 decimal places and display the result
obs_cnt_singl = round(obs_cnt_singl, 2)

# observed counts of single reads (unbinned)
# =========================================================================== #
#        0        1        2        3        4        5       5+ 
# 18279693  1610109   103067     6187      581      363      228 
# =========================================================================== #

```

### Theoretical Poission distribution

```{r}

# Yuval's code
# Calculate the expected distribution for a uniform Poisson model
# Nsingle = length(read_line)
# reg_lambda=sum(read_line)/Nsingle    # in region
# model_prob = dpois(0:39,lambda = reg_lambda)

```

```{r}

Nsingle = length(read_line)
lambda = mean(read_line)  # Mean of observed counts

# Calculate expected probabilites for 0-5 and aggregate the rest as 5+
obs_prob_singl = obs_cnt_singl / Nsingle

exp_pois_upto5 = dpois(0:5, lambda)

exp_pois_plus5 = sum(dpois(6:max(read_line), lambda))

# join to merged probs object
expected_prob = c(exp_pois_upto5, exp_pois_plus5)

expected_prob = round(expected_prob, 2) 
names(expected_prob) = c(as.character(0:5), "5+") # add column names

```



### Comparing the counts in a table:
```{r}


# Round the counts to 2 decimal places and display the result
obs_prob_singl = round(obs_prob_singl, 5)

expected_prob = round(expected_prob, 5)

# Create a data frame
prob_df = data.frame(
  pois_val = c("expected", "observed"),
  "0"  = c(expected_prob[1], obs_prob_singl[1]),
  "1"  = c(expected_prob[2], obs_prob_singl[2]),
  "2"  = c(expected_prob[3], obs_prob_singl[3]),
  "3"  = c(expected_prob[4], obs_prob_singl[4]),
  "4"  = c(expected_prob[5], obs_prob_singl[5]),
  "5"  = c(expected_prob[6], obs_prob_singl[6]),
  "5+" = c(expected_prob[7], obs_prob_singl[7])
  )

print(prob_df, right = TRUE)


```


Graphical comparison:
```{r}
# Create a data frame for the graphical comparison
comparison_df = data.frame(
  Count = names(obs_prob_singl),

  Observed = as.numeric(obs_prob_singl),

  Expected = as.numeric(expected_prob)
)

# Reshape data to long format using pivot_longer
comparison_df_long = comparison_df %>%
  pivot_longer(cols = c("Observed", "Expected"), names_to = "Type", values_to = "Value")

# Plot
ggplot(comparison_df_long, aes(x = Count, y = Value, fill = Type)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9)) +
  scale_fill_manual(values = c("Observed" = "blue", "Expected" = "lightblue")) +
  labs(title = "Observed vs Expected Poisson Distribution Probabilities",
       y = "Probabilities",
       x = "Read Counts") +
  theme_minimal()


```


```{r}
# Define the bin size (at least 5K nucleobases)
bin_size = 20e+03
end_region = max(chr1_reads$Loc)
num_bins = ceiling(end_region / bin_size)
# Function to count the number of fragments per bin
countFragmentsPerBin = function(locations, bin_size, num_bins) {
  bins = rep(0, num_bins)
  for (loc in locations) {
    bin_index = ceiling(loc / bin_size)
    bins[bin_index] = bins[bin_index] + 1
  }
  return(bins)
}
tic()
bins = countFragmentsPerBin(chr1_reads$Loc, bin_size, num_bins)
toc()
```

```{r}
# Step 2: Filter out outlier values and estimate histogram
bin_f = !is.na(bins) & bins <= 5
bins_filtered = bins[bin_f]

# Step 2: Filter out outlier values and estimate histogram
# no_outlier = !is.na(bins) & bins<= 5
# bins_filtered = hist(bins[no_outlier],breaks=100, plot = FALSE)

# line_filtered = ifelse(read_line > 5, 5, read_line)


hist_data = hist(bins_filtered, breaks = seq(0, 5, by = 1), plot = FALSE)
hist_data = hist(bins_filtered, breaks = seq(0, 5, by = 1), plot = FALSE)
obs20K_count = hist_data$counts
obs20K_count["5+"] = sum(bins > 5)

# Step 3: Calculate expected distribution using Poisson model
N20k = length(bins)
lambda20k = sum(read_line)/N20k
# lambda = mean(bins)
exp20K_count = dpois(0:5, lambda20k) * N20k
exp20K_count["5+"] = sum(dpois(6:max(bins), lambda20k) * N20k)

# Merge observed and expected counts
obs20K_count = c(obs20K_count, sum(bins > 5))
names(obs20K_count) = c(0:5, "5+")
exp20K_count = c(exp20K_count, sum(dpois(6:max(bins), lambda20k) * N20k))
names(exp20K_count) = c(0:5, "5+")
```


# Step 4: Visual comparison

```{r}
comparison_df = data.frame(
  Count = names(obs20K_count),
  Observed = as.numeric(obs20K_count),
  Expected = as.numeric(exp20K_count[!is.na(exp20K_count)])
)

ggplot(comparison_df, aes(x = Count)) +
  geom_bar(aes(y = Observed, fill = "Observed"), stat = "identity", position = "dodge") +
  geom_bar(aes(y = Expected, fill = "Expected"), stat = "identity", position = "dodge", alpha = 0.5) +
  scale_fill_manual(values = c("Observed" = "blue", "Expected" = "lightblue")) +
  labs(title = "Observed vs Expected Poisson Distribution",
       y = "Counts",
       x = "Read Counts") +
  theme_minimal()
```

### Chi-square goodness-of-fit test
```{r}
# Step 5: Numerical metric (Chi-square goodness-of-fit test)
chisq_test = chisq.test(as.numeric(obs20K_count), p = exp20K_count/sum(exp20K_count))
print(chisq_test)

```




## Short summary

Based on our analysis of the data, it seems that the reads are not distributed normally or uniformly.

