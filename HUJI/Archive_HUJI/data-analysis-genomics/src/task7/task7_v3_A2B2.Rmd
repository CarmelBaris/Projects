---
title: "Lab Task 6"
author: "Group 6"
date: Sys.Date()
output:
  html_document:
    code_folding: show
editor_options: 
  markdown: 
    wrap: sentence
---

Group members:

- Shawn Yakir , 315714980,  shawn.yakir@mail.huji.ac.il
- Sarah Levitz, 324673623, sarah.levitz@mail.huji.ac.il
- Carmel Baris, 318455276, carmel.baris@mail.huji.ac.il 

### Clean the environment
```{r clean}
rm(list = ls())
```

### Libraries used

```{r libraries}
library('splines')
```


### Paths
```{r paths}
path = "~/Carmel/RProjects/Lab_Benjamini/data"
# path = "/Users/alevi/Downloads/"
# path = "\\Users\\shawn\\Desktop\\"
```


### Helper functions
```{r helpers}
helpers_file = file.path(path, "help_funcs.R")
source(helpers_file)
helpers = list(loadRData = loadRData, binReads = binReads)
```


### Load data
```{r dat}
load(sprintf("%s/reads_100_A2.rda",path))
load(sprintf("%s/reads_100_B2.rda",path))
load(sprintf("%s/GC_100.rda",path))
GC_100=GC_100[1: (length(reads_100_A2)) ]
```

### Binning
```{r binning}
binsize = 25
chr1t_mat = matrix(reads_100_A2, nr = binsize)
# chr1t_mat[,1:2]
# reads_100_A2[1:2]
reads_2.5K_t2 = colSums(chr1t_mat)

chr1n_mat = matrix(reads_100_B2, nr = binsize)
# chr1n_mat[,1:2]
# reads_100_B2[1:2]
reads_2.5K_n2 = colSums(chr1n_mat)

gc_mat = matrix(GC_100,nr=binsize)
GC_2.5K = colMeans(gc_mat)
```






### Outliers
```{r outliers}
# outliers of gc percent per bin
zeros_GC = GC_2.5K == 0 #bins w/o GC content
small_GC = GC_2.5K <= 0.3 & GC_2.5K > 0 #low-GC content bins (<30%)
valid_GC = !(zeros_GC | small_GC) #bins w/ at least 30% GC content

# identify outliers of reads count per bin
z_scores_n2 = (reads_2.5K_n2 - mean(reads_2.5K_n2)) / sd(reads_2.5K_n2)
z_scores_t2 = (reads_2.5K_t2 - mean(reads_2.5K_t2)) / sd(reads_2.5K_t2)
xtreme_reads_n2 = abs(z_scores_n2) > 2
xtreme_reads_t2 = abs(z_scores_t2) > 2

# create new variables without outliers
outliers = (zeros_GC | small_GC | xtreme_reads_n2 | xtreme_reads_t2 | xtreme_reads_n2)
reads_2.5K_clean_n2 = reads_2.5K_n2 [!outliers]
reads_2.5K_clean_t2 = reads_2.5K_t2[!outliers]
GC_2.5K_clean = GC_2.5K[!outliers]
```

### Fitting bspline regression
```{r fit}
create_est_f = function(X, Y, degree, knots) {
  lknot <- min(X)
  rknot <- max(X)
  lm(Y ~ bs(X, degree = degree, knots = knots, Boundary.knots = c(lknot, rknot)))
}

```


```{r sampling_2.5K}
set.seed(50)
samp1 = sample(length(reads_2.5K_n2),5000)
```

```{r plot_adj}
# Plot adjacent

par(mfcol =c(2,1),mar =c(1,5,1,1))
plot(GC_2.5K[samp1],reads_2.5K_n2[samp1],ylim = c(0,600),xlim = c(0,.75), cex = 0.4, pch=20, ylab="Healthy 1")
abline(v=c(0.35,0.45))
plot(GC_2.5K[samp1],reads_2.5K_t2[samp1],ylim = c(0,600),xlim = c(0,.75),cex = 0.4, pch=20, ylab="Tumor 1")
abline(v=c(0.35,0.45))

par(mfcol =c(1,2),mar =c(1,1,1,1))
plot(GC_2.5K[samp1],reads_2.5K_n2[samp1],ylim = c(0,600),xlim = c(0,.75), cex = 0.4, pch=20, main="Healthy 1")
abline(h=c(180,400))
plot(GC_2.5K[samp1],reads_2.5K_t2[samp1],ylim = c(0,600),xlim = c(0,.75),cex = 0.4, pch=20, main="Tumor 1")
abline(h=c(180,400))

par(mfcol =c(1,1))

```


## Learn parameters from chromosome 1

```{r}
l_1n = length(reads_2.5K_n2)
l_1t = length(reads_2.5K_t2)

GC=GC_2.5K[1:l_1n]
mod_1n = lm(reads_2.5K_n2~poly(GC, degree = 3),subset = reads_2.5K_n2>50 & reads_2.5K_n2<600 )

pred_range = seq(0.2,0.75,0.01)
resp_n = predict(mod_1n,list(GC=pred_range))
preds1n = predict(mod_1n,list(GC=GC_2.5K))

par(mfcol = c(1,1),mar = c(3,5,3,3))
plot(GC_2.5K[samp1],reads_2.5K_n2[samp1],ylim = c(0,600),xlim = c(0.2,.75), cex = 0.5, pch=20, ylab = "Healthy 1")
lines(pred_range, resp_n,col = 4,lw=3)

```


```{r}
GC=GC_2.5K[1:l_1t]
mod_1t = lm(reads_2.5K_t2~poly(GC, degree = 3),subset = (reads_2.5K_t2>50)&(reads_2.5K_t2<500))

pred_range = seq(0.2,0.75,0.01)
resp_t = predict(mod_1t,list(GC=pred_range))
preds1t = predict(mod_1t,list(GC=GC_2.5K))

par(mfcol = c(1,1),mar = c(3,3,3,3))
plot(GC_2.5K[samp1],reads_2.5K_t2[samp1],ylim = c(0,600),xlim = c(0.2,.75), cex = 0.5, pch=20, main = "Tumor 1")
lines(pred_range, resp_t,col = 2,lw=3)
lines(pred_range, resp_n,col = 4,lw=3)
```


## One sample corrections
```{r func_fix}
one_sample_correct = function(samp, preds) {
  one_correct = (samp)/(preds)
  return(one_correct)
}
```

```{r med_fix}
corrected_1n = one_sample_correct (reads_2.5K_n2,preds1n[1:l_1n])
uncorrected_1n = (reads_2.5K_n2)/median(reads_2.5K_n2) 

corrected_1t = one_sample_correct (reads_2.5K_t2,preds1t[1:l_1t])
uncorrected_1t = (reads_2.5K_t2)/median(reads_2.5K_t2) 

range_a = 5000:6000
```

```{r plot_bef_af}
par(mfcol = c(2,1),mar = c(2,5,2,2))

plot(uncorrected_1n[range_a], ylim = c(0,2.5),cex = 0.5,pch=20, ylab = "Before Fix", main = "Healthy 1")
abline(h=1,col=4)
plot(corrected_1n[range_a], ylim = c(0,2.5),cex = 0.5,pch=20, ylab = "Corrected")
abline(h=1,col=4)

plot(uncorrected_1t[range_a], ylim = c(0,2.5),cex = 0.5,pch=20, ylab = "Before Fix", main = "Tumor 1")
abline(h=1,col=4)
plot(corrected_1t[range_a], ylim = c(0,2.5),cex = 0.5, pch=20, ylab = "Corrected")
abline(h=1,col=4)

```

```{r plot_tn_befaf}
par(mfcol = c(2,1),mar = c(2,5,2,2))

plot(uncorrected_1n[range_a], ylim = c(0,2.5),cex = 0.5,pch=20, ylab = "Healthy 1", main = "Before Fix")
abline(h=1,col=4)

plot(uncorrected_1t[range_a], ylim = c(0,2.5),cex = 0.5,pch=20, ylab = "Tumor 1")
abline(h=1,col=4)

plot(corrected_1n[range_a], ylim = c(0,2.5), cex = 0.5, pch=20, ylab = "Healthy 1", main = "Corrected")
abline(h=1,col=4)
plot(corrected_1t[range_a], ylim = c(0,2.5), cex = 0.5, pch=20, ylab = "Tumor 1")
abline(h=1,col=4)

```


```{r plot_tn_stacked}
par(mfcol = c(4,1),mar = c(2,5,2,2))

plot(uncorrected_1n[range_a], ylim = c(0,2.5), cex = 0.5, pch=20, ylab = "Healthy 1", main = "Before Fix")
abline(h=1,col=4)
plot(uncorrected_1t[range_a], ylim = c(0,2.5), cex = 0.5, pch=20, ylab = "Tumor 1")
abline(h=1,col=4)

plot(corrected_1n[range_a], ylim = c(0,2.5), cex = 0.5, pch=20, ylab = "Healthy 1", main = "Corrected")
abline(h=1,col=4)
plot(corrected_1t[range_a], ylim = c(0,2.5), cex = 0.5, pch=20, ylab = "Tumor 1")
abline(h=1,col=4)

```

### Introduction 

This week we began to estimate the number of genomic copies, for a given bin. \n
Our original assumption is that this estimate should be proportional to the coverage, i.e. the number of reads in that bin. \n
So far we have learned that the distribution of $Y_k$, the coverage of bin $K$, depends on the GC content in that bin: $Y_K \sim f(GC_K) + \mathcal{E}_K$. \n
The estimated (predicted) coverage in bin $K$ is given by the following formula: $\hat{Y}_K \sim \hat{f}(GC_K) \ \cdot \ \eta$

is equivalent to the following conditional distribution: $\hat{𝔼}\big[ Y_K|X_K=x_k \big]$. We estimated this distribution using splines regression: $\hat{f}(GC)_K = 𝔼[Y_K | X_j \in Bin_K]$


### Q1. Estimating Number of copies

$$\hat{a}_K = \frac{Y_K}{\hat{f}(GC_K)} \cdot \frac{1}{\mathcal{E}_K}$$

```{r copies}

estimate_num_copies <- function(Y, X, Yhat, varNoise) {
  copies_est <- Y / Yhat

  # Apply noise if varNoise is provided
  if (!is.null(varNoise) && varNoise > 0) {
    noise = exp(rnorm(length(Y), mean = 0, sd = sqrt(varNoise)))
    copies_est = copies_est / noise
  }

  return(copies_est)
}

```


### Q2.a. Estimating for Specific Region

```{r wet_run}
# Select an area of 1000 consecutive cells
start_idx = 2000  # You can choose any starting index
end_idx = start_idx + 999
selected_GC_2.5K = GC_2.5K[start_idx:end_idx]
selected_reads_2.5K = reads_2.5K[start_idx:end_idx]

myknots = c(0.415, 0.45, 0.54)

est_f_select = create_est_f(X = selected_GC_2.5K, Y = selected_reads_2.5K, degree = 3, knots = myknots)
pred_reads_2.5K = est_f_select$fitted.values
tiny_v = 0.0001

est_a = estimate_num_copies(Y=selected_reads_2.5K, X=selected_GC_2.5K, Yhat=pred_reads_2.5K, varNoise=tiny_v)
summary(est_a)

# Show the marginal distribution
hist(est_a, main = "Marginal Distribution of Estimated Num of Copies", xlab = "Number of Copies (Est.)")

# Show the genome-wide distribution
plot(est_a, main = "Spatial Distribution of Estimated Num of Copies",
     xlab = "Chromosomal Index", ylab = "Number of Copies (Est.)",
     ylim = c(0,2), col=rgb(0,0,0,0.75))


# Color outliers in genome-wide distribution
upr_lim = 1.5
lwr_lim = 0.5
suspected = (est_a > upr_lim | est_a < lwr_lim)
abline(h=c(lwr_lim,upr_lim), lwd=1.3, lty=44, col="indianred2")
abline(h=1, lwd=2.5, col="royalblue")

```

### Q2.b. Measuring the Quality of the Estimator

We will compare two estimations, each with a different estimated sample variance of the errors.

```{r}

cat("Variance of noise/error:", sprintf("%.0004f", tiny_v), "\n")
cat("Avg num of copies (est):", round(mean(est_a),4), "\n")
mad_1 = mean(abs(est_a - round(mean(est_a),4)))
cat("Mean Absolute Deviation:", round(mad_1,4), "\n")

cat("\n")

small_v = 0.2
est_a0 = estimate_num_copies(Y=selected_reads_2.5K, X=selected_GC_2.5K, Yhat=pred_reads_2.5K, varNoise=small_v)

cat("Variance of noise/error:", sprintf("%.3f", small_v), "\n")
cat("Avg num of copies (est):", round(mean(est_a0),3), "\n")
mad1 = mean(abs(est_a0 - round(mean(est_a0),4)))
cat("Mean Absolute Deviation:", round(mad1,3), "\n")


```

### Q3. Evaluating the Quality of the Estimator
...

```{r}
estimate_v = function(Y, GC, Yhat) {

  # Calculate ratio
  ratio = Y / Yhat

  # Remove infinite and zero values
  ratio = ratio[is.finite(ratio) & ratio > 0]

  # Estimate v as the sample variance of the log of this ratio
  v_estimate = var(log(ratio))
  return(v_estimate)
}

est_f = create_est_f(X = GC_2.5K, Y = reads_2.5K, degree = 3, knots = myknots)
pred_reads_2.5K = est_f$fitted.values

est_v = estimate_v(reads_2.5K, GC_2.5K, pred_reads_2.5K)
print(round(est_v,2))

```


### Conclusions
* The estimator generally performs well with most estimated copy numbers centered around the expected value of 1.
* There is moderate noise in the data, and the estimator's performance degrades as noise increases.
* Outliers and regions with significant deviations from the expected number of copies need further investigation to understand if they are due to biological variations or noise.
* Fine-tuning the model parameters is essential for improving the estimator's accuracy and robustness.

