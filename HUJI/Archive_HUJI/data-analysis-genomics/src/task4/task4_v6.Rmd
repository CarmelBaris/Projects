---
title: "Lab Task 4: Approx. Regression w/ Piecewise Polynomial Model"
author: "Group 6"
date: Sys.Date()
output:
  html_document:
    code_folding: show
    theme: cerulean
    highlight: tango
editor_options: 
  markdown: 
    wrap: sentence
---

Group members:

- Shawn Yakir , 315714980, shawnyakir@gmail.com
- Sarah Levitz, 324673623, sarah.levitz@mail.huji.ac.il
- Carmel Baris, 318455276, carmel.baris@mail.huji.ac.il 


# Libraries

```{r library}
library(segmented)
library(data.table)

```

# Setting up environment & paths
```{r setup}
## ------------------------------------------------
## ---- DEPENDENCIES AKA FILES REQUIRED
## Make sure that all files are in the current working directory:
## 1. chr1_bases.rda
## 2. TCGA-13-0723-01A_lib2_all_chr1.forward
## 3. helpers_file
## 
## Note that in this lecture we'll create and save a new file:
## 4. reads_gc_5K.rda


## ------------------------------------------------
## ---- CLEAN ENVIRONMENT
rm(list = ls())


## ---- SET WORKING DIRECTORY
dir_name = "C:/Users/user/Documents/Carmel/Projects/HUJI/Archive_HUJI/data-analysis-genomics/data/"
# dir_name = "/Users/alevi/Downloads/"
# setwd(dir_name)
# getwd() # validate


## ------------------------------------------------
## ---- LOAD HELPER FUNCTIONS
helpers_file = file.path(dir_name, "help_funcs.R")
source(helpers_file)
```

# Loading data files 

```{r warning=FALSE}

## ------------------------------------------------
## ---- LOAD FILE OF NUCLEO_BASES (A,T,C,G)
bases_file = file.path(dir_name, "chr1_line.rda")
chr1_bases = loadRData(bases_file) # like Lecture1


## ------------------------------------------------
## ---- LOAD FILE OF READS LOCATIONS (THAT START A FRAGMENT)
  
reads_file_all = file.path(dir_name,"TCGA-13-0723-01A_lib2_all_chr1.forward")
chr1_reads = data.table::fread(reads_file_all) #like Lecture2
colnames(chr1_reads) = c("Chrom","Loc","FragLen")   


```


# Preprocessing data 

```{r, prep, include=FALSE}

## chunk should not have eval = FALSE!!
## o/w it messes up GC_5K

nreads = nrow(chr1_reads)
myLocations = as.numeric(chr1_reads$Loc)
last_read = myLocations[nreads]

binsize = 5000

## ------------------------------------------------
## ---- BINNING NUCLEO_BASES DATA
##
# per bin, count occurrences of each letter
bases_5K = binBases(chr1_bases, last_read, binsize) 

# per bin, sum occurrence counts of C & G only (GC content)
GC_5K <<- bases_5K[, 3] + bases_5K[, 4] 

# convert GC_5K into percentages
if(any(GC_5K>1)){ # This makes sure I don't repeat the command
  GC_5K = GC_5K / binsize
}

## ------------------------------------------------
## ---- BINNING READS COVERAGE DATA

# per bin, calculate reads coverage 
reads_5K = binReads(myLocations,binsize,last_read)
save(reads_5K, GC_5K,file = file.path(dir_path=dir_name,"reads_gc_5K.rda"))


## ------------------------------------------------
## ---- CLEARING UP ENV

gc()  # garbage collection
print("__________________")
rm("chr1_bases","chr1_reads") # remove from memory
ls()  # list objects in the environment
print("__________________")
gc()

# load data
reads_file_5K = file.path(dir_name, "reads_gc_5K.rda")
reads_gc_5K = loadRData(reads_file_5K)
# access using `$`:
#   GC_5K = reads_gc_5K$GC_5K
#   reads_5K = reads_gc_5K$reads_5K


```



# Remove outliers

```{r}
# Function to remove outliers based on IQR for paired data
remove_outliers_paired <- function(x, y) {
  q1_x <- quantile(x, 0.25)
  q3_x <- quantile(x, 0.75)
  iqr_x <- q3_x - q1_x
  lower_bound_x <- q1_x - 1.5 * iqr_x
  upper_bound_x <- q3_x + 1.5 * iqr_x

  q1_y <- quantile(y, 0.25)
  q3_y <- quantile(y, 0.75)
  iqr_y <- q3_y - q1_y
  lower_bound_y <- q1_y - 1.5 * iqr_y
  upper_bound_y <- q3_y + 1.5 * iqr_y

  mask <- (x > lower_bound_x & x < upper_bound_x) & (y > lower_bound_y & y < upper_bound_y)
  return(list(x = x[mask], y = y[mask]))
}

# Remove outliers from reads and GC content data
cleaned_data <- remove_outliers_paired(GC_5K, reads_5K)
GC_5K_clean <- cleaned_data$x
reads_5K_clean <- cleaned_data$y

```

# Question 1: Segmented polynomial regression


```{r pw_regression}

# Fit initial linear model
initial_model <- lm(reads_5K_clean ~ GC_5K_clean)
# Using `segmented` package for piecewise regression
seg_model <- segmented(initial_model, seg.Z = ~GC_5K_clean, npsi = 2)

# Extract breakpoints
breakpoints <- seg_model$psi[, "Est."]
knot1 <- breakpoints[[1]]
knot2 <- breakpoints[[2]]

# Plot piecewise polynomial regression
plot(GC_5K_clean, reads_5K_clean, pch = 16, cex = 0.5, col = rgb(0,0,0,0.5), 
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     main = "Piecewise Polynomial Regression")
plot(seg_model, add = TRUE, col = rgb(1,0,0.5,1))
abline(v = c(knot1, knot2), lty = 2, col = "gray", lwd = 1.5)

# Fit and plot piecewise linear regression using lm() and logical operations
plot(GC_5K_clean, reads_5K_clean, pch = 16, cex = 0.5, col = rgb(0,0,0,0.5), 
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     main = "Piecewise Linear Regression")

pw_linear_model <- lm(reads_5K_clean ~ I(GC_5K_clean * (GC_5K_clean < knot1)) +
                      I(GC_5K_clean * (GC_5K_clean >= knot1 & GC_5K_clean < knot2)) +
                      I(GC_5K_clean * (GC_5K_clean >= knot2)))

# Predict and plot the piecewise linear model
new_data <- data.frame(GC_5K_clean = seq(min(GC_5K_clean), max(GC_5K_clean), length.out = 100))
predictions <- predict(pw_linear_model, newdata = new_data)

lines(new_data$GC_5K_clean, predictions, col = rgb(0,0.5,1,1), lwd = 2)

# Plot knots for reference
abline(v = c(knot1, knot2), lty = 2, col = "gray", lwd = 1.5)

```


# Question 2: Residuals vs Explanatory Variable
Let's start by comparing the residuals of the piecewise polynomial model and the linear model. Ideally, residuals should be randomly distributed around zero without any discernible pattern.


```{r}
# Calculate residuals
pw_poly_residuals <- reads_5K_clean - predict(seg_model)
linear_residuals <- reads_5K_clean - predict(pw_linear_model)

# Plot residuals for piecewise polynomial model
plot(GC_5K_clean, pw_poly_residuals, pch = 16, cex = 0.5, col = rgb(0, 0, 0, 0.5),
     xlab = "GC Content (cleaned)", ylab = "Residuals",
     main = "Residuals of Piecewise Polynomial Model")

# Plot residuals for linear model
plot(GC_5K_clean, linear_residuals, pch = 16, cex = 0.5, col = rgb(0, 0, 0, 0.5),
     xlab = "GC Content (cleaned)", ylab = "Residuals",
     main = "Residuals of Linear Model")
```
     
# Bias Assessment
Bias for Certain GC Values: If there is a noticeable pattern (e.g., residuals consistently above or below zero) in the residuals plot for certain ranges of GC values, it indicates bias. A good fit will have residuals scattered randomly around zero, without any specific trend or pattern. Let's create the scatterplots of the residuals against the GC percentages for both the linear model and the spline model. The goal is to have residuals that are evenly distributed around zero across all GC values, indicating that the model does not systematically over or under-predict for specific GC ranges. This will help us determine if there is any bias for certain GC values.



# Numerical Comparison Metrics
Now, let's calculate and compare MSE and R-squared values for both models.

```{r}
# Function to calculate Mean Squared Error
mse <- function(residuals) {
  return(mean(residuals^2))
}

# Function to calculate R-squared
r_squared <- function(model, data, response) {
  ss_total <- sum((response - mean(response))^2)
  ss_residual <- sum(model$residuals^2)
  return(1 - ss_residual / ss_total)
}

# Calculate MSE for piecewise polynomial model
pw_poly_mse <- mse(pw_poly_residuals)

# Calculate MSE for linear model
linear_mse <- mse(linear_residuals)

# Calculate R-squared for piecewise polynomial model
pw_poly_r_squared <- r_squared(pw_poly_model, GC_5K_clean, reads_5K_clean)

# Calculate R-squared for linear model
linear_r_squared <- r_squared(linear_model, GC_5K_clean, reads_5K_clean)

# Print metrics
cat("MSE of Piecewise Polynomial Model:", pw_poly_mse, "\n")
cat("MSE of Linear Model:", linear_mse, "\n")
cat("R-squared of Piecewise Polynomial Model:", pw_poly_r_squared, "\n")
cat("R-squared of Linear Model:", linear_r_squared, "\n")
```

# Conclusion
Based on the visual comparison of residuals and numerical comparison metrics:

The piecewise polynomial model shows more evenly distributed residuals around zero, indicating a potentially better fit than the linear model, which shows patterns in residuals.
The MSE and R-squared values further support that the piecewise polynomial model provides a better fit to the data compared to the linear model.
Therefore, we conclude that choosing a quadratic piecewise polynomial model was appropriate for capturing the non-linear relationship between GC content and read counts in this dataset.
This analysis demonstrates the importance of model selection and evaluation in regression analysis, using straightforward visual and numerical methods.



