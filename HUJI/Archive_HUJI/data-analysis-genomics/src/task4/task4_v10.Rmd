---
title: "Lab Task 4: Approx. Regression w/ Piecewise Polynomial Model"
author: "Group 6"
date: Sys.Date()
output:
  html_document:
    code_folding: show
editor_options: 
  markdown: 
    wrap: sentence
---

Group members:

- Shawn Yakir , 315714980, shawnyakir@gmail.com
- Sarah Levitz, 324673623, sarah.levitz@mail.huji.ac.il
- Carmel Baris, 318455276, carmel.baris@mail.huji.ac.il 


# Libraries

```{r library, message=FALSE, warning=FALSE}
library(segmented)

```

# Setting up environment & paths
```{r setup}

## ---- CLEAN ENV
rm(list = ls())

## ---- SET WORKING DIRECTORY
dir_name = "C:/Users/user/Documents/Carmel/Projects/HUJI/Archive_HUJI/data-analysis-genomics/data/"

## ---- LOAD HELPER FUNCTIONS
helpers_file = file.path(dir_name, "help_funcs.R")
source(helpers_file)
helpers <- list(
    loadRData = loadRData,
    fitMet = fitMetrics,
    rmvOutliers = removeOutliersPaired,
    binBases = helpers$binBases
)
```

# Loading data files 

```{r warning=FALSE}

## ---- LOAD FILE OF NUCLEO_BASES (A,T,C,G)
bases_file = file.path(dir_name, "chr1_line.rda")
chr1_bases = helpers$loadRData(bases_file) # like Lecture1


## ---- LOAD FILE OF READS LOCATIONS (THAT START A FRAGMENT)
reads_file_all = file.path(dir_name,"TCGA-13-0723-01A_lib2_all_chr1.forward")
chr1_reads = data.table::fread(reads_file_all) #like Lecture2
colnames(chr1_reads) = c("Chrom","Loc","FragLen")   


```


# Preprocessing data 

```{r prep, include=FALSE}

## chunk should not have eval = FALSE!!
## o/w it messes up GC_5K

nreads = nrow(chr1_reads)
myLocations = as.numeric(chr1_reads$Loc)
last_read = myLocations[nreads]

binsize = 5000

## ------------------------------------------------
## ---- BINNING NUCLEO_BASES DATA
##
# per bin, count occurrences of each letter
bases_5K = helpers$binBases(chr1_bases, last_read, binsize) 

# per bin, sum occurrence counts of C & G only (GC content)
GC_5K <<- bases_5K[, 3] + bases_5K[, 4] #store as global variable

# convert GC_5K into percentages
if(any(GC_5K>1)){ # This makes sure I don't repeat the command
  GC_5K = GC_5K / binsize
}

## ------------------------------------------------
## ---- BINNING READS COVERAGE DATA

# save reads coverage data per bin
reads_5K = helpers$binReads(myLocations,binsize,last_read)
save(reads_5K, GC_5K,file = file.path(dir_path=dir_name,"reads_gc_5K.rda"))

# remove redundant files from memory
rm("chr1_bases","chr1_reads") 

# load data
reads_file_5K = file.path(dir_name, "reads_gc_5K.rda")
reads_gc_5K = helpers$loadRData(reads_file_5K)
# access using `$`:
#   GC_5K = reads_gc_5K$GC_5K
#   reads_5K = reads_gc_5K$reads_5K


```



# Remove outliers

```{r}
# Remove outliers from reads and GC content data
cleaned_data = helpers$rmvOutliers(GC_5K, reads_5K)
GC_5K_clean = cleaned_data$x
reads_5K_clean = cleaned_data$y

```

# Splitting Data to Test and Train
```{r train_test}

# Assuming your data is in vectors GC_5K_clean and reads_5K_clean
set.seed(123)  # For reproducibility

# Combine the data into a dataframe
data <- data.frame(GC_5K_clean = GC_5K_clean, reads_5K_clean = reads_5K_clean)

# Split the data into training (70%) and testing (30%) sets
train_indices <- sample(seq_len(nrow(data)), size = 0.7 * nrow(data))
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]

# Fit a piecewise regression model on the training data
lin_model <- lm(reads_5K_clean ~ GC_5K_clean, data = train_data)
seg_model <- segmented(lin_model, seg.Z = ~GC_5K_clean, psi = list(GC_5K_clean = c(0.3, 0.7)))

# Make predictions on the testing data
test_predictions <- predict(seg_model, newdata = test_data)

# Calculate R-squared and MSPE on the testing data
actual <- test_data$reads_5K_clean
predicted <- test_predictions

r_squared <- 1 - sum((actual - predicted)^2) / sum((actual - mean(actual))^2)
mspe <- mean((actual - predicted)^2)

# Print the metrics
cat("R-squared on testing data:", round(r_squared, 2), "\n")
cat("MSPE on testing data:", round(mspe, 2), "\n")

```

# Question 1: Segmented regression


```{r pw_regression}

# Fit initial linear model
initial_model = lm(reads_5K_clean ~ GC_5K_clean)
# Using `segmented` package for piecewise regression
seg_model = segmented(initial_model, seg.Z = ~GC_5K_clean, npsi = 2)

# Extract knots
knots = seg_model$psi[, "Est."]
knot1 = knots[[1]]
knot2 = knots[[2]]

# Plot piecewise polynomial regression
plot(GC_5K_clean, reads_5K_clean, pch = 16, cex = 0.5, col = rgb(0,0,0,0.5), 
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     main = "Piecewise Polynomial Regression")
plot(seg_model, add = TRUE, col = rgb(1,0,0.5,1))
abline(v = c(knot1, knot2), lty = 2, col = "darkgray", lwd = 1.5)

# Fit and plot piecewise linear regression using lm() and logical operations
plot(GC_5K_clean, reads_5K_clean, pch = 16, cex = 0.5, col = rgb(0,0,0,0.5),
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     main = "Piecewise Quadratic Regression")

# Plot knots for reference
abline(v = c(knot1, knot2), lty = 2, col = "darkgray", lwd = 1.5)

# Fit and plot piecewise linear regression using lm() and logical operations
plot(GC_5K_clean, reads_5K_clean, pch = 16, cex = 0.5, col = rgb(0,0,0,0.5), 
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     main = "Piecewise Linear Regression")

lin_model = lm(reads_5K_clean ~ I(GC_5K_clean * (GC_5K_clean < knot1)) +
                      I(GC_5K_clean * (GC_5K_clean >= knot1 & 
                                         GC_5K_clean < knot2)) +
                      I(GC_5K_clean * (GC_5K_clean >= knot2)))

# Predict and plot the piecewise linear model using lm() and logical operations
new_data_lin = data.frame(GC_5K_clean = seq(min(GC_5K_clean), 
                                            max(GC_5K_clean), 
                                            length.out = 100))
predictions = predict(lin_model, newdata = new_data_lin)

lines(new_data_lin$GC_5K_clean, predictions, col = rgb(0,1,0.5,1), lwd = 2)

# Plot knots for reference
abline(v = c(knot1, knot2), lty = 2, col = "darkgray", lwd = 1.5)


```


# Question 2: Residuals vs Explanatory Variable
Let's start by comparing the residuals of the piecewise polynomial model and the linear model. Ideally, residuals should be randomly distributed around zero without any discernible pattern.


```{r}

# Plot the residuals
residuals <- actual - predicted
plot(test_data$GC_5K_clean, residuals, main = "Residuals of Piecewise Model", xlab = "GC_5K", ylab = "Residuals")
abline(h = 0, col = "red")

# Optionally, add fitted lines to the plot to visualize the segments
plot(train_data$GC_5K_clean, train_data$reads_5K_clean, main = "Piecewise Regression", xlab = "GC_5K", ylab = "reads_5K")
lines(train_data$GC_5K_clean, predict(seg_model, newdata = train_data), col = "blue")

```
     
# Bias Assessment
Bias for Certain GC Values: If there is a noticeable pattern (e.g., residuals consistently above or below zero) in the residuals plot for certain ranges of GC values, it indicates bias. A good fit will have residuals scattered randomly around zero, without any specific trend or pattern. The goal is to have residuals that are evenly distributed around zero across all GC values, indicating that the model does not systematically over or under-predict for specific GC ranges. This will help us determine if there is any bias for certain GC values.


# Numerical Comparison Metrics

R-squared is based on the assumption of a linear relationship between the predictors and the response variable. In non-linear or piecewise regression models, this assumption is violated. As a result, R-squared might not fully capture the model's ability to generalize to new data. In other words, if the R-squared metric is high, it may be due to overfitting rather than precision of prediction.  \n

The measure can be misleading because it suggests a good fit even if the model does not predict new data well. For non-linear relationships, other metrics like Mean Squared Prediction Error (MSPE) are more indicative of predictive performance. \n

By using MSPE alongside R-squared, we can get a clearer picture of how well our model predicts new data.



```{r}

# Predictions from the models
pred_seg = predict(seg_model)

# Compute metrics for training data
met_seg = helpers$fitMetrics(reads_5K_train, pred_seg)

# Predictions on test data


# Combine metrics for comparison
metrics_comparison = data.frame(
  Model = c("Segmented", "Linear"),
  R_sqr = c(met_seg$R_sqr, met_lin$R_sqr),
  MSE = c(met_seg$MSE, met_lin$MSE),
  MAE = c(met_seg$MAE, met_lin$MAE),
  MSPE = c(met_seg$MSPE, met_lin$MSPE)
)

print(metrics_comparison)

```

# Conclusion
Based on the visual comparison of residuals and numerical comparison metrics:

The model using the `segmented` package shows more evenly distributed residuals around zero, indicating a potentially better fit than the linear or the quadratic models. The MSPE, MSE and R-squared metrics further support this indication.


