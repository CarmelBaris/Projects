---
title: "Lab Task 4: Approx. Regression w/ Piecewise Polynomial Model"
author: "Group 6"
date: Sys.Date()
output:
  html_document:
    code_folding: show
editor_options: 
  markdown: 
    wrap: sentence
---

Group members:

- Shawn Yakir , 315714980, shawnyakir@gmail.com
- Sarah Levitz, 324673623, sarah.levitz@mail.huji.ac.il
- Carmel Baris, 318455276, carmel.baris@mail.huji.ac.il 


## Libraries

```{r library, message=FALSE, warning=FALSE}
library(segmented)
library(data.table)
library(caret)  # For creating training and testing sets

```

## Setting up environment & paths
```{r setup}
## ------------------------------------------------
## ---- DEPENDENCIES AKA FILES REQUIRED
## Make sure that all files are in the current working directory:
## 1. chr1_bases.rda
## 2. TCGA-13-0723-01A_lib2_all_chr1.forward
## 3. helpers_file
## 
## Note that in this lecture we'll create and save a new file:
## 4. reads_gc_20K.rda


## ------------------------------------------------
## ---- CLEAN ENVIRONMENT
rm(list = ls())


## ---- SET WORKING DIRECTORY
dir_name = "~/Carmel/RProjects/Lab_Benjamini/data/"
# dir_name = "/Users/alevi/Downloads/"
# setwd(dir_name)
# getwd() # validate


## ------------------------------------------------
## ---- LOAD HELPER FUNCTIONS
helpers_file = file.path(dir_name, "help_funcs.R")
source(helpers_file)
helpers <- list(
    loadRData = loadRData,
    fitMet = fitMetrics,
    rmvOut = removeOutliersPaired,
    binBases = binBases)

```

## Loading data files 

```{r warning=FALSE}

## ------------------------------------------------
## ---- LOAD FILE OF NUCLEO_BASES (A,T,C,G)
bases_file = file.path(dir_name, "chr1_line.rda")
chr1_bases = helpers$loadRData(bases_file) # like Lecture1


## ------------------------------------------------
## ---- LOAD FILE OF READS LOCATIONS (THAT START A FRAGMENT)
  
reads_file_all = file.path(dir_name,"TCGA-13-0723-01A_lib2_all_chr1.forward")
chr1_reads = data.table::fread(reads_file_all) #like Lecture2
colnames(chr1_reads) = c("Chrom","Loc","FragLen")   


```


## Preprocessing data 

```{r message=FALSE, warning=FALSE}

## chunk should not have eval = FALSE!!
## o/w it messes up GC_20K

nreads = nrow(chr1_reads)
myLocations = as.numeric(chr1_reads$Loc)
last_read = myLocations[nreads]

binsize = 20000

## ------------------------------------------------
## ---- BINNING NUCLEO_BASES DATA
##
# per bin, count occurrences of each letter
bases_20K = binBases(chr1_bases, last_read, binsize) 

# per bin, sum occurrence counts of C & G only (GC content)
GC_20K <<- bases_20K[, 3] + bases_20K[, 4] #store as global variable

# convert GC_20K into percentages
if(any(GC_20K>1)){ # This makes sure I don't repeat the command
  GC_20K = GC_20K / binsize
}

## ------------------------------------------------
## ---- BINNING READS COVERAGE DATA

# per bin, calculate reads coverage 
reads_20K = binReads(myLocations,binsize,last_read)
save(reads_20K, GC_20K,file = file.path(dir_path=dir_name,"reads_gc_20K.rda"))


## ------------------------------------------------
## ---- CLEARING UP ENV
rm("chr1_bases","chr1_reads") # remove from memory

# load data
reads_file_20K = file.path(dir_name, "reads_gc_20K.rda")
reads_gc_20K = helpers$loadRData(reads_file_20K)
# access using `$`:
#   GC_20K = reads_gc_20K$GC_20K
#   reads_20K = reads_gc_20K$reads_20K


```



## Remove outliers

```{r}
# Remove outliers from reads and GC content data
cleaned_data = helpers$rmvOut(GC_20K, reads_20K)
GC_20K_clean = cleaned_data$x
reads_20K_clean = cleaned_data$y

```


## Q1: Segmented regression


```{r pw_regression}

# Fit initial linear model
initial_model = lm(reads_20K_clean ~ GC_20K_clean)
# Using `segmented` package for piecewise regression
seg_model = segmented(initial_model, seg.Z = ~GC_20K_clean, npsi = 2)

# Extract breakpoints
breakpoints = seg_model$psi[, "Est."]
knot1 = breakpoints[[1]]
knot2 = breakpoints[[2]]

# Plot piecewise polynomial regression
plot(GC_20K_clean, reads_20K_clean, pch = 16, cex = 0.5, col = rgb(0,0,0,0.5),
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     main = "Piecewise Polynomial Regression")
plot(seg_model, add = TRUE, col = rgb(1,0,0.5,1))
abline(v = c(knot1, knot2), lty = 2, col = "darkgray", lwd = 1.5)

# Plot knots for reference
abline(v = c(knot1, knot2), lty = 2, col = "darkgray", lwd = 1.5)


# Extract breakpoints from your segmented model
breakpoints <- seg_model$psi[, 2]  # Assuming there are two breakpoints

# Create a new dataframe for fitting
df_fit <- data.frame(
    y = reads_20K_clean,
    x = GC_20K_clean
)

# Add indicator variables and interactions
df_fit$seg1 <- ifelse(df_fit$x <= breakpoints[1], df_fit$x, breakpoints[1])
df_fit$seg2 <- ifelse(df_fit$x > breakpoints[1] & df_fit$x <= breakpoints[2], df_fit$x - breakpoints[1], 0)
df_fit$seg2[df_fit$x > breakpoints[2]] <- breakpoints[2] - breakpoints[1]
df_fit$seg3 <- ifelse(df_fit$x > breakpoints[2], df_fit$x - breakpoints[2], 0)

# Fit the piecewise linear model manually
manual_piecewise_model <- lm(y ~ seg1 + seg2 + seg3, data = df_fit)

# For plotting
new_data <- data.frame(x = seq(min(GC_20K_clean), max(GC_20K_clean), length.out = 1000))
new_data$seg1 <- ifelse(new_data$x <= breakpoints[1], new_data$x, breakpoints[1])
new_data$seg2 <- ifelse(new_data$x > breakpoints[1] & new_data$x <= breakpoints[2], new_data$x - breakpoints[1], 0)
new_data$seg2[new_data$x > breakpoints[2]] <- breakpoints[2] - breakpoints[1]
new_data$seg3 <- ifelse(new_data$x > breakpoints[2], new_data$x - breakpoints[2], 0)

# Predict using the manual model
new_data$predicted <- predict(manual_piecewise_model, newdata = new_data)

# Plot
lines(new_data$x, new_data$predicted, col = "purple", lwd = 0.5)


# Assuming breakpoints are known

# Fit the piecewise linear model using I() notation
piecewise_model <- lm(reads_20K_clean ~ I(GC_20K_clean * (GC_20K_clean <= knot1)) +
                      I((GC_20K_clean > knot1) & (GC_20K_clean <= knot2)) +
                      I(GC_20K_clean * ((GC_20K_clean > knot1) & (GC_20K_clean <= knot2))) +
                      I(GC_20K_clean * (GC_20K_clean > knot2)))

# Create new data for prediction
new_data <- data.frame(GC_20K_clean = seq(min(GC_20K_clean), max(GC_20K_clean), length.out = 1000))
new_data$y_pred <- predict(piecewise_model, newdata = new_data)


# Plot the predicted piecewise regression line
lines(new_data$GC_20K_clean, new_data$y_pred, col = "orange", lwd = 2)

# Add vertical lines to indicate breakpoints
abline(v = c(knot1, knot2), lty = 2, col = "darkgray", lwd = 1.5)


```



```{r}
# Fit initial linear model
initial_model = lm(reads_20K_clean ~ GC_20K_clean)

# Using `segmented` package for piecewise regression
seg_model = segmented(initial_model, seg.Z = ~GC_20K_clean, npsi = 2)

# Extract breakpoints
breakpoints = seg_model$psi[, "Est."]
knot1 = breakpoints[[1]]
knot2 = breakpoints[[2]]

# Plot piecewise polynomial regression
plot(GC_20K_clean, reads_20K_clean, pch = 16, cex = 0.5, col = rgb(0,0,0,0.5),
     xlab = "GC Content (cleaned)", ylab = "Read Counts (cleaned)",
     main = "Piecewise Polynomial Regression")

# Add segmented model plot
plot(seg_model, add = TRUE, col = rgb(1,0,0.5,1))
abline(v = c(knot1, knot2), lty = 2, col = "darkgray", lwd = 1.5)

# Plot knots for reference
abline(v = c(knot1, knot2), lty = 2, col = "darkgray", lwd = 1.5)

# Create a new dataframe for fitting manually
df_fit <- data.frame(
    y = reads_20K_clean,
    x = GC_20K_clean
)

# Add indicator variables and interactions
df_fit$seg1 <- ifelse(df_fit$x <= breakpoints[1], df_fit$x, breakpoints[1])
df_fit$seg2 <- ifelse(df_fit$x > breakpoints[1] & df_fit$x <= breakpoints[2], df_fit$x - breakpoints[1], 0)
df_fit$seg2[df_fit$x > breakpoints[2]] <- breakpoints[2] - breakpoints[1]
df_fit$seg3 <- ifelse(df_fit$x > breakpoints[2], df_fit$x - breakpoints[2], 0)

# Fit the piecewise linear model manually
manual_piecewise_model <- lm(y ~ seg1 + seg2 + seg3, data = df_fit)

# For plotting manually fitted model
new_data_manual <- data.frame(x = seq(min(GC_20K_clean), max(GC_20K_clean), length.out = 1000))
new_data_manual$seg1 <- ifelse(new_data_manual$x <= breakpoints[1], new_data_manual$x, breakpoints[1])
new_data_manual$seg2 <- ifelse(new_data_manual$x > breakpoints[1] & new_data_manual$x <= breakpoints[2], new_data_manual$x - breakpoints[1], 0)
new_data_manual$seg2[new_data_manual$x > breakpoints[2]] <- breakpoints[2] - breakpoints[1]
new_data_manual$seg3 <- ifelse(new_data_manual$x > breakpoints[2], new_data_manual$x - breakpoints[2], 0)

# Predict using the manual model
new_data_manual$predicted <- predict(manual_piecewise_model, newdata = new_data_manual)

# Plot manually fitted model
lines(new_data_manual$x, new_data_manual$predicted, col = "purple", lwd = 2)

# Fit the piecewise linear model using I() notation
piecewise_model_I <- lm(reads_20K_clean ~ I(GC_20K_clean * (GC_20K_clean <= knot1)) +
                      I(GC_20K_clean * ((GC_20K_clean > knot1) & (GC_20K_clean <= knot2))) +
                      I(GC_20K_clean * (GC_20K_clean > knot2)))

# Create new data for prediction using I() notation
new_data_I <- data.frame(GC_20K_clean = seq(min(GC_20K_clean), max(GC_20K_clean), length.out = 1000))
new_data_I$y_pred <- predict(piecewise_model_I, newdata = new_data_I)

# Plot the predicted piecewise regression line using I() notation
lines(new_data_I$GC_20K_clean, new_data_I$y_pred, col = "orange", lwd = 2)

# Add vertical lines to indicate breakpoints
abline(v = c(knot1, knot2), lty = 2, col = "darkgray", lwd = 1.5)

# Legend
legend("topleft", legend = c("Segmented Package", "Manual Piecewise", "I() Notation"), 
       col = c(rgb(1,0,0.5,1), "purple", "orange"), lwd = 2, cex = 0.7)

```

## Q2: Residuals vs Explanatory Variable
Let's start by comparing the residuals of the piecewise polynomial model and the linear model. Ideally, residuals should be randomly distributed around zero without any discernible pattern.


```{r}

# Calculate residuals
poly_res = reads_20K_clean - predict(seg_model)

# Plot residuals for piecewise polynomial model
plot(GC_20K_clean, poly_res, pch = 16, cex = 0.5, col = rgb(0, 0, 0, 0.5),
     xlab = "GC Content (cleaned)", ylab = "Residuals",
     main = "Residuals of Piecewise Polynomial Model")

abline(h = 0, col = "darkgray", lwd = 1.5)


```
     
## Bias Assessment
Bias for Certain GC Values: If there is a noticeable pattern (e.g., residuals consistently above or below zero) in the residuals plot for certain ranges of GC values, it indicates bias. A good fit will have residuals scattered randomly around zero, without any specific trend or pattern. The goal is to have residuals that are evenly distributed around zero across all GC values, indicating that the model does not systematically over or under-predict for specific GC ranges. This will help us determine if there is any bias for certain GC values.


## Q3: Comparing to Simple Linear Regression
Now, we calculate and compare Root Mean Squared Error, Mean Absolute Error and R-squared values for both models.

```{r}

# Predictions from the models
pred_seg = predict(seg_model)

# Compute metrics
met_seg = helpers$fitMet(reads_20K_clean, pred_seg)

# Combine metrics for comparison
metrics_comparison = data.frame(
  Model = c("Segmented"),
  R_sqr = c(met_seg$R_sqr),
  MSE = c(met_seg$MSE),
  MAE = c(met_seg$MAE)
)

print(metrics_comparison)

```



## Splitting Data to Test and Train

```{r train_test}
set.seed(123)

# Create training and testing sets
train_index = caret::createDataPartition(GC_20K_clean, p = 0.8, list = FALSE)
GC_20K_train = GC_20K_clean[train_index]
reads_20K_train = reads_20K_clean[train_index]
GC_20K_test = GC_20K_clean[-train_index]

```

## Conclusion
Based on the visual comparison of residuals and numerical comparison metrics:

The model using the `segmented` package shows more evenly distributed residuals around zero, indicating a potentially better fit than the linear or the quadratic models. The MSPE, MSE and R-squared metrics further support this indication.

